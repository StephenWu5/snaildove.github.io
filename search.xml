<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[经典摘录-贝叶斯公式]]></title>
    <url>%2F2017%2F08%2F28%2FBayes_rule%2F</url>
    <content type="text"><![CDATA[说明：全文摘自Introduction to probability, 2nd Edition 本文讨论条件概率定律的应用，首先引入一个计算事件概率的定理。 全概率公式设 $A_1, A_2, … , A_n$ 是一组互不相容的事件，它形成样本空间的一个分割（每个试验结果必定使得其中一个事件发生！）。又假定对每个 $i, P(A_i) &gt; 0$ 。则对任何事件 $B$ ，下列公式成立$$\begin{eqnarray}P(B) &amp;=&amp; P(A_1\cap B )+\cdots+P(A_n\cap B) \&amp;=&amp; P(A_1)P(B|A_1)+\cdots+P(B)P(B|A_n)\end{eqnarray}$$下图是全概率公式的图示和证明。直观上，将样本空间分割成若干事件 $A_i$ 的并（ $A_1, \cdots, A_n$ 形成样本空间的一个分割）然后任意事件 $B$ 的概率等于事件 $B$ 在 $A_i$ 发生的情况下的条件概率的加权平均，而权重刚好等于这些事件 $A_i$ 的无条件概率。这条定理的一个主要应用是计算事件 $B$ 的概率。直接计算事件 $B$ 的概率有点难度，但是若条件概率 $P(B|A_i)$ 是已知的或是很容易推导计算时，全概率定理就成为了计算 $P(B)$ 的有力工具。应用这条定理的关键是找到合适的分割 $A_1,\cdots, A_n$ ，而合适的分割又与问题的实际背景有关。 由于事件 $A_1, A_2, \cdots, A_n$ 形成一个样本空间的一个分割，事件 $B$ 可以分解成不想交的 $n$ 个事件的并，即： $$B=(A_!\cap B)\cup\cdots\cup(A_n\cap B) \quad (1)$$利用可加定理，得到： $$P(B) = P(A_1 \cap B)+\cdots+P(A_n \cap B) \quad (2)$$利用条件概率的定义，得到： $$P(A_i\cap B) = P(A_i)P(B|A_i) \quad (3)$$将 $(3)$ 式子代入 $(2)$ 式子中得到： $$P(B)=P(A_1)P(B|A_1)+\cdots+P(A_n)P(B|A_n)$$也可以用等价的序列树形图来说明全概率定理（如上右边图）：叶子 $A_i \cap B$ 的概率等于由叶子到根部上的概率的乘积 $P(A_i)P(B|A_i)$ 。而事件 $B$ 由图上显示的3个叶子组成，将它们的概率相加就得到 $P(B)$ 。 全概率公式例子例 1.13 你参加一个棋类比赛，其中 $50\%$ 是一类棋手，你赢他们的概率为 $0.3\%$ ； $25\%$ 是二类棋手，你赢他们的概率是 $0.4$ ；剩下的是三类棋手，你赢得他们的概率是 $0.5$ 。从他们中间随机地选一位棋手与你比赛，你胜算的概率有多大？ 记 $A_i$ 表示与你下棋的棋手的类别。依题意 $$P(A_1)=0.5,\quad P(A_2) =0.25, \quad P(A_3) = 0.25$$记 $B$ 为你赢得比赛的事件，那么得到： $$P(B|A_1)=0.3,\quad P(B|A_2)=0.4,\quad P(B|A_3)=0.5$$那么利用全概率公式，你在不比赛中胜出的概率为：$$\begin{eqnarray}P(B) &amp;=&amp; P(A_1)P(B|A_1)+P(A_2)P(B|A_2)+P(A_3)P(B|A_3) \&amp;=&amp; 0.5 \cdot 0.3+ 0.25 \cdot 0.4 + 0.25 \cdot 0.5 \&amp;=&amp; 0.375\end{eqnarray}$$ 推断与贝叶斯定理全概率公式经常与著名的贝叶斯公式联系起来，贝叶斯公式将形如 $P(A|B)$ 的条件概率与形如 $P(B|A)$ 的条件概率联系起来。 贝叶斯公式设 $A_1,A_2,\ldots,A_n$ 是一组互斥的事件，它形成样本空间的一个分割（每个试验结果必定使得其中一个事件发生）。又假定对每一个 $i, P(A_i)&gt;0$ ，则对于任何事件 $B$ ，只要它满足 $P(B)&gt;0$ ，下列公式成立：$$\begin{eqnarray}P(A_i|B) &amp;=&amp; \frac{P(A_i)P(B|A_i)}{P(B)}\&amp;=&amp;\frac{P(A_i)P(B|A_i)}{P(A_1)P(B|A_1)+\cdots+P(A_n)P(B|A_n)}\end{eqnarray}$$为证明贝叶斯公式，只需注意到 $P(A_i)P(B|A_i)$ 与 $P(B)P(A_i|B)$ 是相等的，它们都等于 $P(A_i \cap B)$ ，这样得到了第一个等式，至于第二个等式，只需对 $P(B)$ 利用全概率公式即可。 贝叶斯公式还可以用来进行因果推理。有许多”原因“可以造成某一”结果“。现在设我们观察到某一结果，希望推断造成这个结果出现的”原因“。现在设事件 $A_1,\ldots, A_n$ 是原因，而 $B$ 代表由原因引起的结果。 $P(B|A_i)$ 表示在因果模型中由”原因“ $A_i$ 造成结果 $B$ 的概率（见下图）。当观察到结果 $B$ 的时候，希望反推结果 $B$ 是由原因 $A_i$ 造成的概率 $P(A_i|B)$ 。 $P(A_i|B)$ 为由于代表新近得到的信息 $B$ 之后 $A_i$ 出现的概率，称之为后验概率，而原来的 $P(A_i)$ 就称为先验概率。 贝叶斯推断的例子医学在某病人X光片中发现一个阴影，（用 $B$ 表示，代表”结果“）。希望对造成这种结果的3个原因进行分析。这3个原因互斥，并且造成这个结果的原因一定是三者之一：原因1（事件 $A_1$）是恶性肿瘤，原因2（事件 $A_2$）是良性肿瘤，原因3（事件 $A_3$）是肿瘤外的其他原因。假定已经知道 $P(A_i)$ 和 $P(B|A_i), i=1,2,3$ 。现在已经发现了阴影（事件 $B$ 发生），利用贝叶斯公式，这些原因的条件概率为： $$P(A_i|B)=\frac{P(A_i)P(B|A_i)}{P(A_1)P(B|A_1)+P(A_2)P(B|A_2)+P(A_3)P(B|A_3)},i=1,2,3$$在右图给出序列树形图，可用序列树形图给出条件概率计算的另外一种等价的解释。图中第一个深灰的叶子表示恶性肿瘤并出现阴影，其概率为 $P(A_1\cap B)$ ，且所有深灰的叶子表示片子中出现阴影，其概率为 $P(B)$ ，而由恶性肿瘤造成阴影的条件概率 $P(A_1|B)$ 是两个概率相除的结果。 比赛继续使用例 1.13 你参加一个棋类比赛，其中 $50\%$ 是一类棋手，你赢他们的概率为 $0.3\%$ ； $25\%$ 是二类棋手，你赢他们的概率是 $0.4$ ；剩下的是三类棋手，你赢得他们的概率是 $0.5$ 。现在假定你已经得胜，问你的对手为一类棋手的概率有多大？用 $A_i$ 表示你与 $i$ 类棋手相遇的事件。由例中给出的条件知道：$$P(A_1)=0.5,\quad P(A_2)=0.25,\quad P(A_3)=0.25$$记 $B$ 表示你赢的比赛的事件，你胜出的概率为：$$P(B|A_1)=0.3,\quad P(B|A_2)=0.4,\quad P(B|A_3)=0.5$$利用贝叶斯公式得：$$\begin{eqnarray}P(A_1|B) &amp;=&amp; \frac{P(A_1)P(B|A_1)}{P(A_1)P(B|A_1)+P(A_2)P(B|A_2)+P(A_3)P(B|A_3)} \&amp;=&amp; \frac{0.5\cdot 0.3}{0.5\cdot 0.3+0.25\cdot 0.4+0.25\cdot 0.5} \&amp;=&amp; 0.4\end{eqnarray}$$ 假阳性之谜 设对于某种少见的疾病的检出率为 $0.95$ ；如果一个被检查的病人有某种疾病，其检查结果为阳性的概率为 $0.95$ ；如果该人没有这种疾病，其检查结果为阴性的概率是 $0.95$ 。现在假定某一人群中患有这种病的概率为 $0.001$ ，并从这个总体中随机地抽取一个人进行检测，检查结果为阳性。现在问这个人患有这种病的概率有多大？ 设 $A$ 为这个人有这种疾病， $B$ 为经检验这个人为阳性。利用贝叶斯公式：$$\begin{eqnarray}P(A|B) &amp;=&amp; \frac{P(A)P(B|A)}{P(A)P(B|A)+P(A^c)P(B|A^c)} \&amp;=&amp; \frac{0.001\cdot 0.95}{0.001\cdot 0.95 + 0.999\cdot 0.05} \&amp;=&amp; 0.0187\end{eqnarray}$$尽管检验方法非常精确，一个经检测为阳性的人仍然不大可能真正患有这种疾病（患有该疾病的概率小于 $2\%$ ）。根据《经济学人》杂志 $1999$ 年 $2$ 月 $20$ 日的报道，在一家著名的大医院中 $80\%$ 的受访者不知道这类问题的正确答案，而大部分人回答，这个经检测为阳性的人患病概率为 $0.95$ ! 连续随机变量的贝叶斯公式在许多情况下，我们会遇到一个没有观察到的对象。用随机变量 $X$ 代表这种未观察到的量，设其概率密度函数是 $ f_X(x)$ 。我们能够观察到的量是经过噪声干扰的量 $Y$ ，$Y$ 的分布函数是条件分布函数，其条件概率密度函数为： $f_{X|Y}(y|x)$ 。当 $Y$ 的值被观察到以后，它包含 $X$ 的多少信息呢？这类问题与离散随机变量的推断问题类似。现在唯一的不同之处在于处理的是连续随机变量。 上图是推断问题的框图，有一个未观察到的变量 $X$ ，其概率密度函数 $f_X$ 是已知的，同时得到一个观察到的随机变量 $Y$ ，其条件概率密度函数为 $f_{Y|X}(y|x)$ 。给定 $Y$ 的观察值 $y$ ，推断问题变成条件概率密度函数 $f_{X|Y}(x|y)$ 的计算问题。 注意到：当观察到事件 $Y=y$ 以后，所有的信息都包含在条件概率密度函数 $f_{X|Y}(x|y)$ 中，现在只需计算这个条件概率密度函数。利用公式 $f_Xf_{Y|X}=f_{X,Y}=f_Yf_{X|Y}$ 可以得到： $$f_{X|Y}(x|y)=\frac{f_X(x)f_{Y|X}(y|x)}{f_Y(y)}$$这个即所求的公式，与之等价的公式： $$f_{X|Y}(x|y)=\frac{f_X(x)f_{Y|X}(y|x)}{\int_{-\infty}^{+\infty}f_X(t)f_{Y|X}(y|t)dt}$$ 例子通用照明公司生产一种灯泡，已知其使用寿命 $Y$ 为指数随机变量，其概率密度函数为 $\lambda e^{-\lambda y}, y&gt;0$ ，按过往经验，在任意给定的一天参数 $\lambda$ 实际上是一个随机变量，其概率密度函数为区间 $[1, \frac{3}{2}]$ 上的均匀分布。现在随机地取已知灯泡进行试验，得到灯泡的寿命数据。得到数据以后，对于 $\lambda$ 的分布有什么新的认识？ 将 $\lambda$ 看成一个随机变量 $\Lambda$ ，作为对 $\lambda$ 的初始认识，那么根据题意 $\Lambda$ 的概率密度函数是： $$f_{\Lambda(\lambda)}=2, 1\le \lambda \le \frac{3}{2}$$当得到数据 $y$ 以后，关于 $\Lambda$ 的信息包含于条件概率密度函数 $f_{\Lambda, y}(\lambda|y)$ 中，利用连续贝叶斯公式得到： $$f_{ \Lambda|y}(\lambda|y)=\frac{f_\Lambda(\lambda)f_{Y|\Lambda}(y|\lambda)}{\int_{+\infty}^{-\infty}f_{\Lambda}(t)f_{Y|\Lambda}(y|t)dt}=\frac{2\lambda e^{-\lambda y}}{\int_{1}^{\frac{3}{2}}2te^{-ty}dt}，1\le \lambda \le \frac{3}{2}$$ 关于连续随机变量的推断在许多实际问题中，未观察到的随机变量可能是连续的随机变量。例如，在通信问题中传输的信号是一个二进制的信号，经过传输以后，混入的噪声是正态随机变量，这样，观测到的随机变量就是连续的随机变量；或者在医疗诊断中，观察到的量也是连续的测量值，例如：体温或血液样本中的指标。这种情况下需要将贝叶斯公式作适当改变。 现在研究一种特殊情况，未观察到的是一个事件$A$ 。不知道 $A$ 是否发生了。事件 $A$ 的概率 $P(A)$ 是已知的。设 $Y$ 是一个连续的随机变量，并且假定条件概率密度函数 $f_{Y|A}(y)$ 和 $f_{Y|A^c}(y)$ 是已知的。令人兴趣的是事件 $A$ 的条件概率密度函数 $P(A|Y=y)$ 。这个量代表得到的观察值 $y$ 以后关于事件 $A$ 的信息。 由于事件 ${Y=y}$ 是一个零概率事件，转而去考虑事件 ${y \le Y \le y+\delta}$ ，其中 $\delta$ 是一个很小的正数，然后令 $\delta$ 趋于0 。利用贝叶斯公式，令 $f_{Y}(y)&gt;0$ ，我们得到：$$\begin{eqnarray}P(A|Y=y) &amp;\approx&amp; P(A|y\le Y \le y+\delta) \&amp;=&amp; \frac{P(A)P(y\le Y \le y+\delta|A)}{P(y\le Y \le y+\delta)} \&amp;\approx&amp;\frac{P(A)f_{Y|A}(y)\delta}{f_Y(y)\delta} \&amp;=&amp; \frac{P(A)f_{Y|A}(y)}{f_Y(y)}\end{eqnarray}$$利用全概率公式，可将上式的分母写成：$$f_{Y}(y)=P(A)f_{Y|A}(y)+P(A^c)f_{Y|A^c}(y)$$这样得到：$$P(A|Y=y)=\frac{P(A)f_{Y|A}(y)}{P(A)f_{Y|A}(y)+P(A^c)f_{Y|A^c}(y)}$$现在令事件 $A$ 具有形式 ${N=n}$ ，其中 $N$ 是一个离散的随机变量，代表未观察到的随机变量。记 $p_N$ 为 $N$ 的分布函数。令 $Y$ 为连续随机变量，对任意 $N$ 的取值 $n$，$Y$ 具有条件概率密度函数 $f_{Y|N}(y|n)$ 。 这样上面的公式变成 ：$$P(N=n|Y=y)=\frac{p_N(n)f_{Y|N}(y|n)}{f_Y(y)}$$利用下面的全概率公式：$$f_Y(y)=\sum\limits_{i}p_N(i)f_{Y|N}(y|i)$$得到：$$P(N=n|Y=y)=\frac{p_N(n)f_{Y|N}(y|n)}{\sum\limits_{i}p_N(i)f_{Y|N}(y|i)}$$ 例子-信号检测设 $S$ 是一个只取2个值的信号（signal）。记 $P(S=1)=p$ 和 $P(S=-1)=1-p$ 。在接收端，得到的信号为 $Y=N+S$ ，其中 $N$ 是一个正态分布的噪声（noise），期望为0，方差为1，并且与 $S$ 相互独立。当观察到的信号为 $y$ 的时候，$S=1$ 的概率是多少？ 对于给定的 $S=s=1, Y$ 是一个正态随机变量，期望为 $s=1$ ，方差为 $1$ 。应用刚才得到的公式：$$P(S=1|Y=y)=\frac{p_S(1)f_{Y|S}(y|1)}{f_Y(y)}=\frac{\frac{p}{\sqrt{2\pi}}e^{-\frac{(y-1)^2}{2}}}{\frac{p}{\sqrt{2\pi}}e^{-\frac{(y-1)^2}{2}}+\frac{1-p}{\sqrt{2\pi}}e^{-\frac{(y+1)^2}{2}}}$$将上式化简得：$$P(S=1|Y=y)=\frac{pe^y}{pe^y+(1-p)e^{-y}}$$注意：当 $y\rightarrow -\infty, P(S=1|Y=y)\rightarrow 0$ ，当 $y\rightarrow \infty, P(S=1|Y=y)\rightarrow 1$ 。 $y$ 在实数轴上变化时， $P(S=1|Y=y)$ 是 $y$ 的严格上升函数，这符合直观的理解。 基于离散观察值的推断在前文连续随机变量的贝叶斯公式中得到的：$$\begin{eqnarray}P(A|Y=y) &amp;\approx&amp; P(A|y\le Y \le y+\delta) \&amp;=&amp; \frac{P(A)P(y\le Y \le y+\delta|A)}{P(y\le Y \le y+\delta)} \&amp;\approx&amp;\frac{P(A)f_{Y|A}(y)\delta}{f_Y(y)\delta} \&amp;=&amp; \frac{P(A)f_{Y|A}(y)}{f_Y(y)}\end{eqnarray}$$反解得到：$$f_{Y|A}(y)=\frac{f_Y(y)P(A|Y=y)}{P(A)}$$根据归一性（$\int_{-\infty}^{+\infty}f_{Y|A}(y)dy=1$），那么得到一个等价的表达式：$$f_{Y|A}(y)=\frac{f_Y(y)P(A|Y=y)}{\int_{-\infty}^{+\infty}f_Y(t)P(A|Y=t)dt}$$这个公式可以用于当事件 $A$ 被观测到时候，对随机变量 $Y$ 进行推断。对于事件 $A$ 是 ${N=n}$ 的形式，根据前文：$$P(N=n|Y=y)=\frac{p_N(n)f_{Y|N}(y|n)}{\sum\limits_{i}p_N(i)f_{Y|N}(y|i)}$$得到一个相似的公式对随机变量 $Y$ 进行推断：$$f_{Y|N}(y|n)=\frac{P(N=n|Y=y)\sum\limits_{i}p_N(i)f_{Y|N}(y|i)}{p_N(n)}$$ 总结令 $Y$ 为连续随机变量。 若 $X$ 为连续随机变量，则有：$$f_{X|Y}(x|y)f_Y(y)=f_X(x)f_{Y|X}(y|x)$$和$$f_{X|Y}(x|y)=\frac{f_X(x)f_{Y|X}(y|x)}{f_Y(y)}=\frac{f_X(x)f_{Y|X}(y|x)}{\int_{-\infty}^{+\infty}f_X(t)f_{Y|X}(y|t)dt}$$ 若 $N$ 为离散随机变量，则有：$$f_Y(y)P(N=n|Y=y)=p_N(n)f_{Y|N}(y|n)$$得到贝叶斯公式为：$$P(N=n|Y=y)=\frac{p_N(n)f_{Y|N}(y|n)}{f_Y(y)}=\frac{p_N(n)f_{Y|N}(y|n)}{\sum\limits_{i}p_N(i)f_{Y|N}(y|i)}$$和$$f_{Y|N}(y|n)=\frac{f_Y(y)P(N=n|Y=y)}{p_N(n)}=\frac{f_Y(y)P(N=n|Y=y)}{\int_{-\infty}^{+\infty}f_Y(t)P(N=n|Y=t)dt}$$ 对于事件 $A$ ，关于 $P(A|Y=y)$ 和 $f_{Y|A}(y)$ 具有类似的贝叶斯公式。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-正态随机变量]]></title>
    <url>%2F2017%2F08%2F27%2Fnormal_random_variables%2F</url>
    <content type="text"><![CDATA[说明：全文摘自 Introduction to probability, 2nd Edition 3.3 normal random variables 正态随机变量如果一个连续的随机变量 $X$ 的概率密度具有下列形式， 那么这个随机变量称为正态(normal)的或高斯(Gaussian)的。$$f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^2}{2\sigma^2}}$$其中 $u$ 和 $\sigma$ 是密度函数的两个参数，$\sigma$ 还必须是正数。可以证明，$f_X(x)$ 满足下面的概率密度函数的归一化条件（见本章关于定理的习题）：$$\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{+\infty}e^{\frac{-(x-\mu)^2}{2\sigma^2}}dx=1$$下图是正态分布的密度函数和分布函数 $(\mu=1 \text{ 和 } \sigma^2=1)$ 。 由图可以看出，正态随机变量的概率密度函数是相对于均值 $\mu$ 对称的钟形曲线。当 $x$ 离开 $\mu$ 的时候，概率密度函数的表达式中的项 $e^{\frac{-(x-\mu)^2}{2\sigma^2}}$ 很快地下降。在图中，概率密度函数在区间 $[-1,3]$ 之外非常接近 $0$ 。 正态随机变量的均值和方差可由下列式子给出：$$E[X]=\mu,\quad var(X)=\sigma^2$$由于 $X$ 的概率密度函数相对于 $\mu$ 对称，其均值只能是 $\mu$ 。至于方差的公式，一句定义得：$$var(X)=\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{+\infty}(x-\mu)^2e^{-\frac{(x-\mu)^2}{2\sigma^2}}dx$$将公式中的积分作积分变量替换 $y=\frac{(x-\mu)}{\sigma}$ 以及分布积分得到：$$\begin{eqnarray}var(X) &amp;=&amp; \frac{\sigma^2}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}y^2e^{-\frac{y^2}{2}}dy \&amp;=&amp; \frac{\sigma^2}{\sqrt{2\pi}}(-ye^{-\frac{y^2}{2}})|^{+\infty}{-\infty}+\frac{\sigma^2}{\sqrt{2\pi}}\int{-\infty}^{+\infty}e^{\frac{y^2}{2}}dy \&amp;=&amp; \frac{\sigma^2}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{-\frac{y^2}{2}}dy \&amp;=&amp; \sigma^2\end{eqnarray}$$上面最后的等式，是由于$$\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{-\frac{y^2}{2}}dy=1$$这个公式正好是当 $\mu=0$ 和 $\sigma^2=1$ 的时候的正态随机变量的概率密度函数的归一化条件，在本章习题第14题得以证明，截图如下： 正态随机变量具有若干重要的性质。下面的性质尤其重要，并且将在 第四章 Further Topicson Random Variables 的第一节加以证明。 随机变量的正态性在线性变换之下保持不变设 $X$ 是正态随机变量，其均值为 $\mu$ ，方差为 $\sigma^2$ 。若 $a\ne 0$ 和 $b$ 为两个常数，则随机变量$$Y=aX+b$$仍然是正态随机变量，其均值和方差由下式定义给出：$$E[Y]=a\mu+b,\quad var(Y)=a^2\sigma^2$$ 标准正态随机变量设正态随机变量 $Y$ 的期望为 $0$ ，方差为 $1$，则 $Y$ 称为标准正态随机变量。以 $\Phi$ 记为它的 CDF ：$$\Phi(y)=P(Y\le y)=P(Y&lt; y)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{y}e^{\frac{-t^2}{2}}dt$$通常将它的值列成一个表——标准正态累积分布表（见下表：），这是计算有关正态随机变量的概率的重要的工具。标准正态表的每一项提供了 $\Phi(y)=P(Y\le y)$ 的数值，这里 $Y$ 是一个正态随机变量，这个表中 $y\in [0,4.09]$ 。怎么使用这个表呢？举例，为了查找 $\Phi(1.71)$ 的值，查看关于 $1.7$ 所在的行和 $0.01$ 所在的列，得到 $\Phi(1.71)=0.95637$ 。 注意到下表只列出当 $y &gt; 0， \Phi(y) $ 的值，可以利用标准正态随机变量的概率密度函数的对称性，可将 $y &lt; 0$ 时 $\Phi(y)$ 的值推导出来。例如：$$\begin{eqnarray}\Phi(-0.5) &amp;=&amp; P(Y\le -0.5)=P(Y\ge 0.5)=1-P(Y &lt; 0.5) \&amp;=&amp; 1- \Phi(0.5) = 1-0.69146=0.30854\end{eqnarray}$$可推广$$\forall\ y&gt;0, \Phi(-y)=1-\Phi(y)$$ y +0.00 +0.01 +0.02 +0.03 +0.04 +0.05 +0.06 +0.07 +0.08 +0.09 0.0 0.50000 0.50399 0.50798 0.51197 0.51595 0.51994 0.52392 0.52790 0.53188 0.53586 0.1 0.53983 0.54380 0.54776 0.55172 0.55567 0.55966 0.56360 0.56749 0.57142 0.57535 0.2 0.57926 0.58317 0.58706 0.59095 0.59483 0.59871 0.60257 0.60642 0.61026 0.61409 0.3 0.61791 0.62172 0.62552 0.62930 0.63307 0.63683 0.64058 0.64431 0.64803 0.65173 0.4 0.65542 0.65910 0.66276 0.66640 0.67003 0.67364 0.67724 0.68082 0.68439 0.68793 0.5 0.69146 0.69497 0.69847 0.70194 0.70540 0.70884 0.71226 0.71566 0.71904 0.72240 0.6 0.72575 0.72907 0.73237 0.73565 0.73891 0.74215 0.74537 0.74857 0.75175 0.75490 0.7 0.75804 0.76115 0.76424 0.76730 0.77035 0.77337 0.77637 0.77935 0.78230 0.78524 0.8 0.78814 0.79103 0.79389 0.79673 0.79955 0.80234 0.80511 0.80785 0.81057 0.81327 0.9 0.81594 0.81859 0.82121 0.82381 0.82639 0.82894 0.83147 0.83398 0.83646 0.83891 1.0 0.84134 0.84375 0.84614 0.84849 0.85083 0.85314 0.85543 0.85769 0.85993 0.86214 1.1 0.86433 0.86650 0.86864 0.87076 0.87286 0.87493 0.87698 0.87900 0.88100 0.88298 1.2 0.88493 0.88686 0.88877 0.89065 0.89251 0.89435 0.89617 0.89796 0.89973 0.90147 1.3 0.90320 0.90490 0.90658 0.90824 0.90988 0.91149 0.91308 0.91466 0.91621 0.91774 1.4 0.91924 0.92073 0.92220 0.92364 0.92507 0.92647 0.92785 0.92922 0.93056 0.93189 1.5 0.93319 0.93448 0.93574 0.93699 0.93822 0.93943 0.94062 0.94179 0.94295 0.94408 1.6 0.94520 0.94630 0.94738 0.94845 0.94950 0.95053 0.95154 0.95254 0.95352 0.95449 1.7 0.95543 0.95637 0.95728 0.95818 0.95907 0.95994 0.96080 0.96164 0.96246 0.96327 1.8 0.96407 0.96485 0.96562 0.96638 0.96712 0.96784 0.96856 0.96926 0.96995 0.97062 1.9 0.97128 0.97193 0.97257 0.97320 0.97381 0.97441 0.97500 0.97558 0.97615 0.97670 2.0 0.97725 0.97778 0.97831 0.97882 0.97932 0.97982 0.98030 0.98077 0.98124 0.98169 2.1 0.98214 0.98257 0.98300 0.98341 0.98382 0.98422 0.98461 0.98500 0.98537 0.98574 2.2 0.98610 0.98645 0.98679 0.98713 0.98745 0.98778 0.98809 0.98840 0.98870 0.98899 2.3 0.98928 0.98956 0.98983 0.99010 0.99036 0.99061 0.99086 0.99111 0.99134 0.99158 2.4 0.99180 0.99202 0.99224 0.99245 0.99266 0.99286 0.99305 0.99324 0.99343 0.99361 2.5 0.99379 0.99396 0.99413 0.99430 0.99446 0.99461 0.99477 0.99492 0.99506 0.99520 2.6 0.99534 0.99547 0.99560 0.99573 0.99585 0.99598 0.99609 0.99621 0.99632 0.99643 2.7 0.99653 0.99664 0.99674 0.99683 0.99693 0.99702 0.99711 0.99720 0.99728 0.99736 2.8 0.99744 0.99752 0.99760 0.99767 0.99774 0.99781 0.99788 0.99795 0.99801 0.99807 2.9 0.99813 0.99819 0.99825 0.99831 0.99836 0.99841 0.99846 0.99851 0.99856 0.99861 3.0 0.99865 0.99869 0.99874 0.99878 0.99882 0.99886 0.99889 0.99893 0.99896 0.99900 3.1 0.99903 0.99906 0.99910 0.99913 0.99916 0.99918 0.99921 0.99924 0.99926 0.99929 3.2 0.99931 0.99934 0.99936 0.99938 0.99940 0.99942 0.99944 0.99946 0.99948 0.99950 3.3 0.99952 0.99953 0.99955 0.99957 0.99958 0.99960 0.99961 0.99962 0.99964 0.99965 3.4 0.99966 0.99968 0.99969 0.99970 0.99971 0.99972 0.99973 0.99974 0.99975 0.99976 3.5 0.99977 0.99978 0.99978 0.99979 0.99980 0.99981 0.99981 0.99982 0.99983 0.99983 3.6 0.99984 0.99985 0.99985 0.99986 0.99986 0.99987 0.99987 0.99988 0.99988 0.99989 3.7 0.99989 0.99990 0.99990 0.99990 0.99991 0.99991 0.99992 0.99992 0.99992 0.99992 3.8 0.99993 0.99993 0.99993 0.99994 0.99994 0.99994 0.99994 0.99995 0.99995 0.99995 3.9 0.99995 0.99995 0.99996 0.99996 0.99996 0.99996 0.99996 0.99996 0.99997 0.99997 4.0 0.99997 0.99997 0.99997 0.99997 0.99997 0.99997 0.99998 0.99998 0.99998 0.99998 现在用 $X$ 表示一个均值为 $\mu$ 和方差为 $\sigma^2$ 的正态随机变量。通过定义一个新的随机变量 $Y$ 来(“standardize”)标准化 $X$ ：$$Y=\frac{X-\mu}{\sigma}$$因为 $Y$ 是 $X$ 的线性函数，所以 $Y$ 也是正态随机变量。而且$$E[Y]=\frac{E[X]-u}{\sigma}=0,\quad var(Y)=\frac{var(X)}{\sigma^2}=1$$因此，$Y$ 是一个标准正态随机变量。这个事实可以让我们用 $Y$ 重新定义 $X$ 所表示的事件，然后使用标准正态表去计算。 使用正态分布表的例子某地区的年度降雪量是一个正态随机变量，期望为 $\mu=60$ 英寸，标准差为 $\sigma=20$ 。本年度降雪量至少为 $80$ 英寸的概率有多大？ 记 $X$ 为年降雪量，令$$Y=\frac{X-\mu}{\sigma}=\frac{X-60}{20}$$显然 $Y$ 是标准正态随机变量。$$P(X\ge 80)=P(\frac{X-60}{20} \ge \frac{80-60}{20})=P(Y\ge \frac{80-60}{20})=P(Y\ge 1)=1-\Phi(1)$$其中 $\Phi$ 为标准正态累积分布函数。通过查询上表得到：$\Phi(1)=0.84134$ ，因此$$P(X\ge 80)=1-\Phi(1)=0.15866$$推广这个例子中的方法，得到如下： 正态随机变量的累积分布函数计算对于均值为 $\mu$ 方差为 $\sigma^2$ 的正态随机变量 $X$ ，使用一下步骤： 标准化 $X$ ：先减去 $\mu$ 再除以 $\sigma$ 来获取标准随机变量 $Y$ 。 从标准正态表中读取累积分布函数值：$$P(X\le x)=P(\frac{X-\mu}{\sigma}\le \frac{x-\mu}{\sigma})=P(Y\le \frac{x-\mu}{\sigma})=\Phi(\frac{x-\mu}{\sigma})$$正态随机变量经常使用在信号处理和通信工程中去对噪音和信号失真进行建模。 例3.8 信号侦测二进制信息用信号 $s$ 传输，这个信息要么是 $-1$ 和 $+1$ 。信号在信道传输过程中会伴随一些噪声，噪声满足均值为 $\mu=0$ ，方差为 $\sigma^2$ 的正态分布。接收器会接收到混有噪音的信号 ，如果接收到的值为小于 $0$ ，那么就认为信号为 $-1$ ，如果接收到的值为大于 $0$ ，那么就认为接收到的信号为 $+1$ 。问这种判断方法的误差有多大？ 误差只有出现在下面两种情况： 实际被传输的信号为 $-1$，但是噪声变量 $N$ 值至少是 $1$ ，因此 $s+N=-1+N \ge 0$ 。 实际被传输的信号为 $+1$，但是噪声变量 $N$ 值小于 $-1$ 。因此 $s+N=1+N &lt;0$ 。 因此这种判断方法在情况1下出现误差的概率为：$$\begin{eqnarray}P(N\ge 1) &amp;=&amp; 1-P(N &lt; 1) = 1 - P(N&lt;1)=1-P(\frac{N-\mu}{\sigma}&lt;\frac{1-\mu}{\sigma}) \&amp;=&amp; 1- \Phi(\frac{1-\mu}{\sigma}) \&amp;=&amp; 1-\Phi(\frac{1}{\sigma})\end{eqnarray}$$在第2种情况下出现误差的概率根据正态分布的对称性得到与前一种情况一样。$\Phi(\frac{1}{\sigma})$ 能够从正态分布表得到。例如对于 $\sigma=1$ ，$\Phi(\frac{1}{\sigma})=\Phi(1)=0.84134$ ，所以出现误差的概率为 $0.15864$ 。 正态随机变量扮演一个重要的角色在各种广泛的概率模型中，其原因是在物理、工程和统计中，正态随机变量能够很好地模拟许多独立因素的叠加效应。数学上，关键事实是大量独立同分布的随机变量（不必为正态）的和的分布近似地服从正态分布，而这个事实与各个和项的具体的分布无关的。这个事实就是著名的中心极限定理，这个将在本书第五章详细说明。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-分段常数概率密度函数的均值和方差]]></title>
    <url>%2F2017%2F08%2F27%2Fmean_and_variance_of_a_piecewise_constant_PDF%2F</url>
    <content type="text"><![CDATA[本文摘录自 Introduction to probability, 2nd Edition Example 3.17 Mean and Variance of a Piecewise Constant PDF 假设一个随机变量 $X$ 有分段常数的概率密度函数 $$f_x(x)=\cases{\frac{1}{3}, &amp; if $0 \le x \le 1$, \ \frac{2}{3}, &amp; if $ 1 &lt; x \le 2$, \0, &amp; if otherwise}$$ 考虑事件： $$A_1={\text{X 位于第一个区间 [0,1]}}$$ $$A_2={\text{X 位于第二个区间 (1,2]}}$$ 我们从已知的概率密度函数得到： $$P(A_1)=\int_{0}^{1}f_X(x)dx=\frac{1}{3}, \quad P(A_2)=\int_{1}^{2}f_X(x)dx=\frac{2}{3}$$ 因此，条件均值和 $X$ 的条件二阶矩容易计算，因为相关的概率密度函数 $PDF_S$： $f_{X|A_1}$ 和 $f_{X|A_2}$ 是均匀的，回忆例子3.4得到， 均匀分布在区间 $[a,b]$ 上的的随机变量的均值是：$\frac{(a+b)}{2}$ ，它的二阶矩是 $\frac{(a^2+ab+b^2)}{3}$ ，因此： $$\begin{eqnarray}E[X|A_1]&amp;=&amp;\frac{1}{2},\quad E[X|A_2]&amp;=&amp;\frac{3}{2}\E[X^2|A_1]&amp;=&amp;\frac{1}{3},\quad E[X^2|A_2]&amp;=&amp;\frac{7}{3}\end{eqnarray}$$ 使用总期望定理得到：$$\begin{eqnarray}E[X] &amp;=&amp; P(A_1)E[X|A_1]+P(A_2)E[X|A_2] &amp;=&amp; \frac{1}{3} \cdot \frac{1}{2}+\frac{2}{3}\cdot\frac{3}{2} &amp;=&amp; \frac{7}{6} \E[X^2] &amp;=&amp; P(A_1)E[X^2|A_1]+P(A_2)E[X^2|A_2] &amp;=&amp; \frac{1}{3}\cdot\frac{1}{3}+\frac{2}{3}\cdot\frac{7}{3} &amp;=&amp; \frac{15}{9}\end{eqnarray}$$那么可以得到方差： $$var(x)=E[X^2]-(E[X])^2=\frac{15}{9}-\frac{49}{36}=\frac{11}{36}$$ 注意： 对于计算均值和方差的方法是容易推广到多分段的常数概率密度函数。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-[累积]分布函数CDF]]></title>
    <url>%2F2017%2F08%2F26%2Fcumulative_distribution_function%2F</url>
    <content type="text"><![CDATA[说明：全文摘自 Introduction to probability, 2nd Edition 分布函数我们分别用概率质量函数 PMF(Probability Mass Function) 和概率密度函数 PDF(Probability Density Function) 来刻画随机变量 $X$ 的取值规律。现在希望用一个统一的数学工具去刻画随机变量的取值规律。 ​分布函数（用记号 CDF 表示简称）就能完成这个任务。 $X$ 的 CDF 是一个 $x$ 的函数，对每一个 $x$ ，$F_X(x)$ 定义为 $P(X\le x)$ 。特别地，当 $X$ 为离散或连续的情况下：$$F_X(x)=P(X\le x)=\cases{\sum\limits_{k\le x}p_X(k), \text{若 $X$ 是离散的}\\int_{-\infty}^{x}f_X(x)dt, \text{若 $X$ 是连续的 }}$$分布函数又称为累积分布函数（cumulative distribution function），累积意味着 $F_X(x)$ 将 $X$ 取值的概率由 $-\infty\rightarrow x$。 在一个概率模型中，随机变量可以有不同的类型，可以是离散的，也可以是连续的，甚至可以是既非离散的也非连续的。但不管是什么类型的随机变量，它们有一个共同的特征，即都有一个分布函数，这是因为 ${X\le x}$ 是一个随机事件，这些事件的概率形成概率分布。今后，凡是通过 PMF\PDF\CDF刻画事件 ${X\le x}$ 概率的，都称为随机变量 $X$ 的概率律。因此离散情况下的分布列，连续情况下的概率密度函数以及一般情况下的分布函数都是相应的随机变量的概率律。 下图分别给出不同的离散随机变量和连续随机变量的 CDF 的一些说明。从这些图像以及 CDF 的定义，可以得到 CDF 的某些性质。 上图这些离散随机变量的 CDF ，通过随机变量的概率质量函数（PMF）可求得相应的分布函数：$$F_X(x)=P(X\le x)=\sum\limits_{k\le x}p_{X}(k)$$这个函数是一个阶梯函数，在具有正概率的那些点上具有跳跃。在跳跃点上， $F_X(x)$ 取较大的那个值，即 $F_X(x)$ 保持右连续。 上图的这些连续随机变量的 $CDF$ 。通过随机变量的概率密度函数（PDF）可求得相应的分布函数：$$F_X(x)=P(X\le x)=\int_{-\infty}^{+\infty}f_X(t)dt$$概率密度函数 $f_X(x)$ 可由 CDF 经求微分得到：$$f_X(x)=\frac{dF_X(x)}{dx}(x)$$对于连续随机变量，CDF 是连续的 CDF 的性质假设 $X$ 的 CDF $F_X(x)$ 是由下式定义的 ：$$F_X(x)=P(X\le x), \forall x$$并且 $F_X(x)$ 具有下列性质： $F_X(x)$ 是 $x$ 的单调非减函数：若 $x\le y$ ，则 $F_X(x)\le F_X(y)$ 。 当 $x\rightarrow -\infty$ 的时候，则 $F_X(x)\rightarrow 0$ ，当 $x\rightarrow +\infty$ ，则 $F_X(x)\rightarrow 1$ 。 当 $X$ 是离散随机变量的时候， $F_X(x)$ 为阶梯函数。 当 $X$ 是连续随机变量的时候， $F_X(x)$ 为 $x$ 的连续函数。 当 $X$ 是离散随机变量并且取整数数值的时候，分布函数和概率质量函数（PMF）可以利用求和或差分互求：$$F_X(k)=\sum\limits_{i=-\infty}^{k}p_X(i)\p_X(k)=P(X\le k)-P(X\le k-1)=F_X(k)-F_X(k-1)$$其中 $k$ 可以是任意整数。 当 $X$ 是连续随机变量的时候，分布函数与概率密度函数可以利用积分和微分互求：$$F_X(x)=\int_{-\infty}^{x}f_X(t)dt,\quad f_X(x)=\frac{dF_X}{dx}(x)$$(第二个等式只在分布函数可微的那些点上成立) 有时候为了计算随机变量的概率质量函数或概率密度函数，首先计算随机变量的分布函数会更方便些。在连续随机变量的情况下，将在4.1节系统地介绍用该方法求随机变量的函数的分布。下面是一个离散随机变量的计算例子。 例子几个随机变量的最大值你参加某种测试，按规定三次测试的最高成绩作为你的最后成绩，设 $X=max{X_1,X_2,X_3}$ ，其中 $X_1,X_2,X_3$ 是三次测试成绩，$X$ 是你的最后的成绩。假设你的每次测试成绩是 1 分到 10 分之间，并且 $P(X=i)=\frac{1}{10}, i=1,…,10$ 。现在求最终成绩 $X$ 的概率质量函数。 采用间接方法求分布函数。首先计算 $X$ 的 CDF，然后通过$$p_X(k)=F_X(k)-F_X(k-1), i=1,\ldots,10$$得到 $X$ 的概率质量函数。对于 $F_X(k)$ ，得到：$$\begin{eqnarray}F_X(k) &amp;=&amp; P(X\le k) \&amp;=&amp; P(X_1\le k, X_2\le k, X_3\le k) \&amp;=&amp; P(X_1\le k)P(X_2\le k)P(X_3\le k) \&amp;=&amp; (\frac{k}{10})^3\end{eqnarray}$$此处第三个等式是由事件 ${X_1\le k},{X_2\le k},{X_3\le k}$ 相互独立所致。这样 $X$ 的概率质量函数为：$$p_X(k)=(\frac{k}{10})^3-(\frac{k-1}{10})^3, k=1,\ldots,10$$本例的方法可推广到 $n$ 个随机变量 $X_1,\ldots,X_n$ 的情况。如果对每一个 $x$ ，事件 ${X_1\le x},\ldots, {X_n\le x}$ 相互独立，则 $X=max{X_1,\ldots,X_n}$ 的 CDF 为：$$F(x)=F_{X_1}(x)\cdots F_{X_n}(x)$$利用这个公式，在离散情况下通过差分可得到 $P_X(x)$ ，在连续情况下通过微分可得到 $f_X(x)$ 。 距离的分布函数和概率密度函数习题3.5 ：按照均匀分布律，在一个三角形中随机的选取一个点，设已知三角形的高，求这个点到底边的距离 $X$ 的分布函数和概率密度函数。 用 $b$ 表示底的长度，$h$ 表示三角形的高度，$A=\frac{bh}{2}$ 表示三角形的面积。随机地在三角形内选取一个点，然后画一条平行于三角形底边的辅助直线，用 $A_x$ 表示由这条辅助线构成的小三角形的面积，那么这个小三角形的高度即 $h-x$ ，它的底边按比例求得：$b\frac{h-x}{h}$ ，因此 $A_x=\frac{b(h-x)^2}{2h}$ 。对于 $x\in [0,h]$ ，得到：$$F_X(x)=P(0&lt; x \le x)=1-P(X&gt;x)=1-\frac{A_x}{A}=1-\frac{\frac{b(h-x)^2}{2h}}{\frac{bh}{2}}=1-(\frac{h-x}{h})^2$$当 $x&lt;0,$ 那么 $F_X(x)=0$ ; 当 $x&gt;h,$ 那么 $F_X(x)=1$ 。 概率密度函数可以对累积分布函数 CDF 进行求微分得到：$$f_X(x)=\frac{dF_X}{dx}(x)=\cases{\frac{2(h-x)}{h^2}, &amp; 当 $0\le x \le h$\0, &amp; 其他情况}$$ 等待时间习题3.6 ：Jane去银行取款，有1个或0个顾客在她前面，这两种情况是等可能的。已知一个顾客的服务时间是一个指数随机变量，参数为 $\lambda$ 。那么Jane所等待的时间分布函数是？ 用 $X$ 表示等待的时间，用 $Y$ 表示在Jane之前顾客的数量。于是得到：$\forall x &lt;0, F_X(x)=0$ ，其他情况下，根据题意得：$$F_X(x)=P(X\le x)=\frac{1}{2}P(X\le x| Y=0)+\frac{1}{2}P(X\le x|Y=1)$$又因为$$P(X\le x|Y=0)=1,\quad P(X\le x|Y=1)=1-e^{-\lambda x}$$得到$$F_X(x)=\cases{\frac{1}{2}(2-e^{-\lambda x}), &amp; if $x \ge 0$ \0, &amp; 其他情况}$$注意：这个累积分布函数 CDF 在 $x=0$ 处连续，随机变量 $X$ 既不是离散的也不是连续的。 投飞标游戏Alvin在进行飞镖游戏，飞镖的靶是一块半径为 r 的圆板。记 $X$ 为飞镖的落点到靶心的距离。假设落点在靶板上均匀地分布。 (a) 求出 $X$ 的概率密度函数、均值和方差。 $X$ 的累积分布函数比较容易求得：$$F_X(x)=\cases{P(X\le x)=\frac{\pi x^2}{\pi r^2}=(\frac{x}{r})^2, &amp; if $\forall x\in [0,r]$\0, &amp; if $x &lt; 0$\1, &amp; if $x&gt;r$}$$通过微分，得到概率密度函数：$$f_X(x)=\cases{\frac{2x}{r^2}, &amp; if $0\le x\le r$\0, &amp; otherwise}$$进而通过积分得到：$$E[X]=\int_{0}^{r}\frac{2x^2}{r^2}dx=\frac{2r}{3}\E[X^2]=\int_{0}{r}\frac{2x^3}{r^2}dx=\frac{r^2}{2}\var(X)=E[X^2]-(E[X])^2=\frac{r^2}{2}-\frac{4r^2}{9}=\frac{r^2}{18}$$(b) 靶上画出了一个半径为 $t$ 的同心圆。若 $X\le t$ ，Alvin的得分为 $S=\frac{1}{X}$ ，其他情况 $S=0$ 。求出 $S$ 的分布函数。 $S$ 是不是连续随机变量？ 由题意得：当且仅当 $X\le t$ ，Alvin 获得一个介于 $[\frac{1}{t}, +\infty)$ 的分数s，其它情况下，他的得分为 0 。因此：$$F_S(s)=\cases{0, \quad \text{if $s&lt;0$}\P(S\le s)=1-P(X\le t), \quad \text{if $0\le s\le \frac{1}{t}$ (即Alvin击中了内圆之外)} \P(S\le s)=P(X\le t)P(S\le s|X\le t)+P(X&gt;t)P(S\le s|X&gt;t) \quad \text{if $s &gt; \frac{1}{t}$}}$$根据题意，得到：$$P(X\le t)=\frac{t^2}{r^2},\quad P(X&gt;t)=1-\frac{t^2}{r^2}$$而且因为当 $X&gt;t, S=0$ ， 所以 $P(S\le s|X&gt; t)=1$ 。 进而得到：$$P(S\le s| X\le t)=P(\frac{1}{X}\le s|X\le t)=P(\frac{1}{s}\le X|X\le t) = \frac{P(\frac{1}{s}\le X \le t)}{P(X\le t)} =\frac{\frac{\pi t^2 -\pi(\frac{1}{s})^2}{\pi r^2}}{\frac{\pi t^2}{\pi r^2}}=1-\frac{1}{s^2t^2}$$最后得到：$$F_S(s)=\cases{ 0, &amp; \text{if }s&lt;0 \ 1-\frac{t^2}{r^2}, &amp; \text{if } 0\le s \le \frac{1}{t}\ 1-\frac{1}{s^2r^2} &amp; \text{if } \frac{1}{t}&lt;s}$$因为 $F_S(s)$ 在 $s=0$ 处不连续，所以随机变量 $S$ 不是连续的。 几何和指数随机变量的分布函数由于分布函数对一切随机变量都适用，可以利用它来探索离散和连续随机变量之间的关系。特别地，此处讨论几何随机变量和指数随机变量之间的关系。 设 $X$ 是一个几何随机变量，其参数为 $p$ ，即 $X$ 是在伯努利独立试验序列中直到第一次成功所需要的试验次数，而伯努利试验的参数为 $p$ 。这样对于 $k=1,2\cdots,$ 得到 $P(X=k)=p(1-p)^{k-1}$ ，而 $X$ 的 CDF 为：$$F_{geo}(n)=\sum\limits_{k=1}^{n}p(1-p)^{k-1}=p\frac{1-(1-p)^n}{1-(1-p)}=1-(1-p)^n,\quad n=1,2,\cdots$$现在设 $X$ 是一个指数随机变量，其参数 $\lambda&gt;0$ 。其 CDF 是$$F_{exp}(x)=P(X\le x)=0,\quad x\le 0\F_{exp}(x)=\int_{0}^{x}\lambda e^{-\lambda t}dt=-e^{-\lambda t}|^{x}{0}=1-e^{-\lambda x},\quad x&gt;0$$现在比较两个分布函数，令 $\delta=\frac{-ln(1-p)}{\lambda}\rightarrow \delta\lambda=-ln(1 - p)$ ，这样得到：$$e^{-\lambda\delta}=1-p \quad (*)$$那么，将 $(*)​$ 代入 $F{geo}(n)​$ 得：$1-(e^{-\lambda\delta})^n=1-e^{-n\lambda\delta}​$ ，而分布函数 $F_{exp}​$ 在 $x=n\delta​$ 处为： $1-e^{-\lambda n\delta}=1-e^{-n\lambda\delta}​$ 是与 $F_{geo}​$ 在 $n​$ 处相等的，$n=1,2,\cdots​$ ，即：$$F_{exp}(n\delta)=F_{geo}(n)=, n=1,2,\cdots$$现在假定以很快的速度抛掷一枚不均匀的硬币 (每 $\delta$ 秒抛掷一次，$\delta \ll 1$)，每次抛掷，正面向上的概率为 $p=1-e^{-\lambda\delta}$ 。这样第一次得到正面向上所抛掷的次数为 $X$ ，第一次得到正面向上的时刻为 $X\delta$ ，$X\delta$ 与参数为 $\lambda$ 的指数随机变量十分接近，这只需看它们的分布函数即可（看下图）。这在本书第六章讨论伯努利和泊松分布过程的时候，这种关系显得特别重要。 几何随机变量和指数随机变量的分布函数之间的关系。图中离散分布函数为 $X\delta$ 的分布函数，$X$ 是参数为 $p=1-e^{-\lambda x}$ 的几何随机变量。当 $\delta\rightarrow 0$ 时，$X\delta$ 的分布函数趋于指数分布函数 $1-e^{-\lambda x}$ 。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-均匀随机变量的均值和方差]]></title>
    <url>%2F2017%2F08%2F26%2Fmean_and_variance_of_uniform_random_variable%2F</url>
    <content type="text"><![CDATA[说明：全文摘自Introduction to probability, 2nd Edition 均匀分布的离散随机变量按照定义，离散均匀随机变量的取值范围由相邻的整数所组成的有限集合，而取每个整数的概率都是相等的。这样它的分布列： $$p_X(k)=\cases{\frac{1}{b-a+1}, &amp; if k=a, a+1, … ,b\0, &amp; otherwise}$$ 其中$a,b$ 是两个整数，作为随机变量的值域的两个端点，$a&lt;b$。由于它的概率函数相对于(a+b)/2 是对称的，所以其均值为： $$E[X]=\frac{a+b}{2}$$ 为计算$X$的方差，先考虑a=1和b=n的简单情况。利用归纳法可以证明： $$E[X^2]=\frac{1}{n}\sum\limits_{k=1}^{n}k^2=\frac{1}{6}(n+1)(2n+1)$$ （具体证明过程留作习题）。这样利用一、二阶矩，可得到$X$的方差$$\begin{eqnarray*}var(X)&amp;=&amp; E[X^2]-(E[X])^2\&amp;=&amp;\frac{1}{6}(n+1)(2n+1)-\frac{1}{4}(n+1)^2\&amp;=&amp;\frac{n^2-1}{12}\end{eqnarray*}$$对于 $a$ 和 $b$ 的一般情况，实际上在区间 $[a,b]$上的均匀分布与在区间 $[1,b-a+1]$ 上的分布之间的差异，只是一个分布是另外一个分布的偏移，因此两者具有相同的方差（此处区间 $[a,b]$ 是指处于 $a$ 和 $b$ 之间的整数的集合）。这样在一般的情况下，$X$ 的方差只需将简单的情况下公式中的 $n$ 替换成 $b-a+1$ ，即： $$var(X)=\frac{(b-a+1)^2-1}{12}=\frac{(b-a)(b-a+2)}{12}$$ 均匀分布的连续随机变量摘录自 Example 3.4. Mean and Variance of the Uniform Random Variable 设随机变量 $X$ 的分布为 $[a,b]$ 上的均匀分布，得到：$$\begin{eqnarray*}E[X] &amp;=&amp; \int_{-\infty}^{+\infty}xf_X(x)dx \&amp;=&amp; \int_{a}^{b}x\frac{1}{b-a}dx \&amp;=&amp; \frac{1}{b-a}\cdot \frac{1}{2}x^2|^{b}_{a} \&amp;=&amp; \frac{1}{b-a}\cdot\frac{b^2-a^2}{2} \&amp;=&amp; \frac{b+a}{2}\end{eqnarray*}$$这个期望值刚好等于 $PDF$ 的对称中心 $\frac{b+a}{2}$ 。 为求得方差，先计算 $X$ 的二阶矩：$$\begin{eqnarray*}E[X^2] &amp;=&amp; \int_{a}^{b}\frac{x^2}{b-a}dx \&amp;=&amp; \frac{1}{b-a}\cdot\int_{a}{b}x^2dx \&amp;=&amp; \frac{1}{b-a}\cdot \frac{1}{3}x^3|_{a}^{b} \&amp;=&amp; \frac{b^3-a^3}{3(b-a)} \&amp;=&amp; \frac{a^2+ab+b^2}{3} \\end{eqnarray*}$$这样随机变量 $X$ 的方差为：$$var(X)=E[X^2]-(E[X])^2=\frac{a^2+ab+b^2}{3}-\frac{(a+b)^2}{4}=\frac{(b-a)^2}{12}$$]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-样本均值的期望方差与模拟的方法估计概率]]></title>
    <url>%2F2017%2F08%2F25%2Fmean_and_variance_of_sample_and_estimating_probability_by_simulation%2F</url>
    <content type="text"><![CDATA[样本均值的期望方差摘录自：Introduction to probability, 2nd Edition Example 2.21. Mean and Variance of the Sample Mean 我们希望估计总统的支持率。为此，我们随机地选取n个选民，询问他们的看法。令 $x_i​$ 表示 $i​$ 个被问的选民的态度： $$X_i = \cases{1, \text{若第 $i$ 个被问的选民支持总统}\0, \text{若第 $i$ 个被问的选民不支持总统}}$$ 假设$X_1,\ldots, X_n$为独立同分布的伯努利随机变量，其均值为 $p$，方差为 $p(1-p)$ 。此处我们将 $p$ 认为选民支持总统的概率，并且将对调查得到的回应进行平均处理，计算样本均值 $S_n$ ，把 $S_n$ 定义为 $$S_n=\frac{X_1+ \ldots + X_n}{n}$$ 因此，随机变量 $S_n$ 是对n个选民抽样的支持率。 由于 $S_n$ 是 $X_1, \ldots, X_n$ 的一个线性函数，我们利用均值的线性关系得到， $E[S_n]=\sum\limits_{i=1}^{n} E[\frac{X_i}{n}]=\sum\limits_{i=1}^{n}\frac{1}{n}E[X_i]= \sum\limits_{i=1}^{n}\frac{1}{n}p=p=E[X]$ 再利用$X_1,\ldots, X_n$ 的独立性，可以得到： $$var(S_n) = \sum\limits_{i=1}^{n}var(\frac{X_i}{n}) = \sum\limits_{i=1}^{n}\frac{1}{n^2}var(X_i) = \frac{p(1-p)}{n}$$ 样本均值为 $S_n$ 被认为是支持率很好的估计，这是因为它的期望值刚好是 $p$。然后反映精度的方差随着样本大小的$n$ 增大的时候，变得越来越小。 注意，上例中即使 $X_i$ 不是伯努利随机变量，结论 $$var(S_n) = \frac{var(X)}{n}$$ 仍然成立，只要 $X_i$ 之间相互独立，毕竟期望和方差与 $i$ 无关。因此，随着样本大小增加，样本均值仍然是随机变量的均值的一个很好的估计。我们将在第5章再详细讨论样本均值的这些属性，并且与大数定律结合起来。 模拟的方法估计概率摘录自：Introduction to probability, 2nd Edition Example 2.22. Estimating Probabilities by Simulation 在许多实际问题中，有时候计算一个事件的概率是十分困难的，然后我们可以用物理方法或计算机方法重复地进行试验，这些试验结果可以显示事件是否发生。利用这种模拟方法可以以很高的精度计算某事件的概率。可以独立地模拟试验 $n$ 次，并且记录 $n$ 次试验中的 $A$ 发生的次数 $m$，用 $\frac{m}{n}$ 去近似概率 $P(A)$。例如在抛掷硬币试验中，计算概率 $p=P$ （出现正面），独立地抛掷 $n$ 次，用比值（记录中出现的正面次数除以试验总次数n）去逼近概率$p$。 为计算这种方法的精确度，考虑 $n$ 个独立同分布的伯努利随机变量 $X_1,\ldots, X_n$，每个 $X_i$ 的概率质量函数： $$p_{X_i}(k)=\cases{P(A), if\ k=1\1-P(A), if\ k=0}$$ 在模拟环境中，$X_i$ 有关于第 $i$ 次试验的结果，如果第 $i$ 次的试验结果属于 $A$ ，那么 $X_i$ 取值为1，那么随机变量的取值（$$X=\frac{X_1+X_2+\ldots+X_n}{n}$$） 就是概率 $P(A)$ 的估计值。由例 2.21 的结果知，$X$ 的期望为 $P(A)$，方差为 $\frac{P(A)(1-P(A))}{n}$。故 $n$ 很大时，$X$提供了 $P(A)$ 的精确的估计。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-两个信封的悖论]]></title>
    <url>%2F2017%2F08%2F24%2Fthe_two-envelopes_paradox%2F</url>
    <content type="text"><![CDATA[本文摘录自：Introduction to probability, 2nd Edition Example 2.18. The Two-Envelopes Paradox. 这是一个广泛兴趣的智力测验问题，它涉及有关条件期望的数学要点。 主持人给你两个信封，并且告诉你两个信封里有现金，其中一个信封里的钱是另一个信封里的$m$倍（$m&gt;1$且是一个整数）。当你打开一个信封的时候，看到信封里面的钱数以后，你有两个选择，一是收下这个信封里的钱作为你的奖金，二是放弃这个信封的钱，选择另一个信封里的钱作为你的奖金。那么有什么好的策略可使你拿到较多的奖金呢？ 下面有一条推理，它证明应该转向选择第二个信封的。用A表示你打开的信封，B 是你可能换的信封，$x$和$y$分别表示信封A和B中的钱。论证如下：由于要么$y={x\over m}$ 要么 $y=mx$ ，而且两种情况发生的概率都是${1\over 2}$，因此给定的 $x,y$ 的期望值为： $$\frac{1}{2}\cdot \frac{x}{m} + \frac{1}{2}\cdot mx= \frac{1}{2}(\frac{1}{m}+m)x=\frac{1+m^2}{2m}x&gt;x$$ 这样，你应该总是转向信封B。当你随机选择到B的时候，由于同样的理由，又得到转回到A。这样陷入了矛盾之中，因为按照这个推理是不管选择到信封是哪一个都要选择另外一个信封作为奖金。 其实在这个悖论中，有两个假设是有瑕疵的： 对于两个信封内的钱，你是无法预先知道的，当给定$x$的值以后，你以为知道的就是$y=\frac{x}{m}$或者$y=mx$ 。而且没有理由哪一种情况更有可能。 用随机变量$X$和$Y$表示两个信封内的钱，若$E[Y|X=x]&gt;x, x\in \forall$ 成立，那么总是转向选择另一个信封能得到更多的期望奖金。 让我们仔细审查这两个假设： 假设1是有瑕疵的，因为它依赖他一个不完整的确定的概率模型。事实上，各种模型的事件中，包含$X$和$Y$的可能取值，都必须有一个确定概率。有了这样$X$ $Y$的概率信息，$X$的值可能会揭示$Y$取值的大量信息。例如，假设下面这个概率模型：某个人选择 $Z$ 元放在一个信封内，$Z$ 的取值范围为 $[\underline{z}, \overline{z}]$ 的整数，并且服从某个概率分布（distribution ），而在另一个信封内存入$mZ$ 的钱。然后，你以等概率从两个信封中随机地抽取一个信封，看里边的钱数 $X$ 的值。当 $X$ 的值比 $Z$ 的上限 $\overline{z}$ 大的时候，你可以肯定你拿到的信封里的钱数是比较多的，因此你不必换信封。若你拿到的钱数等于 $\underline{z}$ 的值，那么你可以肯定另一个信封中的钱是比 $\underline{z}$ 多，因此你必须换信封。大致上可以这么说，如果你知道X的值域和X的值的可能性，你就能判断在信封A中的钱数X是相对比较小的还是比较大的，然后相应的做出选择。 从数学上，采用一个准确的概率模型，我们一定能够找到 $X$ 和 $Y$ 的联合概率函数。$X$ 和 $Y$ 的联合概率分可由两个信封中的钱的最小者 $Z$ 的分布律为 $P_Z$，则对一切 $z$，$p_{X,Y}(mz,z)=p_{X,Y}(z,mz)=\frac{1}{2}p_Z(z)$ ，对于不具有 $(mz, z)$ 或 $(z,mz)$ 的形式的 $(x,y)$ ，$p_{X,Y}(x,y)=0$。 当 $p_{X,Y}(x,y)$ 给定以后，我们可以用这个换信封的规则：换信封的充要条件为 $E[Y|X=x]&gt;x$ ，按照这个规则可以确定换或者不换信封。 现在的问题是：按照上诉的模型和转换规则是否可以按照某些x的值，转换信封，而另一些x的值不能换？一般情况下是可以的，例如早先局出的 $Z$ 的值域为有界集合的情况，就可以实现这样的转换规则。然而，下面的一个稍显怪癖的例子，使得你总是换信封： ​抛掷一枚均匀的硬币，直到出现正面为止。记 $N$ 为抛掷硬币的次数。此时你将 $m^N$ 元放进一个信封内，将 $m^{N-1}$ 元放进另一个信封内。令 $X$ 是你打开的那个信封（信封A）内的钱数， $Y$ 是令一个信封（信封 B）内的钱数。现在假定 A 中只有一元钱，显然 B 中含有 $m$元， 你应该换信封。当 A 内含有 $m^n$ 元的时候，B 中或者含有 $m^{n-1}$ 元钱或含有 $m^{n+1}$ 元钱。由于 $N$ 具有几何分布列， 我们有： $$\frac{P(Y=m^{m+1} | X=m^n)}{P(Y=m^{m-1} | X=m^n)} = \frac{P(Y=m^{m+1}, X=m^n)}{P(Y=m^{m-1}, X=m^n)}=\frac{P(N=n+1)}{P(N=n)}=\frac{1}{2}$$ 这样我们有: $$P(Y=m^{m-1}|X=m^n)=\frac{2}{3}，P(Y=m^{m+1}|X=m^n)=\frac{1}{3}$$ $$E{信封B中的钱数|x=m^n}=\frac{2}{3}m^{n-1}+\frac{1}{3}m^{n+1}=\frac{2+m^2}{3m}\cdot m^n$$ $\frac{2+m^2}{3m}&gt;1$ 的充要条件是 $m^2-3m + 2 &gt; 0$ 或 $(m-1)(m-2)&gt;0$。 若 $m&gt;2$， 则： $$E[信封 B 中的钱数 | X=m^n]&gt;m^n$$ 这样，为了获得最大的期望奖金，你应该转向信封 $B$。在这个例子中，由于对一切 $x$ 的值， $$E[Y|X=x]&gt;x$$ 你选择B。直观地看，利用全期望定理，应该有结论 $E[Y]&gt;E[X]$ 。然而，由于 $X$ 和 $Y$ 具有相同的概率函数（PMFs，probability mass function (PMF) ），结论$E[Y]&gt;E[X]$ 不可能成立。实际上，我们有： $$E[Y]=E[X]=\infty$$ 这个结论与 $E[Y|X=x]&gt;x, \forall x$ 并不矛盾。当 $E[Y]=E[X]=\infty$ 的情况下，利用关系式 $E[Y|X=x] &gt; x$ 而转换信封并不能够改进平均奖金。从而解决了悖论问题。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-几何随机变量的均值和方差]]></title>
    <url>%2F2017%2F08%2F23%2Fmean_and_variance_of_the_geometric%2F</url>
    <content type="text"><![CDATA[本文摘录自 Introduction to probability, 2nd Edition Example 2.17 mean_and_variance_of_the_geometric 你一次又一次地写一个计算机软件，每写一次都有一个成功的概率 $p$ 。假设每次成功与否与以前的历史记录相互独立。令 $X$ 是你一直到成功为止所写的次数（最后一次你成功了！） $X$ 的期望和方差是多少？ 由于 $X$ 是一个几何随机变量，那么我们视 $X$ 为几何随机变量，概率质量函数是： $$p_X(k)=(1-p)^{k-1}p, k = 1, 2, ….$$ 那么 $X$ 的方差和均值为： $$E[X] = \sum\limits_{k=1}^{\infty}k(1-p)^{k-1}p, var(X)=\sum\limits_{k=1}^{\infty}(k-E[X])^2(1-p)^{k-1}p$$ 但是衡量这些无限和有点麻烦。我们利用全期望定理进行计算。记 $A_1={X=1}={\text{first try is a success}}, A_2={X&gt;1}={\text{first try is a failure}}$。 如果第一次就成功，得到 $X=1​$ ，且 $$E[X|X=1]=\sum\limits_{}^{}xp_{X|X=1}=1p_{1|X=1}=1$$ 如果首次尝试失败 ( X &gt; 1)，我们将浪费一次尝试，我们重新开始，由于是在第一次失败的条件下，那么表示尝试次数的 $X$ 的均值一定是大于1的，剩余尝试的期望即 $E[X]$ 。 $$E[X|X&gt;1] = E[X+1] = 1+E[X]$$ 因此，由全期望定理： $$\begin{eqnarray}E[X] &amp;=&amp; P[X=1]E[X|X=1]+P(X&gt;1)E[X|X&gt;1] \&amp;=&amp; p + (1 - p) (1+E[X])\end{eqnarray}$$从而可以得到： $$E[X]=\frac{1}{p}$$ 相似的推理，我们也得到 $$E[X^2|X=1]=1,\quad E[X^2|X&gt;1]=E[(1+X)^2]=1+2E[X]+E[X^2]$$ 因此， $$E[X^2]=p+(1-p)(1+2E[X]+E[X^2])$$ 联合 $E[X]=\frac{1}{p}$ 得到： $$E[X^2]=\frac{2}{p^2}-\frac{1}{p}$$ 总结： $$var(X)=E[X^2]-(E[X])^2= \frac{2}{p^2}-\frac{1}{p}-\frac{1}{p^2}=\frac{1-p}{p^2}$$]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Trees describe the sample space]]></title>
    <url>%2F2017%2F08%2F15%2Ftrees_describe_the_sample_space%2F</url>
    <content type="text"><![CDATA[This note comes from Introduction to Probability, 2nd Edition Example 1.9 Rada DetectionIf an aircraft is present in a certain area, a radar detects it and generates an alarm signal with probability 0.99. If an aircraf is not present. the radar generates a (false) alarm, with probability 0.10. We assume that an aircraft is present with probability 0.05. What is the probability of no aircraf presence and a false alarm? What is the probability of aircraf presence and no detection? $A$ sequential representation of the experiment is appropriate here, as shown in Fig. 1.9. Let $A$ and $B$ be the events $A = {an\ aircraft\ is\ present}$, $B = {the\ radar\ generates\ an\ alarm} $, and consider also their complements $A^c={an\ aircraft\ is\ not present}$$，$$B^c={the\ radar\ does\ not\ generate\ an\ alarm}$。 The given probabilities are recorded along the corresponding branches of the tree describing the sample space, as shown in Fig. 1.8. Each event of interest corresponds to a leaf of the tree and its probability is equal to the product of the probabilities associated with the branches in a path from the root to the corresponding leaf. The desired probabilities of false alarm and missed detection are $$P(false\ alarm) = P(A^c ∩ B) = P(A^c)P(B | A^c) = 0.95 · 0.10 = 0.095$$，$$P(missed\ detection) = P(A ∩ B^c) = P(A)P(B^c | A) = 0.05 · 0.01 = 0.0005$$. Extending the preceding example, we have a general rule for calculating various probabilities in conjunction with a tree-based sequential description of an experiment. In particular: (a) We set up the tree so that an event of interest is associated with a leaf. We view the occurrence of the event as a sequence of steps, namely, the traversals of the branches along the path from the root to the leaf. (b) We record the conditional probabilities associated with the branches of the tree. (c) We obtain the probability of a leaf by multiplying the probabilities recorded along the corresponding path of the tree. multiplication ruleIn mathematical terms, we are dealing with an event A which occurs if and only if each one of several events $A_1, . . . , A_n$ has occurred, i.e., $A = A_1 ∩ A_2 ∩ · · · ∩ A_n$. The occurrence of $A$ is viewed as an occurrence of $A_1$, followed by the occurrence of $A_2$, then of $A_3$, etc, and it is visualized as a path on the tree with $n$ branches, corresponding to the events $A_1, . . . , A_n$. The probability of $A$ is given by the following rule (see also Fig. 1.9). The multiplication rule can be verified by writing$$P(\cap^n_{i=1} A_i)=P(A_1)\frac{P(A_1\cap A_2)}{P(A_1)}\frac{P(A_1\cap A_2\cap A_3)}{P(A_1\cap A_2)}\cdots\frac{P(\cap_{i=1}^n A_i)}{P(\cap^{n-1}_{i=1} A_i)}$$, and by using the definition of conditional probability to rewrite the right-hand side above as $$P(A_1)P(A_2|A_1)P(A_3|A_1\cap A_2)\cdots P(A_N|\cap^{n-1}_{i=1} A_i)$$. The intersection event $A = A_1∩A_2∩· · ·∩A_n$ is associated with a path on the tree of a sequential description of the experiment. We associate the branches of this path with the events $A_1, . . . , A_n$, and we record next to the branches the corresponding conditional probabilities. The final node of the path corresponds to the intersection event $A$, and its probability is obtained by multiplying the conditional probabilities recorded along the branches of the path $$P(A_1\cap A_2\cap\cdots\cap A_3)=P(A_1)P(A_2|A_1)\cdots P(A_n|A_1\cap A_2\cdots \cap A_{n-1}).$$ Note that any intermediate node along the path also corresponds to some intersection event and its probability is obtained by multiplying the corresponding conditional probabilities up to that node. For example, the event $A_1 ∩ A_2 ∩ A_3$ corresponds to the node shown in the figure, and its probability is $$P(A_1\cap A_2\cap A_3)=P(A_1)P(A_2|A_1)P(A_3|A_1\cap A_2).$$ For the case of just two events, A1 and A2, the multiplication rule is simply the definition of conditional probability.]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[期望定义的由来]]></title>
    <url>%2F2017%2F08%2F14%2Fdefinition_of_expectation%2F</url>
    <content type="text"><![CDATA[前言我们很早就学到某个随机变量$X$的期望就是$X$的所有取值相对于它的概率的加权平均， 但是这是为什么呢？很多人都有疑问，后来看了MIT教授写的 Introduction to Probability, 2nd Edition 书，豁然开朗，以此小计一篇。 例子我们先以一个例子入手：假设你有机会转动一个幸运轮许多次，每次转动后幸运轮都会出现一个数字（数字即奖金数），不妨设为$m_i, i$表示第$i$次转动幸运轮，而且这些数字出现的概率分别为$p_i$，那么每次你期望得到的奖金数是多少呢？此处“每次”和”期望“都是一些不确定的词汇，我们来一一明确它们的含义。 假设一共转动幸运轮$k$次，而其中有$k_i$次转动的结果为$m_i$。你所得到的总钱数为：$\sum\limits_{i=1}^{n}m_i k_i$，那么每次转动的钱数为$M=\frac{\sum\limits_{i=1}^{n}{m_i k_i}}{k}$，现在假设$k$是一个很大的数字，那么我们可以假设概率与频率相互接近。即： $$\frac{k_i}{k}\approx p_i, i=1,\ldots,n$$ 这样你每次转动幸运轮所期望得到的钱数是： $$M=\frac{\sum\limits_{i=1}^{n}m_i k_i}{k}\approx \sum\limits_{i=1}^{n}m_i p_i$$ 有这个例子启发，才有了下面的定义。 期望的定义设随机变量$X$的概率函数是$p_X$，那么$X$的期望值（也称期望或均值）为： $$E[X]=\sum\limits_{x}xp_X(x)$$ 虽然内容较为简单，但是用频率接近概率进而引进概率的定义是很常见的思路，有了这个过程我们对期望才有了很直观的理解。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[复数与复矩阵]]></title>
    <url>%2F2017%2F08%2F12%2Fcomplex_and_complex_matrix%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第12讲：复数与复矩阵 之前接触的大部分线性代数知识都只考虑实数情形，但复数情形不可避免会遇到。例如$\begin{pmatrix}cos\theta&amp;-sin\theta\sin\theta&amp;cos\theta\end{pmatrix}$没有实特征值（除了极特殊情形），目的：比较实数和复数情形的异同，注意学习复数和实数的区别联系。 复数复习 $i^2=-1$， 一个复数$a+bi=z$，$a$是实部(real part)，$b$是虚部(imaginary part)，可以把实部$a$看成x轴分量，虚部$b$看成y轴分量。复数的共轭(complex conjugate) $z=a+bi\rightarrow \bar{z}=a-bi$，长度 $|z|=\sqrt{a^2+b^2}=(a-bi)(a+bi)=z\bar{z}$（$z$的长度不能定义为$\sqrt{(a+bi)^2}$，长度必须是正值，如果把复数$z$看成一个2维向量，那么它的长度显然就是定义中给出的）， 矩阵的共轭定义为： $A=(a_{ij}){n\times n}, a{ij}\in C \rightarrow \bar{A}=(\overline{a_{ij}})_{n\times n}$，性质：$\overline{AB}=\bar{A}\bar{B}\ z\bar{z}=|z|^2$。 {长度为1（单位圆上）的复数}$\rightarrow${二阶旋转矩阵}，且保持乘法。$z=cos\theta+isin\theta\rightarrow A_2=\begin{pmatrix}cos\theta&amp;-sin\theta\sin\theta&amp;cos\theta\end{pmatrix}$。验证性质：$z_1=e^{i\theta_1},z_2=e^{i\theta_2}\rightarrow A_{z_1}=\begin{pmatrix}cos\theta&amp;-sin\theta\sin\theta&amp;cos\theta\end{pmatrix}, A_{z_2}=\begin{pmatrix}cos\theta&amp;-sin\theta\sin\theta&amp;cos\theta\end{pmatrix}\\rightarrow z_1z_2=e^{i(\theta_1+\theta_2)}=\begin{pmatrix}cos(\theta_1+\theta_2)&amp;-sin(\theta_1+\theta_2)\sin(\theta_1+\theta_2)&amp;cos(\theta_1+\theta_2)\end{pmatrix}=A_{z_1z_2}$ 欧拉公式(Euler formula) ：$e^{i\theta}=cos\theta+isin\theta$，极分解(polar decomposition)： $z=re^{i\theta}=r(cos\theta+isin\theta)\rightarrow z^n=r^ne^{in\theta}=r^n(cos(n\theta)+isin(n\theta)) $，这里z的公式中三角函数部分长度为1，所以r即z的长度，这样任何一个复数都可以用$re^{i\theta}$表示。 单位根$x^n=1$有n个复根$e^{2k\pi i\over n}, k=0,1,2,\ldots,n-1$，令$\omega=e^{2\pi i\over n}\rightarrow 1+\omega+\omega^2+\cdots+\omega^{n-1}=0$，例如：求$(1+i)^8\leftarrow1+i=\sqrt{2}e^{i{\pi\over 4}}, (1+i)^8={(\sqrt{2})}^8e^{i2\pi}=16$。$\frac{x^{2n+1}-1}{x-1}$。 代数基本定理：$a_nx^n+\cdots+a_1x+a_0=0, a_i\in C$有n个复数根(可能重复)，设$a_i\in R, a_nx^n+\cdots+a_1x+a_0=0$ 的非实数的复根也是成对出现，即若$z=a+bi(b\ne0)$是它的根，则$\bar{z}=a-bi$也是它的根，复数根是成对出现的。$\Rightarrow$ 奇次实系数方程总有一个实根。（注：公开课字幕内容如下：因为我们知道复根是成对出现的，所以对一个实系数方程，它的复根实际上是2的倍数，因为它是成对出现的，但是奇数次实系数呢，所以它必然除了复根应该有一个实根，不然的话它只有偶数的根，这样就跟它奇数次矛盾）。 实系数多项式（次数$\ge 1$）的$f(x)$可分解成$f(x)=a(x-\lambda_1)^{n_1}\cdots(x-\lambda_s)^{n_s}(x^2-b_1x+c)^{e_1}\cdots(x^2-b_tx+c)^{e_{t}}$，$\lambda_i$即实数根，后$t$项即复数根给出来的，后面这种形式无法写成实根的一次形式，也就是它的判别式小于0（有复数根），不能写成前$s$项的形式。例如：$x^m-1=\prod\limits_{k=0}^{m-1}(x-\omega_k), \omega_k=e^{i2k\pi\over m}$$\omega_{m-k}=e^{i2(m-k)\pi\over m}=e^{i{2\pi(1-{k\over m})}}=cos(2\pi(1-{k\over m}))+isin(2\pi(1-{k\over m}))=cos({2k\pi\over m})-isin({2k\pi\over m})=\overline{\omega_k}\, {k\over m} &lt;1\Rightarrow (x-\omega_k)(x-\omega_{m-k})=x^2-(\omega_k+\omega_{m-k})x+(\omega_k\omega_{m-k})=x^2-2cos({2k\pi\over m}x)+1$， 同理可得：$x^m+1=\prod\limits_{k=0}^{m-1}(x-\xi_k), \xi_k=e^{i(\pi+2k\pi)\over m}$ 。 例题：证明$cos{\pi\over 2n+1}cos{2\pi\over 2n+1}\cdots cos{n\pi\over 2n+1}={1\over 2^n}$要证明这个需要以下3点： (1)$-1-e^{i2\theta}=-1-cos2\theta-isin2\theta=-2cos\theta(cos\theta+isin\theta)\Rightarrow |-1-cos2\theta-isin2\theta|\=2|cos\theta|$ (2)设$\omega=cos{2\pi\over 2n+1}+isin{2\pi\over 2n+1}=e^{i2{\pi\over 2n+1}}\Rightarrow|-1-\omega|=2|cos({\pi\over {2n+1}})|$，那么$x^{2n}+x^{2n-1}+\cdots+1=(x-\omega)(x-\omega^2)\cdots(x-\omega^{2n})\quad (*)$ 推导如下：${x^{2n+1}-1}=(x-1)(x-\omega)(x-\omega^2)\cdots(x-\omega^{2n})\Rightarrow \frac{x^{2n+1}-1}{x-1}=(x-\omega)(x-\omega^2)\cdots(x-\omega^{2n})\\Rightarrow {1(1-x^{2n+1})\over {1-x}}=(x-\omega)(x-\omega^2)\cdots(x-\omega^{2n})$ (3)$cos{(2n+1-k)\pi\over 2n+1}=cos{k\pi\over 2n+1}$令$(*)$等式中$x=-1$，且取两边长度$1=|(-1-\omega)(-1-\omega^2)\cdots(-1-\omega^{2n})$中右边每一项利用(1)式子得到$|-1-\omega|=2|cos{\pi\over {2n+1}}|,\ |-1-\omega^2|=2|cos{2\pi\over {2n+1}}|,\\ldots\|-1-\omega^n|=2|cos{n\pi\over {2n+1}}|$ 从n+1项起根据(3)得： $$|-1-\omega^{n+1}|=2|cos{(n+1)\pi\over {2n+1}}|=2|cos{(2n+1-n)\pi\over {2n+1}}|=2|cos(\pi-{n\pi\over {2n+1}})|=2|cos({n\pi\over {2n+1}})|=|-1-\omega^n|$$ $$|-1-\omega^{n+2}|=2|cos{(n+2)\pi\over {2n+1}}|=2|cos{[(2n+1)-(n-1)]\pi\over {2n+1}}|=2|cos(\pi-{(n-1)\pi\over {2n+1}})|=2|cos{(n-1)\pi\over {2n+1}}|=|-1-\omega^{n-1}|$$$$\cdots\cdots$$ $|-1-\omega^{2n}|=2|cos{2n\pi\over {2n+1}}|=2|cos{(2n+1-1)\pi\over {2n+1}}|=2|cos(\pi-{\pi\over {2n+1}})|=2|cos({\pi\over {2n+1}})|=|-1-\omega|$ 复矩阵Hermitian矩阵复数矩阵$A=(a_{ij}){m\times n},a{ij}\in C$, 那么称$\overline{A^T}(=\bar{A}^T)$ 为 Hermitian 矩阵，记为$A^H$。例如： $Z=\begin{pmatrix}1+i\i\end{pmatrix}\rightarrow Z^H=\begin{pmatrix}1-i&amp;-i\end{pmatrix}$，而且发现$ZZ^H=||Z||^2$，这个可以类比实数中的$x^Tx=||x||^2$。性质：$(A^H)H=A, (AB)^H=B^HA^H$（按照共轭转置即可求得），正如在$R^n$的定义内积，在$C$上也可以定义内积：$u,v\in C^n, u^Hv=(\bar{u}_1\cdots\bar{u}_n)\begin{pmatrix}v_1\\vdots\v_n\end{pmatrix}=\bar{u}_1v_1+\cdots+\bar{u}_nv_n$，内积的性质：$u^Hv=\overline{v^Hu}$。 厄米特Hermite矩阵在实数矩阵中有对称矩阵的概念和作用，复数矩阵有类似的——厄米特矩阵(Hermite matrix)，定义为：$A=A^H$，即一个矩阵的共轭转置等于它本身，那么称这种矩阵为Hermite阵。例：$\begin{pmatrix}2&amp;1+i\1-i&amp;3\end{pmatrix}$。 性质1：Hermite阵对角线元素为实数。 性质2：$z\in C, A=A^H\Rightarrow z^HAz$ 是一个实数。证明如下：${\overline{z^HAz}}^T=(z^HAz)^H=z^HA^Hz=z^HAz$ 性质3：设$A,B$是Hermite阵，则$A+B$也是，证明：$(A+B)^H=A^H+B^H=A+B$。进一步，若$AB=BA$（即乘法可交换的时候），则$AB$是Hermite阵。$\Rightarrow A^n$是Hermite阵。 性质4：设$A$是一个$n$阶复矩阵，$AA^H, A+A^H$是Hermite阵，联系对比实对称矩阵的$AA^T, A^TA, A+A^T$。 性质5：一个Hermite矩阵A的特征值是实数。证明：设$Az=\lambda_0z$，则$z^HAz=\lambda_0z^Hz$。$z^HAz$和$z^Hz$均为实数$\Rightarrow \lambda_0 (z_0\ne 0)$是实数。 性质6：一个Hermite阵的不同特征值的特征向量相互正交。证明：设$(1) Az_1=\lambda_1z_1, (2) Az_2=\lambda_2z_2, \lambda_1 \ne \lambda_2$， 在(1)两边同乘以$z_2^H$得：$(3)z_2^HAz_1=z_2^H\lambda_1z_1 \Rightarrow (4)z_2^HA^Hz_1=(Az_2)^Hz_1=\overline{\lambda_2}z_2^Hz_1=\lambda_2z_2^Hz_1$，由$(3)(4)\Rightarrow \lambda_1z_2^Hz_1=\lambda_2z_2^Hz_1\Rightarrow (\lambda_1-\lambda_2)z_2^Hz_1=0$，因为$\lambda_1\ne \lambda_2$得：$z_2^Hz_1=0$。 酉unitary矩阵酉矩阵是正交阵的复数类比。$U_{n\times n}$是酉矩阵$\Leftrightarrow$ $\forall z\in C^n, ||Uz||=||z||$，证明：$U^HU=I_n\Rightarrow |U z|^2=z^HU^HUz = z^Hz=|z|^2\Rightarrow |Uz|=|z|\Rightarrow |\lambda|=1$ 。得出与实数矩阵类似的性质1：酉矩阵乘以任何向量不改变它的模长。性质2：$U$是酉矩阵，则$U$的特征值模长为1。 例：$u=\begin{pmatrix}{1\over \sqrt{2}}&amp;-\frac{1}{\sqrt{6}}&amp;\frac{1-i\sqrt{3}}{2\sqrt{3}}\\frac{1}{\sqrt{2}}&amp;\frac{1}{\sqrt{6}}&amp;{-1+i\sqrt{3}\over 2\sqrt{3}}\0&amp;{1+i\sqrt{3}\over \sqrt{6}}&amp;{1\over \sqrt{3}}\end{pmatrix}$ ，$|det U|=\prod{|\lambda_i|}=1$ (行列式的长度等于特征值长度的乘积)。 而实数的正交阵，也有类似的性质。下面证明正交阵不同特征值对应的特征向量相互正交： 因为$Q$正交阵,$Q^TQ=E,|Q|=1=λ_1λ_2\ldotsλ_n$,设$λ_1,λ_2$为$Q$的两个不同的特征值,$ξ_1,ξ_2$为对应的特征向量$ (1)Qξ_1=λ_1ξ_1, (2)Qξ_2=λ_2ξ_2,(3)(ξ_2)^T Q^T=λ_2(ξ_2)^T \Rightarrow (3)(1)\Rightarrow ξ_2^TQ^TQξ_1=λ_1λ_2ξ_2^Tξ_1\Rightarrow \(λ_1λ_2-1)ξ_2^Tξ_1=0$而$|λ_1|=|λ_2|=1,λ_1≠λ_2$,得$ξ2^Tξ1=0,因此ξ_2,ξ_1$正交。 复正规阵酉阵和Hermite矩阵均为复正规矩阵，即：$A^HA=AA^H$。 酉相似：设$A,B$是；两$n$阶复矩阵，若存在酉矩阵$U$，使得$A=U^HBU$，则$A$和$B$是酉相似（联系实数矩阵的正交相似）。定理：设$A$复正规阵，则 向量$u$是$A$的关于$\lambda$的特征向量$\Leftrightarrow u$是$A^H$的关于$\bar{\lambda}$的特征向量。证明：设$Au=\lambda u\Rightarrow (A-\lambda I)u=0$令$B=A-\lambda I\Rightarrow ||B^Hu||^2=u^HBB^Hu=u^HB^HBu=||Bu||^2=0$，因为$||B^Hu||^2=0\Rightarrow B^Hu=0, (A-\lambda I)^H=B^H\Rightarrow (A^H-\bar{\lambda}I)u=0\Rightarrow A^Hu=\bar{\lambda}u$ 不同特征值的特征向量正交。证明与Hermite矩阵一样。 定理(Schur)：任意一个复矩阵$A$酉相似于一个上三角阵。即：$\exists\ U\in $ unitary matrix,$\forall\ A\in$ complex matrix, $U^H=U^{-1}, U^HAU=\begin{pmatrix}\lambda_1&amp;&amp; \0&amp;\ddots&amp;*\0&amp;0&amp;\lambda_n\end{pmatrix} \Rightarrow$任意一个复正规阵酉相似于对角阵，特别地，酉相似于$\begin{pmatrix}1\&amp;1\&amp;&amp;\ddots\&amp;&amp;&amp;1\end{pmatrix}$, $U^HAU=diag(\lambda_1,\ldots,\lambda_n)\Rightarrow AU=\lambda U$。 一个实矩阵$A$是正规的$\Leftrightarrow A^TA=AA^T$。例如，$A$是正交阵或者$A$是对称（反对称）矩阵。 如果$A$是正规的，那么存在正交阵$\Omega$使得： $\Omega^TA\Omega=\begin{pmatrix}\begin{pmatrix}a_1&amp;b_1 \ -b_1&amp;a_1\end{pmatrix}\&amp;\ddots\&amp;&amp;\begin{pmatrix}a_s&amp;b_s \ -b_s&amp;a_s\end{pmatrix}\&amp;&amp;&amp;\lambda_{2s+1}\&amp;&amp;&amp;&amp;\ddots\&amp;&amp;&amp;&amp;&amp;\lambda_n\end{pmatrix}​$，即实正规阵正交相似于分块对角阵。 对于复正规阵酉相似对角阵$U^HAU=diag(\lambda_1,\ldots,\lambda_n)\Rightarrow AU=\lambda U$，这里如果把$U$的列向量写成$u_k=\beta+i\gamma,\ \ k\in [1,n],\ \beta,\gamma \in R_n$，例如：$\begin{pmatrix}1+i\1-i\end{pmatrix}=\begin{pmatrix}1\1\end{pmatrix}+i\begin{pmatrix}1 \ -1\end{pmatrix}$。 $Au_k=\lambda_ku_k\Rightarrow A(\beta+i\gamma)=\lambda_k(\beta+i\gamma)$，令$\lambda_k=a+ib$，得：$A\beta=a\beta-b\gamma, A\gamma=b\beta+a\gamma\Rightarrow$$A(\beta, \gamma)=(\beta,\gamma)\begin{pmatrix}a&amp;b \ -b&amp;a\end{pmatrix}$ ，所以$\Omega$的实际上是由$U$的特征向量的实部和虚部组成的这样一个形式。 $\Omega$是一个正交阵，那$\beta$和$\gamma$是不是正交的？它们的长度相等嘛？不然无法保证$\Omega$是一个正交阵。 结论：设$A$是$n$解实正交阵。若$\lambda=a+ib(b\ne 0)$是$A$的特征值，$x=x_1+ix_2,\ x_1,x_2\in R_n$是对应的特征向量，则$||x_1||=||x_2||$，且$x_1,x_2$是相互正交的。 证明：如果$\lambda=a+ib$ 是$A$的特征值，那么$\lambda=a-ib$ 也是$A$的特征值。因为$A$实正交阵，所以对$Ax=\lambda x$取两边共轭得：$\overline{Ax}=A\bar{x}=\bar{\lambda}\bar{x}$。那么得到$\lambda,\bar{\lambda}$都是$A$的特征值，由于正交阵不同特征值对应的特征向量正交，所以${\bar{x}}^Hx=0, x=x_1+ix_2, \bar{x}=x_1-ix_2\Rightarrow ||x_1||=||x_2||, x_1^Tx_2=0$。 例2：证明：$\begin{pmatrix}cos\theta&amp;-sin\theta\sin\theta&amp;cos\theta\end{pmatrix}​$和$\begin{pmatrix}e^{i\theta}&amp;0\0&amp;e^{-i\theta}\end{pmatrix}​$ 酉相似。$U={1\over \sqrt{2}}\begin{pmatrix}i&amp;1\1&amp;i\end{pmatrix}​$ 例3：设$A$是Hermite阵，则$I+iA$是非奇异的。由于A的特征值是实数，那么$I+iA$特征值的是$\lambda i+1$不可能是0，行列式就不可能是0，因此是非奇异的。如果A是Hermite阵，那么$U=(I-iA)(I+iA)^{-1}$是酉阵，验证$U^H=(I-iA)^{-1}(I+iA)=(I+iA)(I-iA)^{-1}$（注：分块是相同的矩阵是可交换即变成分块对角阵），这个是用来通过实对称阵或Hermite阵构造酉矩阵。 离散傅里叶变换DFT回忆若$f(x), f’(x)$是piecewise连续的且$f(x+L)=f(x)$， 则$f(x)=a_0+\sum(a_ncos({2\pi nx\over L})+b_nsin({2\pi nx \over L})), a_n={2\over L}\int_{0}^{L}f(x)cos{2\pi nx \over L}dx,\ b_n={2\over L}\int_{0}^{L}f(x)sin{2\pi nx \over L}dx$， 令$V={f(x)|f(x)\text{如上条件}}\rightarrow R^{\infty}$$f(x)\rightarrow (a_0, a_1, b_1, a_2, b_2,\ldots)$这是一个线性映射，$(a_0, a_1,b_1,\ldots)$是$f(x)$的逆傅里叶变换。 当通过$f(x)$求系数$a_i,b_i,\ldots$即傅里叶变换，当通过系数$a_i,b_i,\ldots$求$f(x)$即逆傅里叶变换。 由前文分析得到傅里叶级数的复形式是$F=\sum\limits_{k=-\infty}^{\infty}c_ke^{ikx}, c_k={1\over 2\pi}\int_{-\pi}^{\pi}f(x)e^{-ikx}dx$，通过变量代换：$x={2\pi \over L}t$ 得：$c_k={1\over L}\int_{-{L\over 2}}^{L\over 2}f(t)e^{-i{2\pi k\over L}t}dt, f(t)=\sum\limits_{k=-\infty}^{+\infty}c_ke^{-i{2\pi k\over L}t}$令$n=k$，则得到新的傅里叶级数复数形式：$f(t)=\sum\limits_{n=-\infty}^{+\infty}c_ne^{-i{2\pi n\over L}t}, c_n={1\over L}\int_{-{L\over 2}}^{L\over 2}f(t)e^{-i{2\pi n\over L}t}dt\quad (1)$令$\omega_n={2\pi n\over L}$得到傅里叶级数的频率形式：$\hat{f}(\omega)=\int_{-\infty}^{+\infty}f(t)e^{i\omega_nt}dt\quad (2)$ 对(1)(2)进行离散化：$f(t_j)=\sum\limits_{k=-\infty}^{+\infty}c_ke^{-i{2\pi k\over L}t_j}$令 $\ t_j={jL\over N}$则得到：$f(t_j)\approx \sum\limits_{k=0}^{N-1}c_ke^{i{2\pi kj\over N}}, c_k={1\over L}\int_{-{L\over 2}}^{L\over 2}f(t_j)e^{i{2\pi kj\over N}}dt_j\quad (1*)$，然后再设置$A_j=f(t_j)，a_k=c_k$得到：$f(t)\rightarrow (A_0,A_1,\cdots, A_{N-1}), (c_k)\rightarrow (a_0,a_1,\cdots, a_{N-1})$。 由上可举N=4的例子：$A_0=f(t_0)=a_{0}e^{i2\pi 00\over 4}+a_1e^{i2\pi 10\over 4}+a_2e^{i2\pi 20\over 4}+a_3e^{i2\pi 30\over 4}=a_{0}+a_1+a_2+a_3=1a_{0}+1a_1+1a_2+1a_3$$A_1=f(t_1)=a_{0}e^{i2\pi 01\over 4}+a_1e^{i2\pi 11\over 4}+a_2e^{i2\pi 21\over 4}+a_3e^{i2\pi 31\over 4}= a_{0}+ia_1-a_2-ia_3=1a_{0}+ia_1+i^2a_2+i^3a_3$$A_2=f(t_2)=a_{0}e^{i2\pi 02\over 4}+a_1e^{i2\pi 12\over 4}+a_2e^{i2\pi22\over 4}+a_3e^{i2\pi 32\over 4} = a_{0}-a_1+a_2-a_3 = 1a_{0}+i^2a_1+i^4a_2+i^6a_3$$A_3=f(t_3)=a_{0}e^{i2\pi 03\over 4}+a_1e^{i2\pi 13\over 4}+a_2e^{i2\pi 23\over 4}+a_3e^{i2\pi 33\over 4}=a_{0}-ia_1-a_2+ia_3=1a_{0}+i^3a_1+i^6a_2+i^9a_3$写成矩阵形式：$\begin{pmatrix}A_0\A_1\A_2\A_3\end{pmatrix}=\begin{pmatrix}1&amp;1&amp;1&amp;1\1&amp;i&amp;i^2&amp;i^3\1&amp;i^2&amp;i^4&amp;i^6\1&amp;i^3&amp;i^6&amp;i^9\end{pmatrix}\begin{pmatrix}a_0\a_1\a_2\a_3\end{pmatrix}$设$F=\begin{pmatrix}1&amp;1&amp;1&amp;1\1&amp;i&amp;i^2&amp;i^3\1&amp;i^2&amp;i^4&amp;i^6\1&amp;i^3&amp;i^6&amp;i^9\end{pmatrix}$，令s表示第s行，t表示第t列，则F的第s行第t列元素为$F_{s,t}=i^{(s-1)(t-1)}$，其实上文中的记号j刚好可以视为行数，k刚好表示列数。 一般地，$\begin{pmatrix}A_0\A_1\\vdots\A_{N-1}\end{pmatrix}=F\begin{pmatrix}a_0\a_1\\vdots\a_{N-1}\end{pmatrix}$，$F_{j, k}=e^{i{2\pi jk\over N}}$令$\omega_N=e^{i{2\pi\over N}}\Rightarrow F_{j,k}=\omega^{jk}{N}=F{j,k}$。F称为傅里叶矩阵，F的各列相互正交且F对称(但注意：不是Hermite矩阵)，这个矩阵跟范德蒙德行列式很像。如果令$\omega_N=e^{i{2\pi\over N}}\Rightarrow F_{s,t}=\omega^{st}{N}=F{t,s}$那么F表示成$F=\begin{pmatrix}1&amp;1&amp;1&amp;1\1&amp;\omega&amp;\omega^2&amp;\omega^3\1&amp;\omega^2&amp;\omega^4&amp;\omega^6\1&amp;\omega^3&amp;\omega^6&amp;\omega^9\end{pmatrix}$。 对于给定的$\begin{pmatrix}A_0\A_1\\vdots\A_{N-1}\end{pmatrix}$，求$\begin{pmatrix}a_0\a_1\\vdots\a_{N-1}\end{pmatrix}=F^{-1}\begin{pmatrix}A_0\A_1\\vdots\A_{N-1}\end{pmatrix}$，$F^{-1}={1\over N}\overline{F}$，需要$N^2$次乘法，$N(N-1)$次加法（忽略除以N的除法），计算量$=O(N^2)$。 注记：实际上由前文可得$\begin{pmatrix}a_0\a_1\\vdots\a_{N-1}\end{pmatrix}=\begin{pmatrix}c_0\c_1\\vdots\c_{N-1}\end{pmatrix}$，因此是向量$\begin{pmatrix}A_0\A_1\\vdots\A_{N-1}\end{pmatrix}$关于某个正交向量基的投影长度，即坐标分量。$(a_0, a_1,b_1,\ldots)$是$f(x)$关于${1,cosx,sinx,\dots}$的坐标。 快速傅里叶变换FFT快速傅里叶变换减少了$DFT$的计算量到$O(Nlog_2^N)$ $N$ $N^2$ $Nlog_2^N$ FFT efficiency 256 65536 1024 64:1 512 262144 2304 114:1 1024 1048576 5120 205:1 注：$\lim\limits_{N\rightarrow +\infty}{log_2^N\over N}=0$ 解释算法：$N=4，\begin{pmatrix}a_0\a_1\a_2\a_3\end{pmatrix}={1\over 4}\begin{pmatrix}1&amp;1&amp;1&amp;1\1&amp;-i&amp;-1&amp;i\1&amp;-1&amp;1&amp;-1\1&amp;i&amp;-1&amp;-i\end{pmatrix}\begin{pmatrix}A_0\A_1\A_2\A_3\end{pmatrix}\quad i^4=1$ $\begin{equation}4a_0=(A_0+A_2)+(A_1+A_3)\4a_1=(A_0-A_2)-i(A_1-A_3)\4a_2=(A_0+A_2)-(A_1+A_3)\4a_3=(A_0-A_2)+i(A_1-A_3)\end{equation}$ 注意：求$a_2$的时候，可以把在求$a_0$过程中的两个括号的值重新利用，求$a_3$的时候，可以把在求$a_1$过程中的两个括号的值重新利用。 引入记号： 将$A_0, A_1, A_2, A_3$重新排序$A_0,A_2,A_1,A_3$使用记号，则 $FFT$算法将$DFT$算法分成$log_2^N$段，每一段有${N\over 2}$个butterfly operation。 举例：$N=8$，第一步将$A_0,A_1,\ldots,A_7$重新排序。原则：考虑$0,1,\ldots,7$的二进制，设$j$的二进制数的反转为$n_j$。若$j&lt;n_j$，则交换$Aj$和$A_{n_j}$。例如1的二进制数为${001}_2$,反转为${100}_2=4, 1&lt;4$，交换$A_1$和$A_4$。 排序后为：$A_0,A_4,A_2,A_6,A_1,A_5,A_3,A_7$（奇偶分离） 奇偶分离的原因：$\begin{pmatrix}a_0\a_1\\vdots\a_{N-1}\end{pmatrix}=({1\over N}\overline{F})\begin{pmatrix}A_0\A_1\\vdots\A_{N-1}\end{pmatrix}$，令$p(x)=A_0+A_1x+\cdots+A_{N-1}x^{N-1}=p_e(x^2)+xp_o(x^2),p_e=A_0+A_2x^2+\cdots\quad p_o=A_1+A_3x^2+\cdots$ 注解：e代表even，o代表odd，则$a_j={1\over N}(1,\overline{\omega}N^j,\overline{\omega}{N}^{2j},\ldots)\begin{pmatrix}A_0\\vdots\A_{N-1}\end{pmatrix}={1\over N}p(\overline{\omega}_N^j)={1\over N}[p_e(\overline{\omega}_N^{2j})+\overline{\omega}_N^{j}p_o(\overline{\omega}_N^{2j})], j=0,1,\cdots,{N\over 2}-1$ $a_{N\over 2+j}={1\over N}[p_e(\overline{\omega}_N^{2({N\over 2}+j)})+\overline{\omega}_N^{N\over 2+j}p_o(\overline{\omega}_N^{2({N\over 2+j})})],j=0,1,\cdots,{N\over 2}-1​$ 再由于：$\omega_N=e^{i{2\pi\over N}}\Rightarrow\overline{\omega}N^{2j}=\overline{\omega}{N\over 2}^j, \overline{\omega}_N^{N\over 2+j}=-\overline{\omega}_N^j, \overline{\omega}N^{N+2j}=\overline{\omega}{N\over 2}^j$ 所以：$\cases{a_j={1\over N}[p_e(\overline{\omega}_{N\over 2}^{j})+\overline{\omega}_N^{j}p_o(\overline{\omega}{N\over 2}^{j})],j=0,1,\cdots,{N\over 2}-1\a{N\over 2+j}={1\over N}[p_e(\overline{\omega}_{N\over 2}^{j})-\overline{\omega}_N^{j}p_o(\overline{\omega}_{N\over 2}^{j})],j=0,1,\cdots,{N\over 2}-1}$ 所以：$a_j={1\over N}p(\overline{\omega}_N^j)$，再令$b_j=p_e(\overline{\omega}_{N\over 2}^{j}), b’_j=p_o(\overline{\omega}_{N\over 2}^{j})$，那么：$\cases{a_j = {1\over N}[ b_j+\overline{\omega}_N^{j}b’j],j=0,1,\cdots,{N\over 2}-1\a{N\over 2+j} = {1\over N}[b_j-\overline{\omega}_N^{j}b’_j] ,j=0,1,\cdots,{N\over 2}-1}$，那么这又是一个butterfly operation: 可以重复利用以上原理对$b_j,b’_j$讨论，$b_j=p_e(\overline{\omega}_{N\over 2}^{j}),j=0,1,\cdots,{N\over 2}-1$，令$c_j=p_{ee}(\overline{\omega}_{N\over 4}^{j}), c’j=p{eo}(\overline{\omega}_{N\over 4}^{j})$，那么：$\cases{b_j = {1\over N}[c_j+\overline{\omega}_{N\over 2}^{j}c’j],j=0,1,\cdots,{N\over 4}-1\b{N\over 4+j} = {1\over N}[c_j-\overline{\omega}_{N\over 2}^{j}c’_j],j=0,1,\cdots,{N\over 4}-1}$，那么这又是一个butterfly operation: 不停的划分下去，即：$FFT$算法将$DFT$算法分成$log_2^N$段，每一段有${N\over 2}$个butterfly operation。 举例：]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机图像]]></title>
    <url>%2F2017%2F08%2F11%2Fcomputer_graphics%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第11讲：计算机图像 引言熟悉的三维空间的基本变换是：平移(translation)，伸缩(rescaling)，旋转(rotation)，投影(projection)和反射(reflection)。现在一个问题：平移变换只对于点才有意义，因为平移变换会改变点的坐标，可是普通向量没有位置概念，只有大小和方向。那如何区分点和向量呢？这时候引入齐次坐标系(homogeneous coordinate system)。 对于任意一个3维空间点$p$的坐标均是参照（相对于）基点（原点）的坐标，可以表示成$p=x\vec e_1+y\vec e_2+z\vec e_3+ O=x\begin{pmatrix}1\0\0\end{pmatrix}+y\begin{pmatrix}0\1\0\end{pmatrix}+z\begin{pmatrix}0\0\1\end{pmatrix}+\begin{pmatrix}0\0\0\end{pmatrix}$，然而$\vec{op}=x\vec e_1+y\vec e_2+z\vec e_3$ 是不参照任何东西的，为了在线性代数中统一表示和区分，把$p=\begin{pmatrix}1&amp;0&amp;0&amp;0\0&amp;1&amp;0&amp;0\0&amp;0&amp;1&amp;0\0&amp;0&amp;0&amp;0\end{pmatrix}\begin{pmatrix}x\y\z\1\end{pmatrix}\quad \vec{op}=\begin{pmatrix}1&amp;0&amp;0&amp;0\0&amp;1&amp;0&amp;0\0&amp;0&amp;1&amp;0\0&amp;0&amp;0&amp;0\end{pmatrix}\begin{pmatrix}x\y\z\0\end{pmatrix}$， 这时三维空间中的一个点的齐次坐标是$(x,y,z,1)$或$\begin{pmatrix}x\y\z\1\end{pmatrix}$，一个向量的齐次坐标是$(x,y,z,0)$或$\begin{pmatrix}x\y\z\0\end{pmatrix}$，所以平移变换就不是$R^3\rightarrow R^3$。 定义 一个函数$f: R^n \rightarrow R^N $是一个刚体运动(rigid motion)，如果$\forall v,w\in R^n, ||f(v)-f(w)||=||v-w||$，即内部的各点间距离不变。定理 $R^3$上的刚体运动是平移，旋转和反射的合成。此时，$f(v)=Av+v_0$，其中$A$是三阶正交阵。三阶正交阵的分类：设$A$是一个三阶正交阵，则存在实可逆阵$P$，$P^{-1}AP=\begin{pmatrix}cos\theta&amp;-sin\theta&amp;0\sin\theta&amp;cos\theta&amp;0\0&amp;0&amp;\pm 1\end{pmatrix}=B$，其中$P=(\alpha_1, \alpha_2, \alpha_3)$，根据相似的性质：$|B|=\pm 1\rightarrow |A|=\pm 1$，$A$本身是一个正交阵，因此$A^TA=I_3$。 若$B_{33=1}, AP=PB\rightarrow A\alpha_3=\alpha_3$是一个旋转矩阵，旋转轴是$\alpha_3$所在直线，旋转角度是沿$\alpha_3$方向逆时针转$\theta$角；若$B_{33}=-1, AP=PB\rightarrow A\alpha_3=-\alpha_3$ 是$A$将$\alpha_3$变为$-\alpha_3$，将$\alpha_1,\alpha_2$所在平面逆时针旋转$\theta$角，此时$A$的作用就是镜面反射和旋转，这里镜面指的是x-y平面。 平移translation 伸缩rescaling 旋转rotation3个特殊情形 一般情形 旋转的性质 投影projection 反射]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图和网络]]></title>
    <url>%2F2017%2F08%2F08%2Fgraph_and_network%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第8讲：图和网络 简介欧姆定律Ohm’s law的向量形式 图与矩阵 关联矩阵incidence matrix 邻接矩阵adjacency matrix 拉普拉斯矩阵laplacian matrix 注： 半正定证明与刚度矩阵类似 网络和加权Laplacian矩阵 电路相关的物理定律 例子不接外部源 接外部源 带权$K=A^TCA$ 关联矩阵的四个基本子空间N(A) C(A)按$C(A)$的定义得：$C(A)={Ax|x\in R^n}$ 。沿用前面使用的字母：$u$是各点电势，$e$是各边电势差，$Au=e$ ，当$Au=e$ 有解 $\Leftrightarrow e \in C(A)$ 去证明：$dim(C(A))=n-1$ ，即$A$ 的任意 $n-1$个列向量是线性无关的。设$A=(a_1,a_2,\,…\,,a_n) $，不妨假设$a_1,a_2,\,…\,,a_{n-1}$线性相关，那么存在$c_1, c_2,\,…\,,c_{n-1} \in R$ 且不全为0满足：$c_1a_1+c_2a_2+…+c_{n-1}a_{n-1}+0a_n=0\Rightarrow A\begin{pmatrix}c_1\c_2\\vdots\c_{n-1}\0\end{pmatrix}={0}\Rightarrow \begin{pmatrix}c_1\c_2\\vdots\c_{n-1}\0\end{pmatrix}\in N(A), $但与$N(A)=\left{c\begin{pmatrix}1\\vdots\1\end{pmatrix} \Bigg| c\in R \right} $ 矛盾，以此类推，得以证明$C(A)$的维数是$n-1$ ，即$A$的任意$n-1$个列向量均可作为$C(A)$的一组基。 发现矩阵中对应的回路：$e\in C(A)$ 如下等式有解 $Au=e\Rightarrow \begin{pmatrix}-1&amp;1&amp;0&amp;0\ -1&amp;0&amp;1&amp;0\0&amp;-1&amp;1&amp;0\0&amp;-1&amp;0&amp;1\0&amp;0&amp;-1&amp;1\end{pmatrix}\begin{pmatrix}u_1\u_2\u_3\u_4\u_5 \end{pmatrix}=\begin{pmatrix}e_1\e_2\e_3\e_4\e_5 \end{pmatrix} \Rightarrow \begin{cases}-u_1+u_2=e_1\ -u_1+u_3=e_2\ -u_2+u_3=e_3\ -u_2+u_4=e_4\ -u_3+u_4=e_5\end{cases} \Rightarrow \begin{cases}e_1-e_2+e_3=0\e_3-e_4+e_5=0\end{cases}$ ，即边1,2,3这3条边电势差之和为0，由图上可得边1,2,3恰好构成一个回路，边3,4,5也一样。这恰好是Kirchholff Voltage Law (KVL)。把这两个回路等式书写成矩阵形式$\begin{pmatrix}1&amp;-1&amp;1&amp;0&amp;0\0&amp;0&amp;1&amp;-1&amp;1 \end{pmatrix}\begin{pmatrix} e_1\e_2\e_3\e_4\e_5 \end{pmatrix}=0$ . 此时称矩阵$B =\begin{pmatrix}1&amp;-1&amp;1&amp;0&amp;0\0&amp;0&amp;1&amp;-1&amp;1 \end{pmatrix}$ 为回路矩阵，可以看到它的每一行代表一个回路且称为极小回路，每一列代表一条边。如果边的方向是逆时针方向则取为正号，否则取为负号。注意，此时$e\in N(B)$。 此外，$BA=\begin{pmatrix}1&amp;-1&amp;1&amp;0&amp;0\0&amp;0&amp;1&amp;-1&amp;1\end{pmatrix}\begin{pmatrix}-1&amp;1&amp;0&amp;0\ -1&amp;0&amp;1&amp;0\0&amp;-1&amp;1&amp;0\0&amp;-1&amp;0&amp;1\0&amp;0&amp;-1&amp;1\end{pmatrix}=\begin{pmatrix}0&amp;0&amp;0&amp;0\0&amp;0&amp;0&amp;0\end{pmatrix}$即$C(A) \subseteq N(B) $ 。$dim(N(B))=3, dim(C(A))=3$，因此$C(A)$就构成了$N(B)$的基。从理意义角度理解：$A$矩阵执行的操作表示求解各边电势之差，$B$各行刚好是回路，由$KVL$定律得结果必为0. $N(A^T)$ 由定义得：$N(A^T)={y\in R^m|A^Ty=0}$。例子中，关联矩阵$A$ 各行代表一条边，各列代表一个顶点。那么$A^T$ 的行代表顶点，列代表边。$A^Ty=0\Rightarrow\begin{pmatrix}-1&amp;-1&amp;0&amp;0&amp;0\1&amp;0&amp;-1&amp;-1&amp;0\0&amp;1&amp;1&amp;0&amp;-1\0&amp;0&amp;0&amp;1&amp;1\end{pmatrix}\begin{pmatrix}y_1\y_2\y_3\y_4\y_5 \end{pmatrix}=\begin{pmatrix}0\0\0\0\0\end{pmatrix} \Rightarrow \begin{cases}-y_1-y_2=0\y_1-y_3-y_4=0\y_2+y_3-y_5=0\y_4+y_5=0\end{cases}$物理意义解读：$y_i$是各第$i$边上的电流，上述等式表明每一个顶点输入输出电流和为0，即Kichhoff Current Law (KCL)。 $A^Ty=0$， 由前文得到：$BA=0 \Rightarrow A^TB^T=0 \Rightarrow A^TB^T=\begin{pmatrix}-1&amp;-1&amp;0&amp;0&amp;0\1&amp;0&amp;-1&amp;-1&amp;0\0&amp;1&amp;1&amp;0&amp;-1\0&amp;0&amp;0&amp;1&amp;1\end{pmatrix}\begin{pmatrix}1&amp;0\ -1&amp;0\1&amp;1\0&amp;-1\0&amp;1\end{pmatrix}=\begin{pmatrix}0&amp;0\0&amp;0\0&amp;0\0&amp;0\end{pmatrix}$因此，$C(B^T) \subseteq N(A^T)$。由于$r(A)=C(A)=r=n-1, N(A^T)+C(A)=m, N(A^T)=m-r=5-3=2$， 由于$B^T$的列向量线性无关，即$B$的行向量代表回路，那么回路向量就是$N(A^T)$的一组基。 $C(A^T)$ 总结 $N(A_{m\times n})$零空间 $Au=0$ ，$N(A)=c{(1,1,\,…\,,1)^T}_{n\times 1}$ ；物理意义：各点电势相等，电势差为0。 $C(A_{m\times n})$列空间 $Au=e$(上文用的是x, b)，$A$ 中任意$n-1$ 列构成了$C(A)$ 的一组基；物理意义每个极小回路电势守恒，每个极小回路构成的极大回路电势依然守恒，诠释了KVL定律。 $N(A^T)$左零空间 $A^Ty=0$，回路向量构成了$N(A^T)$ 的一组基；诠释了无外部电流源的KCL定律。 $C(A^T)$行空间 ，$A^Ty=f$， 每个极大树子图对应关联矩阵的行向量（即边）构成了$C(A^T)$ 的一组基；诠释了有外部电流源的KCL定律。 注计N(B)=C(A) B的零空间中的任何一个向量，它都要属于A的列空间，$A$的列空间中的每一个向量的特点，比如说$A$乘上一个$x_1$到$x_n$，$x_1$到$x_n$是$n$个顶点的电势。$A$乘上这个向量得到的是各个边上的电势差，那么相应的$x_j-x_k$就是$j$和$k$两个顶点上的电势差，顶点连线，$j$和$k$连线的边上的电势差。那么我们要想说明，N(B)中的向量属于C(A)那么我们只要说明任何一个向量属于B的零空间，它最后都能写成这样一种形式，就可以了。那么设$e$属于$N(B)$，那么我们可以取定这个连通图的一个极大树子图，然后在这个极大树子图$T$上取一个顶点作为基点，那么任意的另外一个顶点$K$跟这个基点之间它们连线的路在$T$上只有一条这样的路，因为$T$是一个树，它不可能有回路，所以在$T$中有唯一的一条连接K到基点的路。定义K的电势：在这条路上各边的电势之和，各边的电势之和，我们这个$e_1$到$e_m$呢，我们可以刻画各个边上的电势，那么我们可以看到$e$属于$N(B)$我们实际上可以检查出任意边上的电势差实际上是$e_j$等$u_k$减$u_1$，那么其中的这个$k$呢为j的起点，$l$为$j$的终点，最后我们就可以得到$e=-Au$，所以$e$就属于$C(A)$就是这个地方呢，我们要使用$e$属于$N(B)$，我们才能检查出：任意边上的这个电势差等于$u_k$减$u_l$，就是要满足科尔霍夫电压定律。 欧拉公式Euler’s formula 对于$B_{x \times m}\Rightarrow C(B^T)+dim(N(B))=r_B+dim(N(B))=m\Rightarrow m-r_B=dim(N(B))=dim(C(A))=n-1$ 又因为欧拉公式：$m-l=n-1$，得：$r_B=l$，即$B$是行满秩的，其实极小回路组对应极大线性无关组。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工程中的矩阵]]></title>
    <url>%2F2017%2F08%2F07%2Fengineering_matrices%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第七讲：工程中的矩阵 应用数学的几个原则 将非线性问题变成线性问题(Nonlinear becomes linear) 将连续问题转化为离散的(Continuous becomes discrete) 工程中的矩阵许多物理定理都是线性关系(as approximations of reality)，比如胡克定律(Hook’s law)、欧姆定律(Ohm’s law)、牛顿第二定律(F=ma)，讨论这些定律的向量形式。线性关系的向量形式以如下方式、框架来讨论： $(1)\ e=Au$$(2)\ y=Ce$$(3)\ f=A^Tw$ 其中$u$是起始未知量$(primary\ unknown)$，$f$是外部的输入$(input)$： 线性问题通常是：输入$f$，求出$u$？ 例如：胡克定律：Displacement is proportional to force f=ku欧姆定律：Current is proportional to voltage difference推广到向量形式：$f=Ku$另外的例子：最小二乘法 $A^TAx=A^Tb$ ，求$x$ 线性弹簧模型 情形(1) 情形(2) 情形(3) 情形(4) 总结 胡克定律的向量形式把它应用到了弹性力学中，这个$u$表示的是质体的上下位移$e$是弹簧和伸长或缩短量，那么它们之间的关系呢？可以通过这样$A$这个矩阵那么A非常相似于一个差分矩阵，这样弹簧的伸长和缩短量和弹簧的弹力之间可以通过胡克定律来描述，那么这若干根弹簧它们所产生的弹力我们提升到胡克定律这样一个向量形式：C的每一个对角分量表示的是一个弹性系数（$y=Ce$）。最后弹力和外力之间：当达到平衡以后，可以通过一个矩阵去描述它们的关系，这个矩阵跟前面这个矩阵正好互为转置最后把整个过程合起来到这个矩阵$K=A^TCA$，称为刚度矩阵刚度矩阵刻划了系统受外力作用的形变程度。 刚度矩阵 注：此处老师讲解具有小的跳跃性 ，渣渣注释如下： $K,T$是正定的：$C$ 矩阵表示弹性系数是正定的，$K=A^TCA$ ，当 $A$ 可逆的时候，$K$ 与 $C$ 合同的。 与正定矩阵合同的对称矩阵也是正定的 ​ 判断是实对称阵是不是正定的第一条判别法：特征值是否全正，是的话则这个实对称矩阵就是正定的。根据惯性定理，由于与正定矩阵（记为$A$）合同的矩阵（记为$B$）其特征值符号与 $A$ 一致且保持对称性，那么$B$ 的特征值也是全正的，因此 $B$ 也是正定的。 $B, C$ 是半正定的 因为弹性系数矩阵 $C$ 是正定的对角阵$\Rightarrow x^TKx=x^TA^TCAx=x^TA^T ({\sqrt{C}}^T \sqrt{C}) Ax = x^TA^T {\sqrt{C}}^T \sqrt{C} Ax = ||\sqrt{C} Ax||^2 $，因为$A$是奇异的，$x^TKx\ge 0$， 因此K是半正定的。 性质1 注：$f_i$ 是 $i$ 个质题所受的外力，例如：重力，$f_i=m_ig,\ m_i$ 是 $i$ 个质体的质量。 性质2 注：此处老师直接说一般性结论，$A, \ B$ 都正定的，那么$AB$ 可能不对称，但是$AB$ 存在正特征值。圆盘定理也是直接引用（！！渣渣工科狗表示闻所未闻！！）。 性质3 从离散到连续$f=A^TCAu$ 总结： $(1)\ e=u_i-u_{i-1}=\Delta u={du\over dx}=Au\(2)y=Ce=c(x)e(x)\(3)\ f=-(y_i-y_{i-1})=-\Delta y=-{dy\over dx}=A^Ty$]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伪逆(广义逆)pseudo inverse]]></title>
    <url>%2F2017%2F08%2F06%2Fpseudo_inverse%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第六讲：伪逆 引言矩阵的奇异值分解可以理解成从$R^n$到$R^m$的线性变换在不同基底下矩阵表示，接下来利用矩阵的奇异值分解来定义矩阵的伪逆，然后再利用矩阵的伪逆来讨论线性方程组Ax＝b无解时的最小二乘解，线性代数的中心问题是求解线性方程组$Ax=b$，最简单的情况是如果系数矩阵A是n阶的可逆矩阵，那么这时对于任意的n维向量$b$，线性方程组$Ax=b$有唯一的解，这个解是$A^{-1} b$，那这就启发去对于不可逆的矩阵或者是对于$A_{m\times n}$的矩阵，我们来定义它的一个逆矩阵，那么这时候逆矩阵我们叫做伪逆或者是叫广义逆 。 定义伪逆的定义来自于奇异值分解：(1)若$A$可逆，即$r=m=n$，则：$A^{-1}=(U\Sigma V^T)^{-1}=V\Sigma^{-1}U^T=A^+$，注意：由奇异值分解公式$AV=U\Sigma,\ (v_1\,…\,v_r)\in C(A^T),\ (v_{r+1}\,…\,v_n)\in N(A),\ (u_1\,…\,u_r)\in C(A),\ (u_{r+1}\,…\,u_m)\in N(A^T)$ 得：$AV=U\Sigma: C(A^T)\rightarrow C(A)$，同理可得：$A^+U^T=V\Sigma^{+}:C(A)\rightarrow C(A^T)$ (2)$AA^+=(U\Sigma_{m\times n} V^T)(V\Sigma^+{n\times m}U^T)=U\Sigma{m\times n}\Sigma^+_{n\times m}U^T=U\begin{pmatrix}I_r&amp;0\0&amp;0\end{pmatrix}_{m\times m}U^T$ 得出以下3个性质： 对称性：$(AA^+)^T=AA^+$ $AA^+=u_1u_1^T+\,…\,+u_ru_r^T, U=(u_1,\,…\,u_r,\,u_{r+1}\,…\,,u_n)$ $AA^+=R^m$到$C(A)$的正交投影矩阵，$AA^+|{C(A)}=id, AA^+|{N(A^T)}=0$ 证明1：$AA^+x=(u_1u_1^T+\,…\,+u_ru_r^T)x=(u_1^Tx)u_1+\,…\,+(u_r^Tx)u_r​$，由奇异值svd分解得到$V=(v_1,\,…\,,v_r)​$是$A^T​$列空间（即$C(A^T)​$）的单位正交特征向量基，而$U=(u_1,\,…\,,u_r)​$是$C(A)​$的单位正交特征向量基，所以$AA^+​$是投影到$C(A)​$的正交投影矩阵（即保留了$C(A)​$的部分），因此$AA^+​$限制在$C(A)​$的变换即变成了恒等变换。而$U​$中$(u_{r+1}\,…\,u_m)​$和$U^T​$中$(u_{r+1}\,…\,u_m)^T​$即属于$N(A^T)​$的基乘以矩阵$\begin{pmatrix}I_r&amp;0\0&amp;0\end{pmatrix}_{m\times m}​$中右下角的$0​$相当于对属于$N(A^T)​$的部分做了零变换。 证明2：$A^+u_j={1\over \sigma_j}v_j\Rightarrow AA^+u_j=A({1\over\sigma_j}v_j)={1\over \sigma_j}Av_j$ 再根据奇异值分解中$Av_j=\sigma u_j, (1\le j \le r)$ 得$AA^+u_j=u_j(1\le j\le r),\ AA^+u_j=0(r+1\le j \le m)$ 验证：$(AA^+)(AA^+)=U\begin{pmatrix}I_r&amp;0\0&amp;0\end{pmatrix}_{m\times m}U^TU\begin{pmatrix}I_r&amp;0\0&amp;0\end{pmatrix}_{m\times m}U^T$，由于从svd分解知道$U$是单位正交特征向量基 ，因此：$U^T=U^{-1}\Rightarrow (AA^+)(AA^+)=U\begin{pmatrix}I_r&amp;0\0&amp;0\end{pmatrix}_{m\times m}U^T=AA^+$，这正是投影的性质：多次投影结果还是第一次投影结果。 结果：$\forall\ p\in R^m, b=p+e, p\in C(A), e\in N(A^T), AA^+b=p$ (3)$A^+A=(V\Sigma^+{n\times m}U^T)(U\Sigma{m\times n} V^T)=V\begin{pmatrix}I_r&amp;0\0&amp;0\end{pmatrix}_{n\times n}V^T$ 得到以下三个性质（证明同上）： $(A^+A)^T=A^+A$ $A^+A=v_1v_1^T+\,…\,+v_rv_r^T$ $A^+A=R^n$到$C(A^T)$的正交投影矩阵（$A^+A|{C(A^T)}=id,\quad A^+A|{N(A)}=0$）: $\forall\ x\in R^n=C(A^T)\bigoplus N(A)),\ x=x_{1,r}+x_{r+1,n}, \ x_{1,r}\in C(A^T),\ x_{r+1,n}\in N(A^T),\ A^+Ax=A^+A(x_1,\,…\,x_r,x_{r+1},\,…\,x_n)=x_{1,r}$ 为什么称为伪逆、左逆、右逆 例子注：$u_1, u_2,u_3$ 是$R^m$的一组基底那么它是${Av_1\over \sigma_1}$，那么很容易计算出来，是${1\over\sqrt{2}}\begin{pmatrix}1\1\0\end{pmatrix}$那$u_2$和$u_3$ 分别是0所对应的特征向量，$u_2$和$u_3$可以看成是三维空间里头，$u_1$的正交补所给出来的单位正交的向量。 特例 Jordan标准形的伪逆推导结论：$J_n^+=J_n^T$，Jordan标准形的伪逆是它自己的转置。 Moore-Penrose伪逆E.H.Moore伪逆 Penrose伪逆注： A可以是mxn的复数矩阵，这样的话(3)(4)里面就变成共轭转置。 Penrose伪逆与E.H.Moore伪逆定义是等价的。 $(1)AXA =A \Rightarrow AXAX=AX\Rightarrow (AX)^N=AX\Rightarrow AX$ 是幂等矩阵，投影矩阵$(2)XAX=X\Rightarrow XAXA=XA\Rightarrow (XA)^N=XA\Rightarrow XA$ 是幂等矩阵，投影矩阵$(3)(AX)^T=AX\Rightarrow AX$ 是对称矩阵$(4)(XA)^T=XA\Rightarrow XA$ 是对称矩阵 通过奇异值分解得到的伪逆矩阵$A^+$，$AA^+: R^m \rightarrow C(A)$，$A^+A:R^n\rightarrow C(A^T)=C(A^+)$，前文已经证明两者都是对称的，所以符合Penrose对伪逆矩阵的定义。对于伪逆唯一性的证明上文图片太小可以放大来看。 伪逆的应用之最小二乘法引言但是我们需要求$e$ 即误差最小的解！但是这时候$A_{m\times n}$不是列满秩不存在逆矩阵，于是自然地想到利用伪逆求解。 伪逆求解正规方程——最佳最小二乘解注：由于$A^+$ 来自于：$A^+U^T=V\Sigma^{+},\ (v_1\,…\,v_r)\in C(A^T),\ (v_{r+1}\,…\,v_n)\in N(A),\ (u_1\,…\,u_r)\in C(A),\ (u_{r+1}\,…\,u_m)\in N(A^T),\\Sigma^+=\begin{pmatrix}{1\over \sigma_1}\&amp;{1\over \sigma_2}\&amp;&amp;.\&amp;&amp;&amp;.\&amp;&amp;&amp;&amp;{1\over \sigma_r}\&amp;&amp;&amp;&amp;&amp;0\end{pmatrix}_{n\times m}\Rightarrow A^+: C(A)\rightarrow C(A^T)$，另外由于 $A^TAx=0, Ax=0$ 同解所以零空间相同。 最佳最小二乘解的四个基本子空间]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[马尔科夫矩阵和正矩阵]]></title>
    <url>%2F2017%2F08%2F06%2FMarkov_matrix%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第9讲：马尔科夫矩阵和正矩阵 引言 马尔科夫链详细参考：Markov chain Markov Matrix正矩阵 马尔科夫矩阵定义 马尔科夫矩阵性质 正马尔科夫矩阵 正马尔科夫矩阵的性质 例子 人口流动模型 正矩阵 谱半径Spectral radius 定义为谱半径是矩阵特征值模的最大值，而非最大特征值，注意：矩阵来自于线性变换（也叫线性算子），因此线性变换也有谱半径，详询wiki: 谱半径Spectral radius。 ##Perron-Frobenius theorem 这个原理应用在统计推断，经济，人口统计学，搜索引擎的基础。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性变换2]]></title>
    <url>%2F2017%2F08%2F05%2Flinear_transformation_2nd_part%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第五讲：线性变换2 前言对于给定的线性变换选取适当的基底使得其矩阵表示尽可能简单，我们引入了线性变换的矩阵表示对于从$n$维的向量空间$V$到$m$维的向量空间$W$的线性变换$\sigma$，我们取定$V$的一组基$v_1$到$v_n$取定W的一组基$w_1$到$w_m$，那线性变换$σ$作用在$v_1$到$v_n$上可以被$w_1,…,w_m$线性表示，表示的系数我们被一个$m×n$的矩阵$A$去描述，那么这样线性变换$σ$就跟这个$m×n$的矩阵$A$一一对应。线性变换的矩阵表示要依赖于我们基底的选取，一般说来如果基做了改变，同一个线性变换它会有不同的矩阵表示，那我们希望找出线性变换与基底选取无关的性质，这样当我们借助矩阵来研究线性变换的这些性质的时候就可以利用好基底下面尽可能简单的矩阵表示。 恒等变换与基变换恒等变换就是不变，那么不变的线性变换对应单位矩阵。 the 9th property of determinant: the determinant of $AB$ is det $A$ times det $B$: $|AB| = |A||B|$ 因此：由于$(\sigma_1\,….\,\sigma_n)$ 和 $(\beta_1\,…\,\beta_n)$ 都是基向量，因此都是列满秩，又是 $n$ 维，所以可逆，再推出$P$可逆。否则 $|\alpha_1\,…\,\alpha_n|\ne|\beta_1\,…\,\beta_n||P|$ 基变换的应用一张256x256的灰度图像 注意：$C^N$是$n$维元素可为复数的基 图像的其中3种基底 小波基好求它的逆，傅里叶基也好求它的逆。如果是$4\times4$纯色图像直接用小波基或者傅里叶基的第一个分量$w_1$和$\xi_1$做基底，表示成$c_1w_1=W\begin{pmatrix}c_1\0\0\0\end{pmatrix}$和$c_1\xi_1=\xi\begin{pmatrix}c_1\0\0\0\end{pmatrix}$。而像素之间变换比较剧烈的图像可用小波基中的 $c(w_3+w_4)$ 和傅里叶基中的 $c\xi_3$ 。 jpeg 图像本身是用系数矩阵$c$表示，那么所谓的压缩和传输图像也是压缩和传输这个矩阵$c$。压缩做的就是用尽可能少的信息（数据）去代表原有的信息（数据），这个过程会丢失一些不重要的信息（数据），对应到矩阵上就是$c$的非0项元素比较少（这个要求用更少数量的基底向量就能接近描述出原来的矩阵，越少越好）。由于 $c=W^{-1}x$ 因此能不能快速计算基底的逆也很重要，而小波基和傅里叶基正符合此特点。 线性变换在不同基下的矩阵 定理：$n$向量空间$V$上的线性变换$\sigma$在$V$的不同基下的矩阵是相似矩阵。 由上图可得：$I_1$ 和 $I_2$ 是恒等变换$(\beta_1\,…\,\beta_n)=I_1(\beta_1\,…\,\beta_n)=(\alpha_1\,…\,\alpha_n)P$$(\alpha_1\,…\,\alpha_n)=I_2(\alpha_1\,…\,\alpha_n)=(\beta_1\,…\,\beta_n)P^{-1}$线性变换复合角度：$\sigma=I_2\,\sigma\,I_1\,\rightarrow\,B=P^{-1}AP$ 同一个线性变换在不同基下的不变性当我们借助于矩阵来研究线性变换的时候，我们希望研究线性变换与基底选取无关的性质。由以上的讨论我们知道这个向量空间$V$到自身的线性变换在不同基下的矩阵表示是互为相似矩阵的。因此，所谓与基底选取无关的性质也就是相似变换下不变的性质，那么这样自然地研究相似不变量是线性代数中很重要的内容。我们知道对于一个矩阵而言特征多项式、特征值、迹、行列式、矩阵的秩等等都是矩阵的相似不变量，这样我们就称一个n维向量空间$V$上线性变换在$V$的一组基下的矩阵$A$，把矩阵表示$A$的特征多项式、特征值、迹行列式等等就叫做这个线性变换的特征多项式、特征值 、迹、行列式。 矩阵分解与基变换给定一个$R^n$到$R^m$的线性变换$σ$，它在$R^n$中的标准基$e_1$到$e_n$和$R^m$的标准基$ẽ_1,…,ẽ_m$下的矩阵是 $A$ ，$σ$作用在$e_1 … e_n$上面就等于$\tilde{e}_1,…, \tilde{e}_m$去乘以矩阵$A$，也就是说$σ$作用在$e_j$上，就等于$A$的第j列，也就是$A$去乘以$e_j$，因此这个线性变换就可以表示成对任何的$n$维向量$v$，那么$σ$作用在$v$上就是矩阵$A$去乘以$V$ ：$$\sigma(e_1\,…\,e_n)=(\tilde{e}_1 \,…\,\tilde{e}_m)A\rightarrow\sigma(e_j)=Ae_j$$ 接下来做基变换，第一个改变输入基，第二个改变输出基，第三个输入输出基都改。 对角化矩阵视为线性变换 由上可得 $\sigma(x_1\,…\,x_n)=(x_1\,…\,x_n)\Lambda=S\Lambda$ ，$x$ 为特征向量基，另外基变换 ${id}_1(S)=S={e}S$$σ$这个线性变换在A的特征向量作为的新基下面，它的矩阵表示是 $\Lambda$ 这个对角阵。而$σ$从 $R^n$ 到 $R^n$在标准基下的矩阵是$A$，$σ$在特征向量基下的矩阵表示是对角阵 $\Lambda$。那么输入$x$这组基，输出$e$这组基，这个恒同变换，它的矩阵表示是 $S$ 。如果输入$e$这组基 ，输出$x$这组基这个恒同变换，它的矩阵表示是$S^{-1}$。 奇异值分解视为线性变换 线性变换的核与像定义 线性变换的零度与秩 线性变换秩的证明 注：$L(\sigma(v_1),\,…\,,\sigma(v_n))$ 符号含义：由 $\sigma(v_1),\,…\,,\sigma(v_n)$ 线性张成。 线性变换的维度公式 单射满射可逆中学学过的单射双射满射 线性变换下的单射（injective），满射（surjective）与逆（inverse） 第一个等价符号证明（反证法）：如果单射无法推出核只有${0}$，那么假设$\exists\,\alpha(\ne0)\in{ker\,\sigma}$ 那么$\sigma(\alpha)=0$，又因为$\sigma(0)=0$, 即$\sigma(\alpha\,or\,0)=0$与单射矛盾。反之，如果$\sigma(v_1)=0, \sigma(v_2)=0$，根据线性变换的定义或者性质得：$\sigma(v_1-v_2)=0\rightarrow v_1-v_2\in ker\,\sigma={0}\rightarrow v_1=v_2\rightarrow \sigma$ 是单射。因此：$\sigma$是单射$\Leftarrow\Rightarrow ker\,\sigma={0}$ 例子： 不变子空间定义 不变子空间的意义 那从这里头我们看到，我们希望把大空间分解成不变子空间的直和，从而能够取出合适的基底，从而使得线性变换在这组基底下的矩阵表示能够成为对角块的形状，那么对于线性变换的研究就转化成它限制在不变子空间上的研究以此为基础，看一下幂零变换的结构。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性变换1]]></title>
    <url>%2F2017%2F08%2F04%2Flinear_transformation_1st_part%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第四讲：线性变换1 前言历史上英国数学家Arthur Cayley是为了描述线性变换的复合而引入矩阵的乘法，从而使矩阵成为数学的研究对象。线性变换是两个向量空间之间保持线性运算的映射。线性代数就是从其中心问题（求解线性方程组）出发发展起来研究向量空间、线性变换以及研究相关数学问题的数学学科。对有限维向量空间的研究总可以转化成对矩阵的研究，这是线性代数的核心特点。 线性变换的定义性质运算回顾中学阶段学过的函数：$f(x)=2x\quad g(x)=x^{2}\quad l(x)=sin(x)$ 都是一个映射从定义域中的一个数映成值域中的一个数。推广到把向量映射到向量的映射比如f是从 $R^{3}$ 映到 $R^{2}$ 的一个映射：$f:\begin{pmatrix}x\y\z\end{pmatrix}\,\rightarrow\,\begin{pmatrix}2x\3y-z\end{pmatrix}$，我们关心向量空间到向量空间的映射。人们发现平面上的点、空间中的点 、矩阵多项式函数、连续函数等等集合看上去不同但是它们各自的加法和数乘满足同样的性质，于是就引入了向量空间这样的一个抽象的概念来统一地研究向量空间的概念。 向量空间的定义 线性变换的定义 例子 注意，由线性变换的定义 $T:V\,\rightarrow\,W$ 得到 $T(0)=0$ 线性变换的性质 针对第一条证明： 如果 $T(0)\ne0$ 不满足线性变换定义 $T(cx)=cT(x)$，例如： $T(0)=1\,\rightarrow\,T(0)=T(c0)=1\,\ne\,cT(0)=c$ 针对第三条证明：若 $x_{1},\,…\,,x_{n}$ 线性相关，那么存在不全为0的数 $c_{1},\,…\,,c_{n}$ 满足 $c_{1}x_{1}\,+\,…\,+\,c_{n}x_{n}=0$ 即 $T(c_{1}x_{1}\,+\,c_{2}x_{2}\,+\,…\,+\,c_{n}x_{n})=T(0)=c_{1}f(x_{1})\,+\,…\,+\,c_{n}f(x_{n})=0$，即$T(x_{1}),\,…\,,T(x_{n})$ 线性相关。 线性变换的运算加法 数乘 乘积注：线性变换的乘积被定义为线性变换的复合运算 注意：线性变换不满足乘法交换律、消去律，与矩阵乘法类似 逆 幂 多项式 注：由于线性变换不满足乘法交换律，因此$(\sigma\tau)^{m}=\underbrace{(\sigma\tau)(\sigma\tau)\,…\,(\sigma\tau)}_{m个(\sigma\tau)相乘}\ne\sigma^{m}\tau^{m}$ 线性变化的矩阵表示 由于 $T(v_{1})$,$T(v_{2})$, … , $T(v_{3})\,\epsilon\,W$ 这个输出空间, 因此可以进行如下： 例子 线性变换与矩阵之间的关系一一对应 线性变换的乘积与矩阵的乘积 注（极其重要）：这里线性变换的乘积（复合）对应的是矩阵的“左乘”。 线性同构 例：设线性变换$\tau\,:\,R^{3}\rightarrow\,R^{2}$定义为$\tau(x,y,z)=(x+y,y-z)$, 线性变换$\sigma:R^{2}\,\rightarrow\,R^{2}$定义为$\sigma(u,v)=(2u-v,u)$.求线性变换$\sigma\tau:R^{3}\,\rightarrow\,R^{2}$在$R^{3}$与$R^{2}$标准基下的矩阵. 解：注意到$\sigma\tau=\sigma(\tau(x,y,z))=\sigma(x+y, y-z)=(2x+y+z, x+y)$ 因此标准基下线性变化$\sigma(\tau(x\,y\,z)):R^{3}\to\,R^{2}$: $$e_{1}=(1,0,0)^{T}, e_{2}=(0,1,0)^{T}, e_{3}=(0,0,1)^{T}\,\Rightarrow\, I_{3}=(e_{1}\,e_{2}\,e_{3})$$ $\sigma(\tau(e_{1}))=\sigma(\tau(\,(1,0,0)\,)=\begin{pmatrix}2\1\\end{pmatrix}\quad\sigma((\tau(e_{2}))=\begin{pmatrix}1\1\\end{pmatrix}\quad\sigma(\tau(e_{3}))=\begin{pmatrix}1\0\\end{pmatrix}$ $\sigma(\tau(e_{1}\,e_{2}\,e_{3}))=\sigma(\tau(I_{3}))=\underbrace{\begin{pmatrix}2&amp;1&amp;1\1&amp;1&amp;0\end{pmatrix}}_{C}$ 第一个线性变化$\tau(x,y,z)=(x+y,y-z):R^{3}\,\to\,R^{2}$ : $$\tau(e_{1})=\tau(1,0,0)=(1+0,0+0)=(1,0)$$ $$\tau(e_{2})=\tau(0,1,0)=(0+1,1+0)=(1,1)$$ $$\tau(e_{3})=\tau(0,0,1)=(0+0,0+1)=(0,1)$$ $$\tau(I_{3})=\tau(e_{1}\,e_{2}\,e_{3})=\begin{pmatrix}1&amp;1&amp;0\0&amp;1&amp;-1\end{pmatrix}=I_{2}\begin{pmatrix}1&amp;1&amp;0\0&amp;1&amp;-1\end{pmatrix}$$ $$\underbrace{\begin{pmatrix}1&amp;1&amp;0\0&amp;1&amp;-1\end{pmatrix}}_{A}\begin{pmatrix}x\y\z\end{pmatrix}=\begin{pmatrix}x+y\y-z\end{pmatrix}$$ 第二个线性变化$\sigma(u,v)=(2u-v,u): R^{2}\,\to\,R^{2}$: $$\delta_{1}=(1,0)^{T}, \delta_{2}=(0,1)^{T}\,\Rightarrow\, I_{2}=(\delta_{1}\,\delta_{2})$$ $$\sigma(\delta_{1})=\begin{pmatrix}2\1\end{pmatrix},\,\sigma(\delta_{2})=\begin{pmatrix}-1\0\end{pmatrix}\Rightarrow\sigma(\delta_{1}\,\delta_{2})=I_{2}\begin{pmatrix}2&amp;-1\1&amp;0\end{pmatrix}$$ $$\underbrace{\begin{pmatrix}2&amp;-1\1&amp;0\end{pmatrix}}_{B}\begin{pmatrix}u\v\end{pmatrix}=\begin{pmatrix}2u-v\u\end{pmatrix}$$ 发现$BA=C\,\Rightarrow\,\begin{pmatrix}2&amp;-1\1&amp;0\end{pmatrix}\begin{pmatrix}1&amp;1&amp;0\0&amp;1&amp;-1\end{pmatrix}=\begin{pmatrix}2&amp;1&amp;1\1&amp;1&amp;0\end{pmatrix}$，符合上文所说的线性变换的复合是对应矩阵的左乘。 结论：有限维向量空间上的线性变换$\leftarrow\rightarrow$矩阵]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[奇异值分解singular values decomposition]]></title>
    <url>%2F2017%2F08%2F03%2Fsingular_values_decomposition%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第三讲：奇异值分解 前言对角矩阵是我们最喜欢的一类矩阵，对能够相似于对角阵的矩阵能方便地计算其幂和指数，对不能相似于对角阵的方阵。上节课我们讨论了如何求出其尽可能简单的相似标准形及Jordan标准形以上讨论的都是方阵。那么对m乘n的矩阵我们如何来对它进行对角化呢？ 线性代数中最重要的一类矩阵分解即奇异值分解，从而回答以上的问题。对角矩阵是我们最喜欢的一类矩阵，因为给定一个对角阵立即就可以得到它的特征值，行列式，幂和指数函数等等。对角矩阵的运算跟我们熟悉的数的运算有很多相似之处，而一个n阶的矩阵相似于对角阵当且仅当它存在着n个线性无关的特征向量。特别地，实对称矩阵一定会正交相似于对角阵，也就是说给你一个实对称矩阵，一定存在着正交矩阵$Q$把它的列向量记成$v_1$到$v_n$，它能够满足$Q^TAQ$等于$\lambda$，$\lambda$是一个对角阵，它的对角元是$A$的特征值，那么其中$Q$的列向量$v_i$，它是矩阵$A$的属于特征值，$\lambda_i$的特征向量，也就是满足$Av_i$等于$\lambda_iv_i$。我们现在有个问题是说，如果对于$m \times n$的一个矩阵，我们如何来”对角化”它。那么也就是说在什么意义上，我们能够尽可能地。把$m \times n$的一个矩形的阵向对角阵靠拢，今天我们来讨论矩阵的奇异值分解它是线性代数应用中，最重要的一类矩阵分解。 $AA^T$与$A^TA$的特性$AA^T$与$A^TA$的特征值 $AA^T$与$A^TA$非0特征值集合 $A^TA$与$AA^T$的特征向量 令$u_i:={Av_i \over \sigma_i}\in\,R^m(1 \le i \le r) $，则 $AA^Tu_i=A(A^T\frac{Av_i}{\sigma_i})=A\frac{A^TAv_i}{\sigma_i}=A\frac{\sigma_i^2v_i}{\sigma_i}={\sigma_i}^2{Av_i \over \sigma_i}={\sigma_i}^2u_i$，得出：$AA^Tu_i={\sigma_i}^2u_i$。又因为：${u_i}^T{u_j}=\frac{(Av_i)^T}{\sigma_i}{Av_j \over \sigma_j}={v_i^T(A^TAv_j) \over \sigma_i\sigma_j}=\frac{\sigma_j^2{v_i}^Tv_j}{\sigma_i\sigma_j}={\sigma_j\over \sigma_i}v_i^Tv_j\rightarrow u_i^Tu_j=\begin{cases}0, &amp; i\ne j\ 1, &amp; i=j\end{cases}$故：${u_i|1\le i \le r}$ 是$AA^T$的单位正交特征向量。 根据假设（$v_1,\,…\,,v_n$是$A^TA$的单位交基，$\sigma_1^2,\,…\,,\sigma_n^2$是$AA^T$的特征值）得：$A^TAv_i=\sigma_i^2v_i(1\le i\le r) \rightarrow v_i^TA^TAv_i=v_i^T\sigma_i^2v_i=\sigma_i^2v_i^Tv_i \rightarrow ||Av_i||^2=\sigma_i^2 \rightarrow|Av_i|=\sigma_i$ 从$AA^T$得出SVD$(1)u_i:={Av_i \over \sigma_i}\in\,R^m(1 \le i \le r) \rightarrow Av_i=\sigma_iu_i\ (2)A^TAv_i={\sigma_i}^2v_i, (i\le i \le r)\rightarrow A^T{Av_i\over \sigma_i}=\sigma_iv_i\rightarrow A^Tu_i=\sigma_iv_i$ 由上式子得：$U$是$A$列空间的一组单位正交基，$V$是$A^T$的列空间的一组单位正交基。$\sigma_i$是$Av_i$的长度，计$\begin{pmatrix}\sigma_1&amp;&amp;&amp;&amp;\&amp;.&amp;&amp;&amp;\&amp;&amp;.&amp;&amp;\&amp;&amp;&amp;.&amp;\&amp;&amp;&amp;&amp;\sigma_r\end{pmatrix}$为$\Sigma$，得：$A_{m\times n}V_{n\times r}=U_{m\times r}\Sigma_{r\times r}\rightarrow A_{m\times n}=U_{m\times r}\Sigma_{r\times r} {V^{-1}}{r\times n}\=U{m\times r}\Sigma_{r\times r} {V^{T}}_{r\times n}$ 向量形式：$A=\sum_{i=1}^r \sigma_i u_i{v_i}^T$ SVD形式 例题 求$u_3$两种方法： 方法1：$AA^Tu_3=\begin{pmatrix}1&amp;0\0&amp;1\1&amp;-1\end{pmatrix}\begin{pmatrix}1&amp;0&amp;1\0&amp;1&amp;-1\end{pmatrix}u_3=\begin{pmatrix}1&amp;0&amp;1\0&amp;1&amp;-1\1&amp;-1&amp;2\end{pmatrix}u_3=0u_3\rightarrow u_3={1\over\sqrt{3}}\begin{pmatrix}1\ -1\ -1\end{pmatrix}$ 方法2：$u_j:=\begin{pmatrix}x\y\z\end{pmatrix}, \sum_{i=1}^{r=3}u_iu_j=0 (i\ne j), ||u_j||^2=1\rightarrow u_{j=3}={1\over\sqrt{3}}\begin{pmatrix}1\ -1\ -1\end{pmatrix}$ svd几何意义 svd应用svd与矩阵的四个基本子空间 svd与图像压缩 奇异值与特征值关系 奇异值与奇异矩阵as]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[傅里叶级数]]></title>
    <url>%2F2017%2F08%2F02%2FFourier_series%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第10讲：傅里叶级数 引言 傅里叶级数Fourier series定义定义1设$f(x)$是周期为$2\pi$的有限个分段（piecewise）的连续函数（ continuous function）（即在$[\pi,-\pi]$中只有有限个点不连续，且不连续点的左右极限存在），那么它的傅里叶级数是 $F={a_0\over 2}+\sum\limits_{k=1}^{\infty}(\ a_kcos(kx)+b_ksin(kx)\ ), a_k={1\over \pi}\int_{-\pi}^{\pi}f(x)cos(kx)dx, b_k={1\over \pi}\int_{-\pi}^{\pi}f(x)sin(kx)dx,k=0,1,\ldots$，这个级数又称为傅里叶级数的实形式。 $f(x)$举例如下的$(1)$，而 $(2)$ 在周期内的不连续点处无极限。 定义2$f(x)$如上，它的傅里叶级数的复形式是$F=\sum\limits_{k=-\infty}^{+\infty}c_ke^{ikx}, c_k={1\over 2\pi}\int_{-\pi}^{\pi}f(x)e^{-ikx}dx$. 推导如下： 在定义1中，使用欧拉公式：$e^{ix}=cosx+isinx\Rightarrow cosx={e^{ix}+e^{-ix}\over 2},\ sinx={e^{ix}-e^{-ix}\over 2i}$ ，定义1中的傅里叶级数变成$F={a_0\over 2}+\sum\limits_{k=1}^{\infty}[{a_k\over 2}(e^{ikx}+e^{-ikx})-{ib_k\over 2}(e^{ikx}-e^{-ikx})]={a_0\over 2}+\sum\limits_{k=1}^{\infty}({a_k-ib_k\over 2}e^{ikx}+{a_k+ib_k\over 2}e^{-ikx}).$ 其中$a_k-ib_k={1\over 2\pi}\int_{-\pi}^{\pi}f(x)(e^{ikx}+e^{-ikx})dx-{i\over 2\pi}\int_{-\pi}^{\pi}f(x)\frac{e^{ikx}-e^{-ikx}}{i}dx ={1\over \pi}\int_{-\pi}^{\pi}e^{-ikx}dx,\ a_k+ib_k={1\over \pi}\int_{-\pi}^{\pi}e^{ikx}dx​$ , 令$c_k={a_k-ib_k\over 2}={1\over 2\pi}\int_{-\pi}^{\pi}f(x)e^{-ikx}dx,k=1,2,\ldots\quad c_{-k}={a_k+ib_k\over 2}={1\over 2\pi}\int_{-\pi}^{\pi}f(x)e^{ikx}dx,k=1,2,\ldots​$ 这样就得到定义2。注意：正如泰勒级数，这里并没有断言$f(x)​$等于它的傅里叶级数。 定理设$f(x)$是周期为$2\pi$的周期函数，$f(x)$和$f’(x)$均在$[-\pi, \pi]$上是分段连续的，则$f(x)$的傅里叶级数收敛，且在任意连续点$x=a$等于$f(a)$，在不连续点$x=a$等于${1\over 2}[lim_{x\rightarrow a^{+}}f(x)+lim_{x\rightarrow a^{-}}f(x)]$。 内积空间inner product space设$V$是一个向量空间（线性空间）（$R$或$C$上），$V$上的一个内积是这样一个函数 (-,-) : $V\times V\rightarrow R\ or\ C$ 满足： $\forall u\in V, (u,u)\ge0$，且若$(u,u)=0\rightarrow u=0$ $(c_1u+c_2v,w)=c_1(u,w)+c_2(v,w), u,v,w\in V, c_1,c_2\in R\ or\ C$ $\overline{(u,v)}=(v,u)$ 共轭对称 注：没有假设$v$是有限维的。第一条：$u$跟自己的内积必须是一个实数且是一个正数，或者说更确切地是一个非负数，如果$u$跟自己的内积是等于0的，那么就可以确定$u$就是$0$向量。第二条：两个向量的线性组合跟另一个向量的内积相当于两个向量跟另一个向量先作内积再做线性组合。第三条：$u$和$v$的内积与$v$和$u$的内积是一个共轭的关系，如果这个函数是定义在$V\times V\rightarrow R$，那么这个内积函数是个对称的，$u,v$的内积与$v,u$的内积是一样的，如果定义在复数上，那么就差一个共轭。 令$||u||=\sqrt{(u,u)}$，若$||u||=1$，则$u$ 是一个单位向量。任何一个向量$u\ne 0\rightarrow {v\over ||v||}$是一个单位向量，关于范数($||·||$)，这里范数是长度。 例 $V=R^2,u=\begin{pmatrix}a_1\a_2\end{pmatrix}, v=\begin{pmatrix}b_1\b_2\end{pmatrix},(u,v)=u^T v=a_1b_1+a_2b_2$ 是一个内积，$||u||=\sqrt{(a_1^2+a_2^2)}$。若$V=C^2$，$u,v\in C, (u,v)=u^T\bar{v}=a_1\overline{b_1}+a_2\overline{b_2}$ 。 $C[a,b]$是定义在区间$[a,b]$上的全体连续实函数构成的向量空间。定义连续函数的内积为$(f,g)=\int_{a}^{b}f(x)g(x)dx$ 。验证这个式子：$f(x)\in C[a,b], (f,f)\ge 0$ ，即 $(f,f)=\int_{a}^{b}{f(x)}^2dx=\int_{a}^{b}{|f(x)|}^2dx\ge 0$。若$(f,f)=0$，即$\int_{a}^{b}{|f(x)|}^2dx=0$，令$F(t)=\int_{a}^{t}{|f(x)|}^2dx, a\le t \le b$，则$F(t)=0, F(t)$可导，$F’(t)={|f(t)|}^2=0$，即$f(t)=0,t\in [a,b]$。在这里函数的长度的平方定义为函数与自身的内积，即$||f(x)||^2=(f(x),f(x))=\int_{a}^{b}f(x)f(x)dx$。 在例2中，若$C[a,b]$是$[a,b]$上的连续复函数的向量空间，则内积定义为：$(f,g)=\int_{a}^{b}f(x)\overline{g(x)}dx$。 标准正交系orthonormal system总结：若f(x)在区间$[a,b]$存在傅里叶级数，那么f(x)的傅里叶级数是f(x)在标准正交系${\frac{1}{\sqrt{2\pi}}, \frac{1}{\sqrt{\pi}}sinx, \frac{1}{\sqrt{\pi}}cosx, \frac{1}{\sqrt{\pi}}sin2x, \frac{1}{\sqrt{\pi}}cos2x, \ldots}$下的投影。 周期函数的傅里叶级数对傅里叶级数的实数形式$F={a_0\over 2}+\sum\limits_{k=1}^{\infty}(\ a_kcos(kx)+b_ksin(kx)\ ), a_k={1\over \pi}\int_{-\pi}^{\pi}f(x)cos(kx)dx, b_k={1\over \pi}\int_{-\pi}^{\pi}f(x)sin(kx)dx,k=0,1,\ldots$进行变量代换，令 $x={\pi\over L}t, k=n$ 得：$ dx={\pi\over L}dt,\ t=\cases{L, x=\pi\ -L, x=-\pi}\Rightarrow f(t)={a_0\over 2}+\sum\limits_{n=1}^{\infty}[a_ncos({n\pi t\over L})+b_nsin({n\pi t\over L})],\ a_n={1\over L}\int_{-L}^{L}f(t)cos({n\pi t\over L})dt, \b_n={1\over L}\int_{-L}^{L}f(t)sin({n\pi t\over L})dt, n=0,1,\ldots$，对应的复数形式为： 投影注：$e^{ikx}=cos(kx)+isin(kx)\rightarrow (e^{ikx},e^{ikx})=2L, L$为半周期的绝对值，另外根据复函数的向量空间的内积定义为：$(f,g)=\int_{a}^{b}f(x)\overline{g(x)}dx \rightarrow (f(x),e^{ikx})$在周期 $[-\pi,\pi]$ 下为 $\int_{-\pi}^{\pi}f(x)e^{-iks}dx$ 。 关于傅里叶变换的注记Fourier series傅里叶级数和Fourier transformation傅里叶变换是傅里叶分析的主要部分。设$f(t)$周期$T=2L$，则$f(t)$的傅里叶级数展开为$f(t)=\sum\limits_{k=-\infty}^{\infty}c_ke^{\frac{ik\pi}{L}t},c_k={1\over 2L}\int_{-L}^{L}f(t)e^{\frac{-ik\pi}{L}t}dt$ ($c_k$是$f(t)$在$e^{\frac{ik\pi}{L}t}$上的投影)。现在考虑定义在$(-\infty, +\infty)$上的非周期函数$f(t)$，它有傅里叶级数展开形式吗？ 给定$L&gt;0$，定义$f_L(t)=\cases{f(t), |t|&lt;L\0 , \quad\ |t| \ge L}$。假设$L\rightarrow \infty$时，$f_L(t)$（一致）趋近于$f(t)$。函数 $f_L(t)$ 能被周期延拓，即令$F_L(t)=\cases{f(t), -L&lt; t \le L\ F_L(t+2L), T=2L}$ 则 $F_L(t)$有傅里叶级数。 当 $-L&lt;t&lt;L,f(t)=f_L(t)=F_L(t)=\sum\limits_{k=-\infty}^{\infty}c_k(L)e^{\frac{ik\pi}{L}t},c_k(L)={1\over 2L}\int_{-L}^{L}f_L(t)e^{\frac{-ik\pi}{L}t}dt$ 因为 $f_L(t)=0, |t|&gt;L \rightarrow c_k(L)={1\over 2L}\int_{-L}^{L}f_L(t)e^{\frac{-ik\pi}{L}t}dt={1\over 2L}\int_{-\infty}^{\infty}f_L(t)e^{\frac{-ik\pi}{L}t}dt$ 由于 $k\rightarrow\infty$ 同时 $L\rightarrow \infty$ ，所以等式右边的指数项未知，因此做变量代换，令 $\tilde{f}L(w)=\int{-\infty}^{\infty}f_L(t)e^{-iwt}dt$，令 $w_k={k\pi\over L}$ 则$c_k(L)={1\over 2L}\tilde{f}(\frac{k\pi}{L})={1\over 2L}\tilde{f}({w_k})={1\over 2\pi}\tilde{f}({w_k})(w_{k+1}-w_k)$ 那么得到傅里叶展开的新形式：$f_L(t)=F_L(t)={1\over 2\pi}\sum\limits_{-\infty}^{+\infty}\tilde{f}_L(w_k)e^{iw_kt}\Delta w_k, \tilde{f}L(w)=\int{-\infty}^{+\infty}f_L(t)e^{-iw_kt}dt, \Delta w_k=w_{k+1}-w_{k}={\pi\over L}$。当$L\rightarrow +\infty, \Delta w\rightarrow 0$，等式左边$f_L(t)$（一致）趋近于$f(t)$，右边就趋近于一个积分形式：$ f(t)={1\over 2\pi}\int_{-\infty}^{+\infty}\tilde{f}_L(w)e^{iwt}dw$， 称$\tilde{f}(w)$是$f(t)$的傅里叶变换，$f(t)$是$\tilde{f}(w$)的逆傅里叶变换。 $f(t)$实际上是关于时间函数的$sin\ cos$之间叠加出来的，那么$\tilde{f}(ω)$是关于这些频率叠加出来的，它是频率的函数。讲复矩阵的时候将会回到这个傅里叶变换，会考虑傅里叶变换的离散形式，那么$f(x)$或者$f(t)$就被一个向量替换，$\tilde{f}(ω)$也被一个向量替换，它们之间互逆的这种傅里叶变换或者逆傅里叶变换的关系，实际上就是通过一个傅里叶矩阵进行互相转换的，以及相应的快速的傅里叶变换。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[positive definite and least squares]]></title>
    <url>%2F2017%2F08%2F01%2Fpositive_definite_and_least_square%2F</url>
    <content type="text"><![CDATA[positive definiteWhen a symmetric matrix $A$ has one of these five properties, it has them all and $A$ is positive definite: all n eigenvalue are positive. all n principal minors(n upper left determinants) are positive. all n pivots are positive. $x^{T}Ax$ is positive except when $x = 0$ (this is usually the definition of positive definiteness and the energy-based definition). $A$ equals $R^{T}R$ for a matrix $R$ with independent columns. Let us prove the fifth rule. If $A = R^{T}R$, then $$\begin{eqnarray}x^{T}Ax&amp;=&amp;x^{T}R^{T}Rx \nonumber\&amp;=&amp;(x^{T}R^{T})Rx \nonumber\&amp;=&amp;(Rx)^{T}Rx \nonumber\&amp;=&amp;|Rx| \nonumber\&amp;\ge&amp;0 \nonumber\end{eqnarray}$$ And the columns of $R$ are also independent, so $|Rx|=x^{T}Ax&gt;0$, except when $x$=0 and thus $A$ is positive definite. $A^{T}A$$A_{m\times n}$ is almost certainly not symmetric, but $A^{T}A$ is square (m by m) and symmetric. We can easily get the following equations through left multiplying $A^{T}A$ by $x^{T}$ and right multiplying $A^{T}A$ by $x$: $$\begin{eqnarray}x^{T}A{^TA}x&amp;=&amp;x^{T}(A{^TA})x\nonumber\&amp;=&amp;(x^{T}A^{T})Ax\nonumber\&amp;=&amp;(Ax)^{T}(Ax)\nonumber\&amp;=&amp;|Ax|\nonumber\&amp;\ge&amp;0\nonumber\end{eqnarray}$$ If $A_{m\times\,n}$ has rank $n$ (independent columns), then except when $x = 0$, $Ax=|Ax|=x^{T}(A{^TA})x&gt;0$ and thus $A^{T}A$ is positive definite. And vice versus. Besides, $A^{T}A$ is invertible only if $A$ has rank $n$ (independent columns). To prove this, we assume $Ax=0$, then: $$\begin{eqnarray}Ax&amp;=&amp;0\nonumber\(Ax)^{T}(Ax)&amp;=&amp;0\nonumber\(x^{T}A{^T})(Ax)&amp;=&amp;0\nonumber\x^{T}A{^T}(Ax)&amp;=&amp;x^{T}0\nonumber\(A{^TA})x&amp;=&amp;0\nonumber\end{eqnarray}$$ From the above equations, we know solutions of $Ax=0$ are also solutions of $(A{^TA})x=0$. Because $A_{m\times\,n}$ has a full set of column rank (independent columns), $Ax=0$ only has a zero solution as well as $(A{^T}A)x=0$. Moreover, if $A{^T}A$ is invertible, then $A_{m\times\,n}$ has rank $n$ (independent columns). We also notice that if $A$ is square and invertible, then $A{^T}A$ is invertible. Overall, if all columns of $A_{m\times\,n}$ are mutual independent, then $(A{^T}A)$ is invertible and positive definite as well, and vice versus. least squareWe have learned that least square comes from projection :$$b-p=e\Rightarrow\,A^{T}(b-A\hat{x})=0\Rightarrow\,A^{T}A\hat{x}=A^{T}b$$Consequently, only if $A^{T}A$ is invertible, then we can use linear regression to find approximate solutions $\hat{x}=(A^{T}A)^{-1}A^{T}b$ to unsolvable systems of linear equations. According to the reasoning before, we know as long as all columns of $A_{m\times\,n}$ are mutual independent, then $A{^T}A$ is invertible. At the same time we ought to notice that the columns of $A$ are guaranteed to be independent if they are orthoganal and even orthonormal. In another prospective, if $A^{T}A$ is positive definite, then $A_{m\times\,n}$ has rank $n$ (independent columns) and thus $A^{T}A$ is invertible. Overall, if $A^{T}A$ is positive definite or invertible, then we can find approximate solutions of least square.]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正定矩阵]]></title>
    <url>%2F2017%2F08%2F01%2Fpositive_definite_matrix%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第一讲：正定矩阵 引言 矩阵特征值的正负在求解微分方程和差分方程时，会影响解是否收敛，例如上图如果$\lambda_i &lt; 0$那么$e^{\lambda_i t}$ 随着$t\rightarrow \infty, e^{\lambda_it}\rightarrow0$ 主子式 实对称矩阵A正定的充要条件下列6项条件，满足任意一项即可判定实对称矩阵$A$为正定矩阵： 证明$(1)\Rightarrow(2):$ 对实对称矩阵$A$，那么存在正交阵$Q$，使得$AQ=Q\Lambda \rightarrow A=Q\Lambda Q^T$，其中$\Lambda=diag(\lambda_1,\,…\,,\lambda_n)$。于是对于任意非零向量$x$，有$x^TAx=x^TQ\Lambda Q^Tx=y^T \Lambda y=\lambda_1 {y_1}^2+\,…\,+\lambda_n {y_n}^2&gt;0, y=Q^Tx=(y_1,\,…\,,y_n) \ne\vec{0}$ $(2)\Rightarrow(1):​$ 设$Ax=\lambda x(x\ne0)​$ 则$0&lt;x^TAx=x^T\lambda x=\lambda||x||^2​$，因此所有$\lambda_i&gt;0​$。 $(2)\Rightarrow(3):$ 由于行列式等于矩阵特征值的乘积，故$(2)\Rightarrow(1)\Rightarrow (3)det A=\lambda_1\,…\,\lambda_n&gt;0$ ： $(2)\, 0&lt;\begin{pmatrix}x_k^T&amp;0\end{pmatrix} \begin{pmatrix}A_k&amp;*\*&amp;*\end{pmatrix}\begin{pmatrix}x_k\0\end{pmatrix}={x_k}^T A_k x_k = {x_k}^T \begin{pmatrix} \lambda_1&amp;\&amp;\ddots\&amp;&amp;\lambda_k \end{pmatrix} x,\, (1 \le k \le n) \\Rightarrow (1) \lambda_i &gt; 0,(1\le i \le k, 1 \le k \le n) \Rightarrow (3) detA_k&gt;0, (1 \le k \le n)$ $(3)\Rightarrow(4)$：顺序主子式与主元有直接联系，因为第k个主元$d_k={det A_k \over det A_{k-1}}$，所以$(3) \Rightarrow (4)\,d_k &gt; 0$，其中$A_k$是第$k$个顺序主子矩阵（the k-th leading principal sub-matrix）。 $(4) \Rightarrow (2)$：由对称矩阵的Gauss消元法得$A=LDL^T$且对角阵$D=diag(d_1,\,…\,d_n)$ 的对角元为A的主元，$L$是下三角矩阵，$L^T$ 是上三角矩阵，而且根据分解结果知道$L$的主对角线上全元素为1，也即$L^T$的主元全为1，即$L^T$行列式为1且是方阵，那么这俩都可逆。因为$(4):d_1,\,…\,,d_n$大于0，那么到：$x\ne 0\Rightarrow y=L^Tx\ne 0\Rightarrow x^TAx=x^TLDL^Tx=y^TDy=d_1y_1^2+…+d_ny_n^2&gt;0$ 。 可逆矩阵齐次方程只有零解 $(2)\Rightarrow(5)$：$A=LDL^T=L\sqrt{D}\sqrt{D}L^T=(\sqrt{D}L^T)^T(\sqrt{D}L^T)$，此时可取$R=\sqrt{D}L^T$，因为$\sqrt{D}, L^T$ 都可逆且都是方阵，由于$(2)\Rightarrow(3)\Rightarrow(4)$ ，因此$\sqrt{D}&gt;0$，且有上面推导得$|L^T|&gt;0$， 可逆矩阵乘积还是可逆。 根据行列式性质：$ |A||B|=|AB|$, 当$A,B$ 均可逆，那么$|A|&gt;0, |B|&gt;0 \rightarrow |AB|&gt;0$, 所以$AB$也可逆。 或者：$A=Q\Lambda Q^T=Q\sqrt{\Lambda}\sqrt{\Lambda}Q^T=(\sqrt{\Lambda}Q^T)(\sqrt{\Lambda}Q^T)$，此时可取 $R=\sqrt{\Lambda}Q^T$ ，同理可得。 $(5)\Rightarrow(2)$：$A=R^TR\Rightarrow x^TAx=x^TR^TRx=(Rx)^TRx=||Rx||^2 \ge 0$且$R$是列满秩，除了$x=0$之外，其余 $x^TAx=||Rx||^2 &gt; 0$，即$(5)\Rightarrow(2)$ $(6)\Leftarrow\Rightarrow(2)$: 典型例子 正定矩阵的性质如果$A,B$是正定矩阵，那么$A+B$也是正定矩阵 如果$A$为正定矩阵，则存在矩阵$C$，满足$A=C^2$ 如果$A$为正定矩阵，则矩阵$A$的幂也是正定的 如果$A$为正定矩阵，矩阵$C$，那么$B=C^TAC$也是正定的 注：其实B称为A的合同矩阵 半正定矩阵的判别条件 二次型定义 注意：这里证明里面 ${A-A^T\over 2}$ 是反对称矩阵，利用反对称矩阵性质，所以 $x^T{A-A^T\over 2}x=0$ 。二次型与判定正定矩阵的第二条准则密切相关。 例子 对角形 二次型化成对角形 注：由于实对称矩阵$A$可以与二次型一一对应，因此，可以借助实对称矩阵研究二次型。 主轴定理principal axis theorem 有心二次型central_conic 三维空间中的二次曲面-6类基本的二次曲面$R^3$种的二次曲面的方程形如:$a_{11}x^2+a_{22}y^2+a_{33}z^2+2a_{12}xy+2a_{13}xz+2a_{23}yz+b_{1}x+b_{2}y+b_{3}z+c=0$. 注：由于二次型可以与实对称对称矩阵一一对应，二次型里面又包括二次曲面，所以实对称矩阵可以跟二次曲面对应起来。 二次型的分类 二次型与特征值 二次型的一个应用——求二次型的几何形状 把二次型的部分去化成对角形的标准型，相应的这个一次项也作了变换，于是再做配方然后去跟基本的形状做比较得出这个曲面的几何形状，这是二次型的一个应用。 合同congruent前言 注：非退化矩阵即满秩矩阵 定义 例子 主轴定理与合同 合同的性质 证明:矩阵$A$左乘可逆矩阵$C^T$相当于做初等行变换，右乘以可逆矩阵$C$相当于做初等列变换，因此根据消元法知道并不改变矩阵$A$的秩。对称性保持证明在于二次型定义可以看到。 1.利用初等变换不改变矩阵的秩，因为可逆矩阵可以表示为初等矩阵的乘积，而A乘初等矩阵相当于对A作初等变换，所以A的秩不变-。这个方法包括了可逆矩阵左乘A，右乘A，或是左右同时乘A 2.利用 r(AB) 惯性定理Sylvester’s law of inertia的证明 惯性定理的应用 正负定矩阵在函数极值中的应用以二元函数$f(x,y)$为例：设$(x_0,y_0)$是二元函数$f(x,y)$的一个稳定点，即：$\frac{\partial f}{\partial x}(x_0,y_0)={\partial{f}\over \partial{y}}(x_0,y_0)=0$。如果$f(x,y)$在$(x_0,y_0)$的领域里有三阶偏导数，则$f(x,y)$在$(x_0,y_0)$可展开成Talor级数： 黑塞Hessian矩阵黑塞矩阵（Hessian Matrix），又译作海森矩阵、海瑟矩阵、海塞矩阵等，是一个多元函数的二阶偏导数构成的方阵，描述了函数的局部曲率。黑塞矩阵最早于19世纪由德国数学家Ludwig Otto Hesse提出，并以其名字命名。黑塞矩阵常用于牛顿法解决优化问题，利用黑塞矩阵可判定多元函数的极值问题。在工程实际问题的优化设计中，所列的目标函数往往很复杂，为了使问题简化，常常将目标函数在某点邻域展开成泰勒多项式来逼近原函数，此时函数在某点泰勒展开式的矩阵形式中会涉及到黑塞矩阵。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim无插件使用]]></title>
    <url>%2F2016%2F01%2F20%2Fvim_without_widgets%2F</url>
    <content type="text"><![CDATA[本文根据使用经验，会持续更新。 vim的四种模式 一般模式：normal模式。可以移动光标，删除字符或整行，也可复制、粘贴文件数据。打开vim就是进入这个模式，3个模式的切换也是在这里中转。 编辑模式：一般模式下按下i I o O a A r R s S 任何一个进入该模式。可以编辑文件内容，按Esc回到一般模式。 i I是insert（在光标所在字符前和行首） o O是open新行（在光标所在行的下面另起一新行和在光标所在行的上面另起一行开始插入 a A是append（在在光标所在字符后和在光标所在你行的行尾） s S 是删除（光标所在的字符并开始插入和光标所在行并开始插入），即substitute替换。 r R是replace光标所在的字符和变成替换模式 命令行模式：一般模式下按下: / ？任何一个进入该模式（下文会介绍这些符号的含义）。可以查找数据操作，读取、保存、大量替换字符、离开vim、显示行号等操作，按Esc回到一般模式。 可视模式：一般模式下按下v V ctr+v 进入可视模式，相当于高亮选取文本后的普通模式，即在该模式下进行任意选择特定区域且被选择的区域高亮显示，v选择单位：一个字符； V 又称为可视行模式，选择单位：行；ctr+v又称为可视块模式，选择的单位：方块；这三者都有用，详细看下文。 移动normal模式下： w → 到下一个单词的开头 e → 到下一个单词的结尾 （单词默认是以空格分隔的）W → 到下一个字符串的开头 E → 到下一个字符串的结尾 (字符串指的是数字、字母、下划线组成的字符串)B → 到前一个字符串的首字符上 b → “命令则将光标移动到前一个word的首字符上。 默认上来说，一个单词由字母，数字和下划线组成 如果你认为单词是由blank字符分隔符，那么你需要使用大写的E和W（陈皓: 注） 0 → 数字零，到行头^ → 到本行第一个不是blank字符的位置（所谓blank字符就是空格，tab，换行，回车等）$ → 到本行行尾g_ → 到本行最后一个不是blank字符的位置% → 到光标所在这对括号的另外一个gg → 首行G → 最后一行h j k l (强例推荐使用其移动光标，但不必需) →你也可以使用光标键 (←↓↑→). 注: j 向下伸，k是向上伸 高频使用场景1： 修改行中某个变量名 先移把光标移动：w and b 、W and B （或者如果本行太长可用下文的搜索功能）到目的单词 高频使用场景2： 修改缩进，跳到行头^ 高频使用场景3： 查看函数或类的完整或者变量作用域% 高频使用场景4： 切分屏幕之后，跳转不同窗口：ctrl+w+(h or j or k or l) 高频使用场景5： 左下上右移动（h、j、k、l） 高频使用场景6： 删除到末尾:d$ 删除到开头: d^ 标记简记：标记是为了更好地查找，normal模式下： mx mean: mark x, x is mark name;&#39;x mean: go to the position of x mark 高频使用场景1： 在函数中看到调用其他函数，你想去看怎么定义的，你看完之后要回来，那么先标记一下，然后在跳回来。 语法相关的跳转normal模式下： gd 意思： go to definition 先按 [ 再按 ctrl+d 跳转到#define处 语言支持不太良好 先按 [ 再按 ctrl+i 跳转到函数、变量和#define 语言支持不太良好 快速翻页normal模式下： 伙伴1 伙伴2 ctr + d page down ctr + u page up ctr + f page former ctr + b page back 动作操作指令normal模式下： 伙伴1 伙伴2 d delete a character and copy to clipboard D 从光标所在位置一直删除到行尾 y copy to clipboard Y 复制一行(=yy) s substitue a character S 替换光标所在行 r replace a character R 不常用，表示进入替换模式 c change a character C 不常用，表示修改光标所在位置一直到行尾，与S呈现效果一样 p paste after the cursor P 黏贴在光标位置之前（如果是黏贴一整行，则黏贴到上一行） u undo a operation U 一次性撤销对一整行的所有操作 x cut a character X 不常用， 向左剪切，即退格：删除光标的左边那个字符 * 向下搜索当前光标所在的单词，找到就跳到下一个单词 # 向上搜索当前光标所在的单词，找到就跳到上一个单词 /word 向下全文搜索单词word，跳到匹配的第一个单词，如果多个，继续向下查找按n键（顺着命令本来方向），向上找按N键。 ?word 向上全文搜索单词word，跳到匹配的第一个单词，如果多个，继续向上查找按n键（顺着命令本来方向），向下找按N键。 a append after the cursor A是附加在光标所在行的行尾） i insert before the cursor I插入在光标所在行的行首 o 在光标所在行的下面另起一新行，open the new world？ O在光标所在行的上面另起一行开始插入 v 进入visual模式，用来选择区域（可跨行），用来配合后续的其他操作（增删改查） v 进入visual行模式，用来选择一些行，用来配合后续的其他操作（增删改查） f find a character after the cursor F 向光标位置之前查找一个字符 t till a character tx和fx相同，区别是跳到字符x前 T Tx 和Fx相同，区别是跳到字符x后 单独成型. 重复刚才的操作~ 转换大小写 可以对变量首字母改变大小写 可以结合下文提供的命令的选择一个字符串（变量），然后再改变整个字符串（变量）的大小写。比如：宏定义 = 自动格式化 对当前行用== （连按=两次）, 或对多行用n==（n是自然数）表示自动缩进从当前行起的下面n行 或者进入可视行模式选择一些行后再=进行格式化，相当于一般IDE里的code format。 使用gg=G可对整篇代码进行排版。 撤销和恢复 u undo撤销上一步的操作，命令可以组合，例如Nu N是任意一个整数，表示撤销N步操作，以下类同。 U 恢复当前行（即一次撤销对当前行的全部操作） ctr+r control+redo 恢复上一步被撤销的操作 CTRL-R 回退前一个命令 文本替换normal 模式下输入替换命令： :[range]s/pattern/string/[flags] pattern 就是要被替換掉的字串，可以用 regexp 來表示。 string 將 pattern 由 string 所取代。 [range] 有以下一些取值： [range] 含义 无 默认为光标所在的行 . 光标所在当前的行 N 第N行 $ 最后一行 &#39;a 标记a所在的行（之前要使用ma做过标记） .+1 当前光标所在行的下面一行 $-1 倒数第二行，可以对某一行加减某个数值来确定取得相对的行 22,33 第22～33行 1,$ 第1行 到 最后一行 1,. 第1行 到 当前行 .,$ 当前行 到 最后一行 &#39;a,&#39;b 标记a所在的行 到 标记b所在的行（之前要使用ma和mb做过标记） % 所有行（与 1,$ 等价） ?str? 从当前位置向上搜索，找到的第一个str所在的行 （其中str可以是任何字符串或者正则表达式） /str/ 从当前位置向下搜索，找到的第一个str所在的行（其中str可以是任何字符串或者正则表达式） 注意，上面的所有用于range的表示方法都可以通过 +、- 操作来设置相对偏移量。 [flags]有以下一些取值： flags 含义 g 对指定范围内的所有匹配项（global）进行替换 c 在替换前请求用户确认（confirm） e 忽略执行过程中的错误 i ignore 不分大小写 无 只对指定范围内的第一个匹配项进行替换 注意：上面的所有flags都可以组合起来使用，比如 gc 表示对指定范围内的 所有匹配项进行替换，并且在每一次替换之前都会请用户确认。 例子替换某些行的内容 :10,20s/from/to/g 对第10行到第20行的内容进行替换。 :1,$s/from/to/g 对第一行到最后一行的内容进行替换（即全部文本） :1,.s/from/to/g 对第一行到当前行的内容进行替换。 :.,$s/from/to/g 对当前行到最后一行的内容进行替换。 :&#39;a,&#39;bs/from/to/g 对标记a和b之间的行（含a和b所在的行）进行替换，其中a和b是之前用m命令所做的标记。 替换所有行的内容：:%s/from/to/g 动作的重复normal模式下，任意一个动作都可以重复 注：N是数字 数字：Nyy从当前行算起向下拷贝N行、Ndd从当前行算起向下删除N行、Ngg跳到第N行、dNw删除从当前光标开始到第N个单词前（不包含空白，即删除N-1个单词)、yNe拷贝从当前光标到第N个单词末尾（注意： yy=1yy dd=1dd）、d$删除到本行末尾 重复前一个命令： .N （N表示重复的次数） 区块选择注：中括号内容为可选项 normal模式下：[ctr + ] v + (h or j or k or l) 高频使用场景1: [ctr + ] v 选中某些行的行头之后 再按= 效果：代码格式自动调整 高频使用场景2: [ctr + ] v 选中某些行的行头之后 再按I再按注释的符号（比如：//）最后按ESC 效果：选中的这些行全部注释了 多行快速注释 高频使用场景3: [ctr + ] v 选中某些行的行头之后 再按A再按注释的内容 最后按 ESC（比如：//这是测试代码） 效果：选中的这些行的行尾全部注释上//这是测试代码 多行快速注释 高频使用场景4: [ctr + ] v 选中某些行的行头的注释（比如：//）之后 再按d 最后按ESC 效果：选中的这些行全部注释删除了 多行快速删除注释 高频使用场景5: [ctr + ] v 选中某些区块之后，再按上文动作的按键实现区域操作 组合的强大操作光标所在的一个单词normal模式下： 动作 + 移动 [+重复次数]前面已经已经大量使用组合，这里继续： 动作操作指令+范围 效果 cw or c1 or c1w change from current cursor to word end caw change whole word including current cursor dw or d1 or d1w delete from current cursor to word end daw delete whole word including current cursor yw or y1 or y1w copy from current cursor to word end yaw copy whole word including current cursor 范围+动作操作指令 效果 bve 或 BvE + c/d/y 操作一个变量或字符串 上表都是高频使用场景 自动补全在insert模式下直接按： 最常用的补全 12ctrl + n ctrl + p 智能补全 1ctrl + x //进入补全模式 整行补全 CTRL-X CTRL-L 根据当前文件里关键字补全 CTRL-X CTRL-N 根据字典补全 CTRL-X CTRL-K 根据同义词字典补全 CTRL-X CTRL-T 根据头文件内关键字补全 CTRL-X CTRL-I 根据标签补全 CTRL-X CTRL-] 补全文件名 CTRL-X CTRL-F 补全宏定义 CTRL-X CTRL-D 补全vim命令 CTRL-X CTRL-V 用户自定义补全方式 CTRL-X CTRL-U 拼写建议 CTRL-X CTRL-S //例如：一个英文单词 折叠normal模式下： 123zo (折+open)zi (折+indent)zc (折+close) 切分屏幕切分命令，normal模式下，输入 vs(说明：vertically split 纵向切分屏幕） sp(说明：split 横向切分屏幕，即默认的切分方式） 屏幕相互跳转 ctr + w 再按 h或j或k或l 解释：h: left , j : down , k : up, l : right 调整切分窗口的大小 ctrl+w 在按 + 或 - 或 = ，当然在按 + 或 - 或 = 之前先按一个数字，改变窗口高度，= 是均分的意思。。 在normal模式下 输入：resize -N 或 :resize +N 明确指定窗口减少或增加N行 ctrl+w 在按 &lt; 或 &gt; 或 = ，当然在按 &lt; 或 &gt; 或 = 之前先按一个数字，改变窗口宽度，= 是均分的意思。 有时候预览大文件，感觉切分的屏幕太小，ctrl+w + T 移动当前窗口至新的标签页。 tab窗口vim 从 vim7 开始加入了多标签切换的功能， 相当于多窗口. 之前的版本虽然也有多文件编辑功能， 但是总之不如这个方便啦。 用法normal模式下： :tabnew [++opt选项] ［＋cmd］ 文件 建立对指定文件新的tab :tabc 关闭当前的tab or :q :tabo 关闭其他的tab :tabs 查看所有打开的tab :tabp 前一个previous tab window :tabn 后一个next tab window 标准模式下： gt , gT 可以直接在tab之间切换。 还有很多他命令， :help table 吧。 目录normal模式下： :Te 以tab窗口形式显示当前目录 然后可进行切换目录、打开某个文件 :!ls 这种是vim调用shell命令的方式:!ls + shell_command,但不是以tab窗口的形式显示当前目录。 成对符号的内容操作以下命令可以对标点内的内容进行操作： ci&#39; ci&quot; ci( ci[ ci{ ci&lt; 分别change这些配对标点符号中的文本内容 di&#39; di&quot; di(或dib di[ di{或diB di&lt; 分别删除这些配对标点符号中的文本内容 yi&#39; yi&quot; yi( yi[ yi{ yi&lt; 分别复制这些配对标点符号中的文本内容 vi&#39; vi&quot; vi( vi[ vi{ vi&lt; 分别选中这些配对标点符号中的文本内容 cit dit yit vit 分别操作一对标签之间的内容，编辑html很好用 另外如果把上面的 i 改成 a 可以同时操作配对标点和配对标点内的内容，举个例子： 比如要操作的文本：111”222”333，将光标移到”222”的任何一个字符处输入命令 di” ,文本会变成： 111””333 若输入命令 da” ,文本会变成： 111333 剪贴板1. 简单复制和粘贴vim提供12个剪贴板，它们的名字分别为vim有11个粘贴板，分别是0、1、2、…、9、a、“。如果开启了系统剪贴板，则会另外多出两个+和*。使用:reg命令，可以查看各个粘贴板里的内容。 在vim中简单用y 只是复制到 &quot; 的粘贴板里，同样用p 粘贴的也是这个粘贴板里的内容。 2. 复制和粘贴到指定剪贴板要将vim的内容复制到某个粘贴板，进入正常模式后，选择要复制的内容，然后按 &quot;Ny 完成复制，其中N为粘贴板号（注意是按一下双引号然后按粘贴板号最后按y），例如要把内容复制到粘贴板a，选中内容后按”ay就可以了。 要将vim某个粘贴板里的内容粘贴进来，需要退出编辑模式，在正常模式按&quot;Np，其中N为粘贴板号。比如，可以按&quot;5p将5号粘贴板里的内容粘贴进来，也可以按&quot;+p将系统全局粘贴板里的内容粘贴进来。 3. 系统剪贴板查看vim支持的剪切板，normal模式下输入：reg 和系统剪贴板的交互又应该怎么用呢？遇到问题一般第一个寻找的是帮助文档，剪切板即是 Clipboard。通过:h clipboard 查看帮助 星号和加号+粘贴板是系统粘贴板。在windows系统下， 和 + 剪贴板是相同的。对于 X11 系统， 剪贴板存放选中或者高亮的内容， + 剪贴板存放复制或剪贴的内容。打开clipboard选项，可以访问 + 剪贴板；打开xterm_clipboard，可以访问 剪贴板。 * 剪贴板的一个作用是，在vim的一个窗口选中的内容，可以在vim的另一个窗口取出。 复制到系统剪贴板 example： &quot;*y &quot;+y &quot;+Nyy 复制N行到系统剪切板 解释： 命令 含义 {Visual}”+y copy the selected text into the system clipboard “+y{motion} copy the text specified by {motion} into the system clipboard :[range]yank+ copy the text specified by [range] into the system clipboard 剪切到系统剪贴板 example： “+dd 从系统剪贴板粘贴到vim normal模式下： &quot;*p &quot;+p :put+ 含义： Ex command puts contents of system clipboard on a new line 插入模式下： &lt;C-r&gt;+ 含义： From insert mode (or commandline mode) “+p比 Ctrl-v 命令更好，它可以更快更可靠地处理大块文本的粘贴，也能够避免粘贴大量文本时，发生每行行首的自动缩进累积，因为Ctrl-v是通过系统缓存的stream处理，一行一行地处理粘贴的文本。 vim编码Vim 可以很好的编辑各种字符编码的文件，这当然包括UCS-2、UTF-8 等流行的 Unicode 编码方式。 四个字符编码选项，encoding、fileencoding、fileencodings、termencoding (这些选项可能的取值请参考 Vim 在线帮助 :help encoding-names，它们的意义如下: encoding: Vim 内部使用的字符编码方式 包括 Vim 的 buffer (缓冲区)、菜单文本、消息文本等。默认是根据你的locale选择.用户手册上建议只在 .vimrc 中改变它的值，事实上似乎也只有在.vimrc 中改变它的值才有意义。你可以用另外一种编码来编辑和保存文件，如你的vim的encoding为utf-8,所编辑的文件采用cp936编码,vim会自动将读入的文件转成utf-8(vim的能读懂的方式），而当你写入文件时,又会自动转回成cp936（文件的保存编码). fileencoding: Vim 中当前编辑的文件的字符编码方式 Vim 保存文件时也会将文件保存为这种字符编码方式 (不管是否新文件都如此)。 fileencodings: Vim会自动探测编码设置项 启动时会按照它所列出的字符编码方式逐一探测即将打开的文件的字符编码方式，并且将 fileencoding 设置为最终探测到的字符编码方式。因此最好将Unicode 编码方式放到这个列表的最前面，将拉丁语系编码方式 latin1 放到最后面。 termencoding: Vim 所工作的终端 (或者 Windows 的 Console 窗口) 的字符编码方式 如果vim所在的term与vim编码相同，则无需设置。如其不然，你可以用vim的termencoding选项将自动转换成term的编码.这个选项在 Windows 下对我们常用的 GUI 模式的 gVim 无效，而对 Console 模式的Vim 而言就是 Windows 控制台的代码页，并且通常我们不需要改变它。 好了，解释完了这一堆容易让新手犯糊涂的参数，我们来看看 Vim 的多字符编码方式支持是如何工作的。 Vim 启动，根据 .vimrc 中设置的 encoding 的值来设置 buffer、菜单文本、消息文的字符编码方式。 读取需要编辑的文件，根据 fileencodings 中列出的字符编码方式逐一探测该文件编码方式。并设置 fileencoding 为探测到的，看起来是正确的 (注1) 字符编码方式。 对比 fileencoding 和 encoding 的值，若不同则调用 iconv 将文件内容转换为encoding 所描述的字符编码方式，并且把转换后的内容放到为此文件开辟的 buffer 里，此时我们就可以开始编辑这个文件了。注意，完成这一步动作需要调用外部的 iconv.dll(注2)，你需要保证这个文件存在于 $VIMRUNTIME 或者其他列在 PATH 环境变量中的目录里。 编辑完成后保存文件时，再次对比 fileencoding 和 encoding 的值。若不同，再次调用 iconv 将即将保存的 buffer 中的文本转换为 fileencoding 所描述的字符编码方式，并保存到指定的文件中。同样，这需要调用 iconv.dll由于 Unicode 能够包含几乎所有的语言的字符，而且 Unicode 的 UTF-8 编码方式又是非常具有性价比的编码方式 (空间消耗比 UCS-2 小)，因此建议 encoding 的值设置为utf-8。这么做的另一个理由是 encoding 设置为 utf-8 时，Vim 自动探测文件的编码方式会更准确 (或许这个理由才是主要的 ;)。我们在中文 Windows 里编辑的文件，为了兼顾与其他软件的兼容性，文件编码还是设置为 GB2312/GBK 比较合适，因此 fileencoding 建议设置为 chinese (chinese 是个别名，在 Unix 里表示 gb2312，在 Windows 里表示cp936，也就是 GBK 的代码页)。 对于fedora来说，vim的设置一般放在/etc/vimrc文件中，不过，建议不要修改它。可以修改~/.vimrc文件（默认不存在，可以自己新建一个），写入所希望的设置。 我的.vimrc文件如下: 1234:set encoding=utf-8:set fileencodings=ucs-bom,utf-8,cp936:set fileencoding=gb2312:set termencoding=utf-8 其中，fileencoding配置可以设置utf-8，但是我的mp3好像不支持utf-8编码，所以干脆，我就设置为gb2312了。现在搞定了，不管是vi中还是mp3上都可以显示无乱码的.txt文件了。 个人的配置本人无插件使用过程中的配置很短，写在vim的配置文件.vimrc里， 配置是使用vim script进行配置的，它有自己的一套语法，详细请点击vim Script 1234567891011set number;display numberset mouse=a; setting smart mouseset hlsearch ;high light searchset tabstop=4 ; setting tab width 4 lettersset shiftwidth=4; setting new line incident widthset noexpandtab; tab doesn't expand to space;set list ;display manipulator, example： \n \t \r ......set encoding=utf-8set fileencodings=ucs-bom,utf-8,cp936set fileencoding=gb2312set termencoding=utf-8 前进和后退功能流行的文本编辑器通常都有前进和后退功能，可以在文件中曾经浏览过的位置之间来回移动（联想到浏览器），在 vim 中使用 Ctrl-O 执行后退，使用 Ctrl-I 执行前进，相关帮助： :help CTRL-O :help CTRL-I :help jump-motions vim比较文件启动方法首先保证系统中的diff命令是可用的。Vim的diff模式是依赖于diff命令的。 1vimdiff file1 file2 [file3 [file4]] 或者1vim -d file1 file2 [file3 [file4]] 窗口比较局部于当前标签页中。你不能看到某窗口和别的标签页中的窗口的差异。这样，可以同时打开多组比较窗口，每组差异在单独的标签页中。Vim 将为每个文件打开一个窗口，并且就像使用 -O 参数一样，使用垂直分割。如果你要水平分割，加上 -o 参数:1vimdiff -o file1 file2 [file3 [file4]] 如果已在 Vim 中，你可以用三种方式进入比较模式，只介绍一种：1:diffs[plit] &#123;filename&#125; 对 {filename} 开一个新窗口。当前的和新开的窗口将设定和”vimdiff” 一样的参数。要垂直分割窗口，在前面加上 :vertical 。例如:1:vert diffsplit another_filename 跳转到差异有两条命令可用于在跳转到差异文所在的位置: [c 反向跳转至上一处更改的开始。计数前缀使之重复执行相应次。 ]c 正向跳转至下一个更改的开始。计数前缀使之重复执行相应次。如果不存在光标可以跳转到的更改，将产生错误。 合并比较目的就是合并差异，直接使用以下自带命令或者麻烦的办法：手动从一个窗口拷贝至另一个窗口。 123456789101112131415161718:[range]diffg[et] [bufspec] 用另一个缓冲区来修改当前的缓冲区，消除不同之处。除非只有另外一 个比较模式下的缓冲区， [bufspec] 必须存在并指定那个缓冲区。 如果 [bufspec] 指定的是当前缓冲区，则为空动作。[range] 可以参考下面。:[range]diffpu[t] [bufspec] 用当前缓冲区来修改另一个缓冲区，消除不同之处。[count]do 同 ":diffget"，但没有范围。"o" 表示 "obtain" (不能用 "dg"，因为那可能是 "dgg" 的开始！)。dp 同 ":diffput"，但没有范围。注意 不适用于可视模式。 给出的 [count] 用作 ":diffput" 的 [bufspec] 参数。当没有给定 [range] 时，受影响的仅是当前光标所处位置或其紧上方的差异文本。当指定 [range] 时，Vim 试图仅改动它指定的行。不过，当有被删除的行时，这不总有效。参数 [bufspec] 可以是缓冲区的序号，匹配缓冲区名称或缓冲区名称的一部分的模式。例如: :diffget 使用另一个进入比较模式的缓冲区 :diffget 3 使用 3 号缓冲区 :diffget v2 使用名字同 "v2" 匹配的缓冲区，并进入比较模式(例如，"file.c.v2") 更新比较和撤销修改比较基于缓冲区的内容。因而，如果在载入文件后你做过改动，这些改动也将参加比较。不过，你也许要不时地使用 :diffupdate[!]。因为并非所有的改动的结果都能自动更新。包含! 时，Vim 会检查文件是否被外部改变而需要重新载入。对每个被改变的文件给出提示。 如果希望撤销修改，可以和平常用vim编辑一样，直接进入normal模式下按u但是要注意一定要将光标移动到需要撤销修改的文件窗口中。 上下文的展开和查看比较和合并文件的时候经常需要结合上下文来确定最终要采取的操作。Vimdiff 缺省是会把不同之处上下各 6 行的文本都显示出来以供参考。其他的相同的文本行被自动折叠。如果希望修改缺省的上下文行数，可以这样设置： 1:set diffopt=context:3 多个文件的退出在比较和合并告一段落之后，可以用下列命令对多个文件同时进行操作。 比如同时退出：:qa （quit all） 如果希望保存全部文件：:wa （write all） 或者是两者的合并命令，保存全部文件，然后退出：:wqa （write, then quit all） 如果在退出的时候不希望保存任何操作的结果：:qa! （force to quit all） vimdiff 详细请参考 vim下 :help diff vimdiff doc vim命令行的保存、离开等命令： :w 将编辑的数据写入硬盘文件中。 :w! 若文件属性为“只读”，强制写入该文件。但能否写入还由对该文件的文件权限有关。 :q保存后离开。若为“:wq！”则强制保存后离开。 :w[文件名] 将编辑的数据保存为另一个文件。 :r[文件名] 在编辑的数据中读入另一个文件的内容加到光标所在行后面。 :n1,n2 w[文件名] 将n1行到n2行的内容保存到另一个文件。 :!command 暂时离开vi到命令行模式下执行command的显示结果。 ZZ 若文件未改动，则直接离开；若已改动则保存后离开。 set num/nonum 显示/取消行号。 VIM的宏宏的使用非常强大，前往vim 中，宏的使用 完整版命令本文只提供个人使用过程中积累的高频场景，完整版请点击此处，或查阅 vim manual 玩游戏来熟能生巧用进废退，所以多用才是王道，这里推荐一个游戏：通过键盘输入控制人物角色冒险的游戏，玩游戏的过程中熟悉VIM命令: vim-adventures 参考 官方文档 vim doc 中文 freewater 博客 Thinking In Linux]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[决策树学习]]></title>
    <url>%2F2015%2F05%2F01%2Fdecision_tree%2F</url>
    <content type="text"><![CDATA[决策树学习决策树学习通常包含三个方面：特征选择、决策树生成和决策树剪枝。决策树学习思想主要来源于：Quinlan在1986年提出的ID算法、在1993年提出的C4.5算法和Breiman等人在1984年提出的CART算法。 特征选择为了解释清楚各个数学概念，引入例子 表5.1 贷款申请样本数据表（来自李航《统计方法》） ​ 上表有15个样本数据组成的贷款申请训练数据D。数据包括贷款申请人的4个特征：年龄、有工作与否、有房子与否、信贷情况，其中最后一列类别的意思是：是否同意发放贷款，这个就是决策树最后要给出的结论，即目标属性——是否发放贷款，即决策树最末端的叶子节点只分成2类：同意发放贷款与不同意发放贷款。 信息熵（entropy）​ 引入概念，对于第一个要用到的概念：信息熵在另外一篇博客——数据压缩与信息熵中详细解释了信息熵为什么度量的是不确定性，下文也不再赘述，直接引用。 ​ 设D为按照目标类别（或称目标属性）对训练数据（即样本数据）进行的划分，则D的信息熵（information entropy）表示为： ​ 其中pi表示第i个类别在整个训练数据中出现的概率，可以用属于此类别元素的数量除以训练数据（即样本数据）总数量作为估计。 具体问题具体分析 在上表中目标类别：是否发放贷款，将9个发放归为一类，剩余6个不发放归为一类，这样进行分类的信息熵为： $$H(D)=-\frac{9}{15}log_2\frac{9}{15}-\frac{6}{15}log_2\frac{6}{15}=0.971$$ 注：这个根据目标类别分类得出的信息熵，在样本给出的情况下就已经知晓，根据概率统计，也称经验熵。 ​ 现在我们假设将训练数据D按属性A进行划分，则按A属性进行分裂出的v个子集（即树中的v个分支），这些子集按目标类别（发放与不发放两类）进行分类所对应的熵的期望（即：按属性A划分出不同子集的信息熵的平均值）： 注：这个实际上是经验条件熵，因为确认是在A属性划分出子集的前提下再按照目标类别分类得出的熵的期望，见下文信息增益计算就可以一目了然。 信息增益（information gain）为上述两者的差值： 具体问题具体分析 按照年龄属性（记为A1）划分：青年（D1表示），中年（D2表示），老年（D3表示） 按照是否有工作（记为A2）划分：有工作（D1表示），无工作（D2表示） 按照是否有自己房子（记为A3）划分：有自己房子（D1表示），无自己房子（D2表示） 同理，根据最后一个属性：信贷情况算出其信息增益： 所以可以看出信息增益度量的是：信息熵的降低量，这个降低是经过某个属性对原数据进行划分得出的。信息熵的降低，即确定性的提高，进一步讲，就是类别的数量在下降，那么确定为哪一类的可能性就提高，这样就更容易分类了。ID3算法就是基于信息增益来衡量属性（即特征）划分数据的能力，进而为特征（即属性）选择提供原则。 增益比率（gain ratio） 信息增益选择方法有一个很大的缺陷，它总是会倾向于选择属性值多的属性，如果我们在上面的数据记录中加一个姓名属性，假设15条记录中的每个人姓名不同，那么信息增益就会选择姓名作为最佳属性，因为按姓名分裂后，每个组只包含一条记录，而每个记录只属于一类（要么发放要么不发放），因此不确定性最低，即纯度最高，（注：为什么最高呢？大家可以根据导数计算一下，最大值的情况，这里不赘述）以姓名作为测试分裂的结点下面有15个分支。但是这样的分类没有意义，它没有任何泛化能力。增益比率对此进行了改进，它引入一个分裂信息： $$SplitInfo_R(D)=-\sum\limits_{j=1}^{k}\frac{|D_j|}{D}\times log_2(\frac{|D_j|}{D})$$ 注：分裂信息即按照某个属性划分的信息熵，而本文前面叙述的熵全部是按照目标属性进行分类的信息熵。 增益比率定义为信息增益与分裂信息的比率： $$GainRatio(R)=\frac{Gain(R)}{SplitInfo_R(D)}$$ 我们找GainRatio最大的属性作为最佳分裂属性。如果一个属性的取值很多，那么SplitInfoR(D)会大，从而使GainRatio(R)变小。不过增益比率也有缺点，SplitInfo(D)可能取0，此时没有计算意义；且当SplitInfo(D)趋向于0时，GainRatio(R)的值变得不可信，改进的措施就是在分母加一个平滑，这里加一个所有分裂信息的平均值： $$GainRatio(R)=\frac{Gain(R)}{\overline{SplitInfo(D)}+SplitInfo_R(D)}$$ C4.5算法就是按照信息增益比来计算各属性的分类能力，进而为特征（即属性）选择提供原则。 基尼指数（Gini coefficient） 定义（基尼指数）：在分类问题中，假设有K个类，样本点属于第K类的概率为p(k)，则概率分布的基尼指数定义为 对于2分类问题，若样本属于第一类的概率是p，则概率分布的基尼指数为： 对于给定的样本集合D的基尼指数为： 这里，C(k)是D中属于第k类的样本子集，K是类的个数。 如果样本集合D根据特征A是否取某一可能值α被分割成D1和D2两部分，即 则在特征A的条件下，集合D的基尼指数定义为 基尼指数Gini(D)表示集合D的不确定性，基尼指数Gini(D, A)表示经A=α分割后集合D的不确定性。基尼指数值越大，样本集合的不确定性也就越大，这一点与熵相似。 ID3算法 信息增益算法（来自李航《统计方法》） ID3算法（来自李航《统计方法》） 示例（来自李航《统计方法》） C4.5生成算法（来自李航《统计方法》） CART生成算法（来自李航《统计方法》） 示例]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Perception Learning Algorithm]]></title>
    <url>%2F2015%2F04%2F24%2Fperception_learning_algorithm%2F</url>
    <content type="text"><![CDATA[PLA(Perception Learning Algorithm) 适用于二维及高维的线性可划分问题。问题的答案只有同意或者不同意。 例子银行可以根据顾客的个人信息来判断是否给顾客发放信用卡。将顾客抽象为一个向量$X$，包括姓名、年龄、年收入、负债数等。同时设定各个属性所占的权重向量为$W$，对于正相关的属性设置相对较高的权重，如年收入，对于负相关的属性设置较低的权重，如负债数。$y$表示是否想该用户发放了信用卡。通过求$X$和$W$的内积减去一个阀值threshold，若为正则同意发放信用卡，否则不发放信用卡。我们假设存在着一个从$X$到$Y$的映射$f$，PLA算法就是用来模拟这个映射，使得求出的函数与$f$尽可能的相似，起码在已知的数据集(即样本上)上一致。 PLA算法即用来求向量$W$，使得在已知的数据中机器做出的判断与现实数据相同。当$X$为二维向量时，相当于在平面上画出一条直线将所有的点分成两部分，一部分同意发送，另一部分的不同意。内积可以表示成：$$\begin{eqnarray}h(x) &amp;=&amp; sign((\sum\limits_{i=1}^{d}W_i X_i)-threshold)\&amp;=&amp; sign((\sum\limits_{i=1}^{d}W_i X_i)+\underbrace{(-threshold)}_{W_0}\times\underbrace{(+1)}_{X_0})\&amp;=&amp; sign(\sum\limits_{i=0}^{d}W_i X_i)\&amp;=&amp; sign(W^TX)\end{eqnarray}$$ 其中$X_0=1，W_0=-threshold$ $y_s$的值域：${+1，-1}$，($y_s$ 表示样本中$y$的值，用于输入到算法进行调整) 结合文中例子：$y_s=1$ 表示在给定的样本数据中，给该用户发放了信用卡，$y_s= -1$表示未发放。 PLA先假定$W_0$为向量$\vec{0}$，然后找到一个不满足条件的点，调整$W$的值，依次进行迭代所有样本数据使得最终可以将两部分完全分开。 W的调整方案错误驱动调整 解释一下ppt的内容，出现错误分2种情况： 在给定的已知数据中向该用户发放了数据，即$y_s(i)$样本中第$i$个数据为$+1$，但算法给出的结果是不发放（$h(X_i) &lt;0$），说明两个向量的内积为负，需要调整$W$向量使得两条向量更接近，此时令调整系数为样本的$y_s(i)$，则调整后的$W_{t+1}= W_t + y_s(i)X_i$，$W$的下标$t, t+1$表示调整的次数，示意图: 在给定的已知数据中向该用户发放了数据，即$y_s(i)$样本中第$i$个数据为$-1$，但算法给出的结果是不发放（$h(X_i) &gt; 0$），说明两个向量的内积为正，需要调整$W$向量使得两条向量更远离，此时令调整系数为样本的$y_s(i)$，则调整后的$W_{t+1}= W_t + y_s(i)X_i$，示意图: 注意：2种不同情况的调整的表达式都一样 对于线性可分的数据集，PLA算法是可收敛的 两个向量的内积增大说明： 两个向量夹角越小 或者向量的长度增大 老师的ppt上 $||W_{t+1}||^2 \le ||W_t||^2 + max{1 \le i \le n\ \ |\ \ ||y_i X_i||^2}$ 其中，$y_i$的值域 ${+1, -1}$ 因此 $||W_{t+1}||^2 \le ||W_t||^2 + max{1 \le i \le n\ \ |\ \ ||X_i||^2}$ 这说明每次调整后，向量的长度增加有限。不妨 带入上一公式得到： $$\begin{eqnarray}\frac{||W_{t+1}||^2}{||W_{t}||^2} &amp;\le&amp; \frac{||W_{t}||^2 + max||y_n x_n||^2}{||W_{t}||^2} \&amp;=&amp; \frac{||W_{t}||^2 + max||x_n||^2}{||W_{t}||^2} \&amp;=&amp;1+ \frac{R^2}{||W(t)||^2}\end{eqnarray}$$ 因此$W_t$最终是收敛的，到此已经证明了PLA算法最终可以停止。 算法需要调整的次数由上述过程可以得到以下两个不等式： $$\begin{eqnarray}W_f^t W_t &amp;=&amp; W_f^t(W_{t-1}+y_s(t-1)X_{t-1}) \&amp;=&amp; W_f^tW_{t-1}+y_s(t-1)W_f^tX(t-1) \&amp;\ge&amp; W_f^tW_{t-1}+min(yW_f^tX) \&amp;\ge&amp; W_f^tW_{t-2}+2\,min(yW_f^tX) \&amp;\cdots&amp; \&amp;\ge&amp; W_f^tW_0 + t\,min(yW_f^tX) \&amp;=&amp; t\,min(yW_f^tX)\end{eqnarray}$$ $$\begin{eqnarray}||W_t||^2 &amp;\le&amp; ||W_{t-1}||^2+max(||X||^2)\&amp;\le&amp; ||W_{t-2}||^2+2\,max(||X||^2)\&amp;\cdots&amp; \&amp;\le&amp; ||W_0||^2+t\,max(||X||^2)\&amp;=&amp; t\, max(||X||^2)\end{eqnarray}$$ 那么来看这个式子：$\frac{W_f^t W_t}{||W_f^t||\ ||W_t||}\ge \frac{t\ min(yW_f^tX)}{||W_f^t||\sqrt{t\,(max(||X||))^2}}=\sqrt{t}\, \frac{min(yW_f^tX)}{||W_f^t||max(||X||)} $ 再根据余弦值最大为1，可以得到$\frac{W_f^tW_t}{||W_f^t||\ ||W_t||}\le 1$，于是我们得到调整次数：$t\le \frac{||W_f^t||(max(||X||))^2}{(min(yW_f^tX))^2}={R^2 \over \rho^2}$. PLA的优缺点 一方面，我事先肯定不知道$W_f^t$，另一方面为了应对可能出现的噪声。那么怎么衡量当前得到的直线能够满足要求呢？我们只能在每一步的时候都判断一下，调整后的$W_{t+1}$是否比上一次的$W_t$能够线性可分更多的数据，于是有了下面的改进算法Pocket PLA，PocketPLA比PLA在调整的时候多做一步：判断当前改正犯的错是否比之前更小，也就是贪心选择。 Pocket PLA 参考 HappyAngel DreamerMonkey ppt全部来自台大《机器学习基石》课堂]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划-最长公共子序列]]></title>
    <url>%2F2014%2F06%2F01%2Flongest_common_sub-sequence%2F</url>
    <content type="text"><![CDATA[算法总体思想动态规划（Dynamic Programming）是通过组合子问题的解而解决整个问题的。分治是指将问题划分成一些独立的子问题，递归地求解各子问题，然后合并子问题的解而得到原始问题的解，与此不同，动态规划适用于子问题不是独立的情况，也就是各个子问题包含公共的子问题。在这种情况下，采用分治法会做许多不必要的工作，即重复地求解公共地子问题。动态规划算法对每个子问题只求解一次，将其结果保存在一张表中，从而避免每次遇到各个子问题时重新计算答案。 动态规划算法的基本要素最优子结构 矩阵连乘计算次序问题的最优解包含着其子问题的最优解。这种性质称为最优子结构性质。 在分析问题的最优子结构性质时，所用的方法具有普遍性：首先假设由问题的最优解导出的子问题的解不是最优的，然后再设法说明在这个假设下可构造出比原问题最优解更好的解，从而导致矛盾。 利用问题的最优子结构性质，以自底向上的方式递归地从子问题的最优解逐步构造出整个问题的最优解。最优子结构是问题能用动态规划算法求解的前提。 注意：同一个问题可以有多种方式刻划它的最优子结构，有些表示方法的求解速度更快（空间占用小，问题的维度低） 重叠子问题 递归算法求解问题时，每次产生的子问题并不总是新问题，有些子问题被反复计算多次。这种性质称为子问题的重叠性质。 动态规划算法，对每一个子问题只解一次，而后将其解保存在一个表格中，当再次需要解此子问题时，只是简单地用常数时间查看一下结果。 通常不同的子问题个数随问题的大小呈多项式增长。因此用动态规划算法只需要多项式时间，从而获得较高的解题效率。 问题举例最长公共子序列(LCS) 若给定序列$X={x_1,x_2,…,x_m}$，则另一序列$Z={z_1,z_2,…,z_k}$，是 $X$ 的子序列是指存在一个严格递增下标序列${i_1,i_2,…,i_k}$使得对于所有$j=1,2,…,k$ 有：$z_j=x_{i}$。例如，序列 $Z={B，C，D，B}$ 是序列 $X={A，B，C，B，D，A，B}$ 的子序列，相应的递增下标序列为${2，3，5，7}$。 给定2个序列 $X$ 和 $Y$，当另一序列 $Z$ 既是 $X$ 的子序列又是 $Y$ 的子序列时，称 $Z$ 是序列 $X$ 和 $Y$ 的公共子序列。 给定2个序列$X={x_1,x_2,…,x_m}$和 $Y={y_1,y_2,…,y_n}$，找出 $X$ 和 $Y$ 的最长公共子序列。 最长公共子序列的结构(LCS)设序列$X={x_1,x_2,…,x_m}$和 $Y={y_1,y_2,…,y_n}$的最长公共子序列为 $Z={z_1,z_2,…,z_k}$ ，则 若$x_m=y_n$，则$z_k=x_m=y_n$，且 $z_{k-1}$ 是 ${x_1,\ldots, x_{m-1}}$ 和 ${y_1, \ldots, y_{n-1}}$ 的最长公共子序列。 若 $x_m≠y_n$ 且 $z_k≠x_m, z_k=y_n$，则 $Z$ 是 ${x_1,\ldots, x_{m-1}}$ 和 $Y$ 的最长公共子序列。 若 $x_m≠y_n$且 $z_k≠y_n, z_k=x_m$，则 $Z$ 是 $X$ 和 ${y_1, \ldots, y_{n-1}}$ 的最长公共子序列。 由此可见，2个序列的最长公共子序列包含了这2个序列的前缀的最长公共子序列。因此，最长公共子序列问题具有最优子结构性质。 LCS时间复杂度求解LCS问题，不能使用暴力搜索方法。一个长度为n的序列拥有 2的n次方个子序列，它的时间复杂度是指数阶，而且还是两个序列求最长公共子序列。 子问题的递归结构由最长公共子序列问题的最优子结构性质建立子问题最优值的递归关系。用$c[i][j]$记录序列和的最长公共子序列的长度。 其中，$X[i]={x_1,x_2,…,x_i}$；$Y[j]={y_1,y_2,…,y_j}$。当 $i=0$ 或 $j=0$ 时，空序列是 $X[i]$ 和 $Y[j]$ 的最长公共子序列。故此时 $c[i][j]=0$ 。其他情况下，由最优子结构性质可建立递归关系如下： $c[i][j]=\cases{0,\quad i=0,j=0 \ c[i-1][j-1]+1\quad i,j&gt;0;x_i=y_j \ max{c[i][j-1],c[i-1][j]}\quad i,j&gt;0;x_i\ne y_j}$ 计算最优值（伪代码）12345678910111213141516AlgorithmlcsLength(x,y,b)mßx.length-1;nßy.length-1;c[i][0]=0;c[0][i]=0;for(int i= 1; i&lt;= m;i++) for(int j = 1; j &lt;= n; j++) if(x[i]==y[j]) c[i][j]=c[i-1][j-1]+1; b[i][j]=1; else if(c[i-1][j]&gt;=c[i][j-1]) c[i][j]=c[i-1][j]; b[i][j]=2; else c[i][j]=c[i][j-1]; b[i][j]=3; 源代码实现（测试通过）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#include&lt;iostream&gt;#define LEN_ARR_A 20#define LEN_ARR_B 12using namespace std;/* * brief : calculate longest common substring of two string and * mark path of getting the longest common substring * parameter : lenComStr : length of common substring * solutionPath : mark of path of solution * * note： dynamic programming :caculate longest common substring between X(n) * and Y(m-1),likey to caculate longest common substring between X(n) * and Y(m-1) or between X(n-1) and Y(m). X(0) and Y(0) are not referenced! * * * return : null */template&lt;class Type&gt;void LCSLength(size_t lenStrA, size_t lenStrB, Type *strA, Type *strB, size_t ** lenComStr, size_t ** solutionPath)&#123; for(size_t i = 0; i &lt; lenStrA; ++i) lenComStr[i][0] = 0; for(size_t i = 0; i &lt; lenStrB; ++i) lenComStr[0][i] = 0; for(size_t i = 1; i &lt; lenStrA; ++i) for(size_t j = 1; j &lt; lenStrB; ++j)&#123; if(strA[i] == strB[j])&#123; lenComStr[i][j] = lenComStr[i -1][j - 1] + 1; //global solution depends on local solution solutionPath[i][j] = 1; //mark path of getting the longest common substring &#125; else if(lenComStr[i - 1][j] &gt;= lenComStr[i][j - 1])&#123; lenComStr[i][j] = lenComStr[i - 1][j]; //global solution depends on local solution solutionPath[i][j] = 2; &#125;else&#123; lenComStr[i][j] = lenComStr[i][j - 1]; //global solution depends on local solution solutionPath[i][j] = 3; &#125; &#125;&#125;/* * brief : output longest common substring of two string * * parameter : i is beginning index of char array * j is end index of char array * solutionPath is the path of solution * * note： value of solutionPath[i][j] has 3 states * * return : null */ template&lt;class Type&gt;void LCS(size_t i, size_t j, Type * strA, size_t ** solutionPath)&#123; if(i == -1 || j == -1) return; if(solutionPath[i][j] == 1)&#123; LCS(i - 1, j - 1, strA, solutionPath); cout &lt;&lt; strA[i]; &#125;else if(solutionPath[i][j] == 2) LCS(i - 1, j, strA, solutionPath); else&#123; LCS(i, j - 1, strA, solutionPath); &#125;&#125;int main()&#123; char strA[LEN_ARR_A] = &#123; '0','B', 'D', 'C', 'A', 'B', 'A'&#125;; char strB[LEN_ARR_B] = &#123; '0', 'A', 'B', 'C', 'B', 'D', 'A', 'B'&#125;; size_t ** lenComStr = new size_t*[LEN_ARR_A]; size_t ** solutionPath = new size_t*[LEN_ARR_A]; for(size_t i = 0; i &lt; LEN_ARR_A; ++i) &#123; lenComStr[i] = new size_t[LEN_ARR_B]; solutionPath[i] = new size_t[LEN_ARR_B]; &#125; LCSLength(LEN_ARR_A, LEN_ARR_B, strA, strB, lenComStr, solutionPath); LCS(LEN_ARR_A - 1, LEN_ARR_B - 1, strA, solutionPath); return 0;&#125;]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Data Structure</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[含括号的运算表达式求解-栈的基础应用3]]></title>
    <url>%2F2013%2F05%2F13%2Fstack_application_on_expression-resolution-with-braces%2F</url>
    <content type="text"><![CDATA[本文根据严蔚敏老师数据结构（c语言版） 写的程序 如有需要先去看视频 如有错误不当之处，欢迎指出，以免害人害己。 例子Exp = a b + ( c – d / e ) f ​ 前缀式：+ a b - c / d e f ​ 中缀式：a b + c–d / e f ​ 后缀式：a b cd e /-f + 相同点数字都是按原式子排列的：因此操作数就按顺序入栈就好了 不同点1:后缀式中运算符的顺序，正好就是求解的顺序 2:每个运算符和它之前出现且紧靠它的2个操作数构成一个最小表达式 关键：就是由原表达式求得后缀式 应用步骤 Step1： 先设立两个栈，一个运算符栈，另一个后缀式栈。 Step2：在表达式前后头尾加入=号，表示运算表达式开始和结束，因此在运算符中，=号优先级最低。 Step3：若当前字符是操作数，则直接发送给后缀式栈。符合上面提到的共同点：数字按原表达式从左自右的顺序。 Step4：左括号的优先级高于左括号前的运算符，左括号后的运算符优先级高于左括号，这样才能起到隔离的作用，则右括号前的运算符高于右括号，这样才能起到括号隔离内层表达式的作用！ Step5：若当前运算符的优先级高于栈顶的运算符，则进运算符栈，否则退出运算符栈的栈顶运算符与从操作数栈栈顶取出的两个操作数运算结果作为新的操作数压入操作数栈，然后再把当前运算符入运算符栈。 源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206#include&lt;stdio.h&gt; #include&lt;malloc.h&gt;//malloc()#include&lt;process.h&gt;//exit();// 函数结果状态代码#define TRUE 1#define FALSE 0#define OK 1#define ERROR 0#define INFEASIBLE -1#define STACK_INIT_SIZE 100 // 存储空间初始分配量#define STACKINCREMENT 2 // 存储空间分配增量typedef int Status; // Status是函数的类型,其值是函数结果状态代码，如OK等typedef char SElemType;struct SqStack&#123; SElemType *base; // 在栈构造之前和销毁之后，base的值为NULL SElemType *top; // 栈顶指针 int stacksize; // 当前已分配的存储空间，以元素为单位&#125;;Status InitStack(SqStack &amp;S)&#123; // 构造一个空栈S if(!(S.base=(SElemType *)malloc(STACK_INIT_SIZE*sizeof(SElemType)))) exit(-1); // 存储分配失败 S.top=S.base; S.stacksize=STACK_INIT_SIZE; return OK;&#125;Status DestroyStack(SqStack &amp;S)&#123; // 销毁栈S，S不再存在 free(S.base); S.base=NULL; S.top=NULL; S.stacksize=0; return OK;&#125;Status ClearStack(SqStack &amp;S)&#123; // 把S置为空栈 S.top=S.base; return OK;&#125;Status StackEmpty(SqStack S)&#123; // 若栈S为空栈，则返回TRUE，否则返回FALSE if(S.top==S.base) return TRUE; else return FALSE;&#125;int StackLength(SqStack S)&#123; // 返回S的元素个数，即栈的长度 return S.top-S.base;&#125;Status GetTop(SqStack S,SElemType &amp;e)&#123; // 若栈不空，则用e返回S的栈顶元素，并返回OK；否则返回ERROR if(S.top&gt;S.base) &#123; e=*(S.top-1); return OK; &#125; else return ERROR;&#125;Status Push(SqStack &amp;S,SElemType e)&#123; // 插入元素e为新的栈顶元素 if(S.top-S.base&gt;=S.stacksize) // 栈满，追加存储空间 &#123; S.base=(SElemType *)realloc(S.base,(S.stacksize+STACKINCREMENT)*sizeof(SElemType)); if(!S.base) exit(-1); // 存储分配失败 S.top=S.base+S.stacksize; S.stacksize+=STACKINCREMENT; &#125; *(S.top)++=e; return OK;&#125;Status Pop(SqStack &amp;S,SElemType &amp;e)&#123; // 若栈不空，则删除S的栈顶元素，用e返回其值，并返回OK；否则返回ERROR if(S.top==S.base) return ERROR; e=*--S.top; return OK;&#125;Status StackTraverse(SqStack S,Status(*visit)(SElemType))&#123; // 从栈底到栈顶依次对栈中每个元素调用函数visit()。 // 一旦visit()失败，则操作失败 while(S.top&gt;S.base) visit(*S.base++); printf("\n"); return OK;&#125;SElemType Precede(SElemType a, SElemType b) &#123; //判断运算符优先级 int i, j; char Table[8][8] = &#123; &#123;' ','+','-','*','/','(',')','#'&#125;, &#123;'+','&gt;','&gt;','&lt;','&lt;','&lt;','&gt;','&gt;'&#125;, &#123;'-','&gt;','&gt;','&lt;','&lt;','&lt;','&gt;','&gt;'&#125;, &#123;'*','&gt;','&gt;','&gt;','&gt;','&lt;','&gt;','&gt;'&#125;, &#123;'/','&gt;','&gt;','&gt;','&gt;','&lt;','&gt;','&gt;'&#125;, &#123;'(','&lt;','&lt;','&lt;','&lt;','&lt;','=',' '&#125;, &#123;')','&gt;','&gt;','&gt;','&gt;',' ','&gt;','&gt;'&#125;, &#123;'#','&lt;','&lt;','&lt;','&lt;','&lt;',' ','='&#125; &#125;; //优先级表格 for(i=0; i&lt;8; i++) if(Table[0][i]==a) //寻找运算符a break; for(j=0; j&lt;8; j++) //寻找运算符 if(Table[j][0]==b) break; return Table[j][i];&#125;Status In(SElemType c)&#123; // 判断c是否为运算符 switch(c) &#123; case'+': case'-': case'*': case'/': case'(': case')': case'#':return TRUE; default:return FALSE; &#125;&#125;SElemType Operate(SElemType a,SElemType theta,SElemType b)&#123; SElemType c; a=a-48; b=b-48; switch(theta) &#123; case'+':c=a+b+48; break; case'-':c=a-b+48; break; case'*':c=a*b+48; break; case'/':c=a/b+48; &#125; return c;&#125;SElemType EvaluateExpression() // 算法3.4&#123; // 算术表达式求值的算符优先算法。设OPTR和OPND分别为运算符栈和运算数栈 SqStack OPTR,OPND; SElemType a,b,c,x,theta; InitStack(OPTR); Push(OPTR,'#'); InitStack(OPND); c=getchar(); GetTop(OPTR,x); while(c!='#'||x!='#') &#123; if(In(c)) // 是7种运算符之一 switch(Precede(c,x)) &#123; case'&lt;':Push(OPTR,c); // 栈顶元素优先权低 c=getchar(); break; case'=':Pop(OPTR,x); // 脱括号并接收下一字符 c=getchar(); break; case'&gt;':Pop(OPTR,theta); // 退栈并将运算结果入栈 Pop(OPND,b); Pop(OPND,a); Push(OPND,Operate(a,theta,b)); break; &#125; else if(c&gt;='0'&amp;&amp;c&lt;='9') // c是操作数 &#123; Push(OPND,c); c=getchar(); &#125; else // c是非法字符 &#123; printf("非法字符\n"); exit(-1); &#125; GetTop(OPTR,x); &#125; GetTop(OPND,x); return x;&#125;int main()&#123; printf("请输入算术表达式（中间值及最终结果要在0～9之间），并以#结束\n"); printf("%c\n",EvaluateExpression()); return 0;&#125;]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Data Structure</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[行编辑器/容错缓冲区-栈的基础应用2]]></title>
    <url>%2F2013%2F05%2F12%2Fstack_application_on_line-editor_or_buff_zone%2F</url>
    <content type="text"><![CDATA[功能接收用户的从终端输入程序或数据，并存入用户的数据区。由于用户在终端上输入难免出现差错，因此，若在行编辑程序中，“每接收一个字符即存入用户数据区”显然是不合理的。较好的做法，设立一个缓冲区，用以接收用户输入的每一行字符，然后逐行存入用户数据区。允许用户输入出错，并在发现有误时可以及时更正。例如，当用户发现刚刚键入的一个字符是错的时，补进一个退格符#，以表示前一个字符无效；如果发现当前键入的行内差错较多或难以补救，就可以键入一个退行符号@，以表示当前行中的字符均无效。 例子​ 从终端接收这样两行字符： ​ whi##ilr#e(s#*s) ​ outcha@putchar(*s#++) ​ 实际有效的是下列两行： ​ while(*s) ​ putchar(*s++) ​ 为此，我们可以设立一个缓冲区，结构为栈，每当用户从终端接受了一个字符之后现做如下判别：如果他既不是退格符，也不是退行符，则将该字符压入栈中，如果是退格符，则从栈顶删去一个字符；如果是退行符，则将字符栈清空。 源代码1234567891011121314151617181920212223242526272829void LineEdit()&#123; //利用字符栈s，从终端接收一行并送至调用过程的数据区。算法3.2 SqStack s; char ch,c; InitStack(s); printf("请输入一个文本文件,^Z结束输入:\n"); ch=getchar(); while(ch!=EOF) &#123;// EOF为^Z键，全文结束符 while(ch!=EOF&amp;&amp;ch!='\n') &#123; switch(ch) &#123; case '#':Pop(s,c); break; // 仅当栈非空时退栈 case '@':ClearStack(s); break; // 重置s为空栈 default :Push(s,ch); // 有效字符进栈 &#125; ch=getchar(); // 从终端接收下一个字符 &#125; StackTraverse(s,copy); // 将从栈底到栈顶的栈内字符传送至文件 ClearStack(s); // 重置s为空栈 fputc('\n',fp); if(ch!=EOF) ch=getchar(); &#125; DestroyStack(s);&#125;]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Data Structure</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
</search>

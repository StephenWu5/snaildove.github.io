<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[同步hexo博客]]></title>
    <url>%2F2018%2F02%2F10%2Fhexo_source-code_synchronization%2F</url>
    <content type="text"><![CDATA[旧电脑上博客根目录执行12345678git initgit check -b sourcegit check sourcegit add *git rm --cached ./node_modules/ ./source/_drafts ._config.yml ./themes/next/_config.ymlvim .gitignore #添加：./node_modules/ ./source/_drafts ._config.yml （博客根目录配置文件，防止泄露隐私）./themes/next/_config.yml (主题配置文件，防止泄露隐私，百度云盘隐藏空间备份)git commit -m "初次同步博客"git push origin source:source 新电脑上博客的新目录下执行在github的 ~.github.io.git（~代表你的github用户名） 仓库上设置 source 分支为默认分支 git 配置完成以后12345git clone https://github.com/~/~.github.io.gitcd ~.github.io.gitnpm install hexonpm installnpm install hexo-deployer-git latex公式问题按网上的教程继续修改 ./node_modules/marked/marked.js 以支持数学公式中的 \ -]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[转载-希腊字母常用指代意义及中文读音]]></title>
    <url>%2F2018%2F02%2F02%2Fgreek-letters%2F</url>
    <content type="text"><![CDATA[更多细节请参考 百度百科-希腊字母]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>english</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-introduction-note1]]></title>
    <url>%2F2018%2F01%2F01%2F01-what-is-machine-learning%2F</url>
    <content type="text"><![CDATA[Need to know This personal note is written after studying the coursera opening course, Machine Learning by Andrew NG . And images, audios of this note all comes from the opening course. So, the copyright belongs to Andrew NG. What is Machine Learning?Two definitions of Machine Learning are offered Arthur Samuel described it as: “the field of study that gives computers the ability to learn without being explicitly programmed.” This is an older, informal definition. Tom Mitchell provides a more modern definition: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.” Example: playing checkers. E = the experience of playing many games of checkersT = the task of playing checkers.P = the probability that the program will win the next game. In general, any machine learning problem can be assigned to one of two broad classifications: Supervised learning Unsupervised learning Supervised LearningIn supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output. Supervised learning problems are categorized into “regression” and “classification” problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories. housing price prediction:Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a continuous output, so this is a regression problem. Let’s say you want to predict housing prices. A while back, a student collected data sets from the Institute of Portland Oregon. And let’s say you plot a data set and it looks like this. Here on the horizontal axis, the size of different houses in square feet, and on the vertical axis, the price of different houses in thousands of dollars. So. Given this data, let’s say you have a friend who owns a house that is, say 750 square feet and hoping to sell the house and they want to know how much they can get for the house. So how can the learning algorithm help you? One thing a learning algorithm might be able to do is put a straight line through the data or to fit a straight line to the data and, based on that, it looks like maybe the house can be sold for maybe about 150,000 dollars . But maybe this isn’t the only learning algorithm you can use. There might be a better one. For example, instead of sending a straight line to the data, we might decide that it’s better to fit a quadratic function or a second-order polynomial to this data. And if you do that, and make a prediction here, then it looks like, well, maybe we can sell the house for closer to $200,000. One of the things we’ll talk about later is how to choose and how to decide do you want to fit a straight line to the data or do you want to fit the quadratic function to the data and there’s no fair picking whichever one gives your friend the better house to sell. But each of these would be a fine example of a learning algorithm. So this is an example of a supervised learning algorithm.We could turn this example into a classification problem by instead making our output about whether the house “sells for more or less than the asking price.” Here we are classifying the houses based on price into two discrete categories. breast cancer(a) Regression - Given a picture of a person, we have to predict their age on the basis of the given picture(b) Classification - Given a patient with a tumor, we have to predict whether the tumor is malignant or benign.If someone discovers a breast tumor, a lump in their breast, a malignant tumor is a tumor that is harmful and dangerous and a benign tumor is a tumor that is harmless. So obviously people care a lot about this. Let’s see you want to look at medical records and try to predict of a breast cancer as malignant or benign.Let’s see a collected data set and suppose in your data set you have on your horizontal axis the size of the tumor and on the vertical axis I’m going to plot one or zero, yes or no, whether or not these are examples of tumors we’ve seen before are malignant which is one or zero if not malignant or benign.So let’s say our data set looks like this where we saw a tumor of this size that turned out to be benign. One of this size, one of this size. And so on. And sadly we also saw a few malignant tumors, one of that size, one of that size, one of that size… So on. So this example… I have five examples of benign tumors shown down here, and five examples of malignant tumors shown with a vertical axis value of one.And let’s say we have a friend who tragically has a breast tumor, and let’s say her breast tumor size is maybe somewhere around this value. The machine learning question is, can you estimate what is the probability, what is the chance that a tumor is malignant versus benign? To introduce a bit more terminology this is an example of a classification problem. The term classification refers to the fact that here we’re trying to predict a discrete value output: zero or one, malignant or benign.And it turns out that in classification problems sometimes you can have more than two values for the two possible values for the output. As a concrete example maybe there are three types of breast cancers and so you may try to predict the discrete value of zero, one, two, or three with zero being benign. Benign tumor, so no cancer. And one may mean, type one cancer, like, you have three types of cancer, whatever type one means. And two may mean a second type of cancer, a three may mean a third type of cancer. But this would also be a classification problem, because this other discrete value set of output corresponding to, you know, no cancer, or cancer type one, or cancer type two, or cancer type three. In classification problems there is another way to plot this data. Let me show you what I mean.Let me use a slightly different set of symbols to plot this data. So if tumor size is going to be the attribute that I’m going to use to predict malignancy or benignness, I can also draw my data like this. I’m going to use different symbols to denote my benign and malignant, or my negative and positive examples. So instead of drawing crosses, I’m now going to draw O’s for the benign tumors. Like so. And I’m going to keep using X’s to denote my malignant tumors. Okay? I hope this is beginning to make sense. （My Note:it isn’t a sequential problem, but for the time being, we can ignore it） All I did was I took, you know, these, my data set on top and I just mapped it down. To this real line like so. And started to use different symbols, circles and crosses, to denote malignant versus benign examples. In other machine learning problems when we have more than one feature, more than one attribute. Here’s an example. Let’s say that instead of just knowing the tumor size, we know both the age of the patients and the tumor size. In that case maybe your data set will look like this where I may have a set of patients with those ages and that tumor size and they look like this.And a different set of patients, they look a little different, whose tumors turn out to be malignant, as denoted by the crosses. So, let’s say you have a friend who tragically has a tumor. And maybe, their tumor size and age falls around there. So given a data set like this, what the learning algorithm might do is throw the straight line through the data to try to separate out the malignant tumors from the benign ones and, so the learning algorithm may decide to throw the straight line like that to separate out the two classes of tumors. And. You know, with this, hopefully you can decide that your friend’s tumor is more likely to if it’s over there, that hopefully your learning algorithm will say that your friend’s tumor falls on this benign side and is therefore more likely to be benign than malignant. In this example we had two features, namely, the age of the patient and the size of the tumor.In other machine learning problems we will often have more features, and my friends that work on this problem, they actually use other features like these, which is clump thickness, the clump thickness of the breast tumor. Uniformity of cell size of the tumor. Uniformity of cell shape of the tumor, and so on, and other features as well. And it turns out one of the interes-, most interesting learning algorithms that we’ll see in this class is a learning algorithm that can deal with, not just two or three or five features, but an infinite number of features. On this slide, I’ve listed a total of five different features. Right, two on the axes and three more up here. But it turns out that for some learning problems, what you really want is not to use, like, three or five features. But instead, you want to use an infinite number of features, an infinite number of attributes, so that your learning algorithm has lots of attributes or features or cues with which to make those predictions. So how do you deal with an infinite number of features. How do you even store an infinite number of things on the computer when your computer is gonna run out of memory. It turns out that when we talk about an algorithm called the Support Vector Machine, there will be a neat mathematical trick that will allow a computer to deal with an infinite number of features. summaryIn supervised learning, in every example in our data set, we are told what is the “correct answer” that we would have quite liked the algorithms have predicted on that example. Such as the price of the house, or whether a tumor is malignant or benign. We also talked about the regression problem. And by regression, that means that our goal is to predict a continuous valued output. And we talked about the classification problem, where the goal is to predict a discrete value output. Unsupervised Learningbreast cancerBack then, recall data sets that look like this, where each example was labeled either as a positive or negative example, whether it was a benign or a malignant tumor. So for each example in Supervised Learning, we were told explicitly what is the so-called right answer, whether it’s benign or malignant. In Unsupervised Learning, we’re given data that looks different than data that looks like this that doesn’t have any labels or that all has the same label or really no labels. So we’re given the data set and we’re not told what to do with it and we’re not told what each data point is. Instead we’re just told, here is a data set. Can you find some structure in the data? Given this data set, an Unsupervised Learning algorithm might decide that the data lives in two different clusters. And so there’s one cluster and there’s a different cluster. And yes, Supervised Learning algorithm may break these data into these two separate clusters. So this is called a clustering algorithm. And this turns out to be used in many places. google newsOne example where clustering is used is in Google News and if you have not seen this before, you can actually go to this URL news.google.com to take a look. What Google News does is everyday it goes and looks at tens of thousands or hundreds of thousands of new stories on the web and it groups them into cohesive news stories.For example, let’s look here. The URLs here link to different news stories about the BP Oil Well story. So, let’s click on one of these URL’s and we’ll click on one of these URL’s. What I’ll get to is a web page like this. Here’s a Wall Street Journal article about, you know, the BP Oil Well Spill stories of “BP Kills Macondo”, which is a name of the spill and if you click on a different URL from that group then you might get the different story. Here’s the CNN story about a game, the BP Oil Spill, and if you click on yet a third link, then you might get a different story. Here’s the UK Guardian story about the BP Oil Spill. So what Google News has done is look for tens of thousands of news stories and automatically cluster them together. So, the news stories that are all about the same topic get displayed together. It turns out that clustering algorithms and Unsupervised Learning algorithms are used in many other problems as well. DNAHere’s one on understanding genomics. Here’s an example of DNA microarray data.The idea is put a group of different individuals and for each of them, you measure how much they do or do not have a certain gene. Technically you measure how much certain genes are expressed. So these colors, red, green, gray and so on, they show the degree to which different individuals do or do not have a specific gene. And what you can do is then run a clustering algorithm to group individuals into different categories or into different types of people.So this is Unsupervised Learning because we’re not telling the algorithm in advance that these are type 1 people, those are type 2 persons, those are type 3 persons and so on and instead what were saying is yeah here’s a bunch of data. I don’t know what’s in this data. I don’t know who’s and what type. I don’t even know what the different types of people are, but can you automatically find structure in the data from the you automatically cluster the individuals into these types that I don’t know in advance? Because we’re not giving the algorithm the right answer for the examples in my data set, this is Unsupervised Learning.Unsupervised Learning or clustering is used for a bunch of other applications. large computer clustersIt’s used to organize large computer clusters. I had some friends looking at large data centers, that is large computer clusters and trying to figure out which machines tend to work together and if you can put those machines together, you can make your data center work more efficiently. social network analysisThis second application is on social network analysis. So given knowledge about which friends you email the most or given your Facebook friends or your Google+ circles, can we automatically identify which are cohesive groups of friends, also which are groups of people that all know each other? Market segmentationMany companies have huge databases of customer information. So, can you look at this customer data set and automatically discover market segments and automatically group your customers into different market segments so that you can automatically and more efficiently sell or market your different market segments together? Again, this is Unsupervised Learning because we have all this customer data, but we don’t know in advance what are the market segments and for the customers in our data set, you know, we don’t know in advance who is in market segment one, who is in market segment two, and so on. But we have to let the algorithm discover all this just from the data. astronomical data analysisFinally, it turns out that Unsupervised Learning is also used for surprisingly astronomical data analysis and these clustering algorithms gives surprisingly interesting useful theories of how galaxies are formed. All of these are examples of clustering, which is just one type of Unsupervised Learning. Let me tell you about another one. cocktail party problemI’m gonna tell you about the cocktail party problem. So, you’ve been to cocktail parties before, right? Well, you can imagine there’s a party, room full of people, all sitting around, all talking at the same time and there are all these overlapping voices because everyone is talking at the same time, and it is almost hard to hear the person in front of you. So maybe at a cocktail party with two people, two people talking at the same time, and it’s a somewhat small cocktail party. And we’re going to put two microphones in the room so there are microphones, and because these microphones are at two different distances from the speakers, each microphone records a different combination of these two speaker voices. Maybe speaker one is a little louder in microphone one and maybe speaker two is a little bit louder on microphone 2 because the 2 microphones are at different positions relative to the 2 speakers, but each microphone would cause an overlapping combination of both speakers’ voices. So here’s an actual recording of two speakers recorded by a researcher. Let me play for you the first : Your browser does not support the audio element. what the first microphone sounds like. One (uno), two (dos), three (tres), four (cuatro), five (cinco), six (seis), seven (siete), eight (ocho), nine (nueve), ten (y diez). All right, maybe not the most interesting cocktail party, there’s two people counting from one to ten in two languages but you know. What you just heard was the first microphone recording, here’s the second recording. Your browser does not support the audio element. Uno (one), dos (two), tres (three), cuatro (four), cinco (five), seis (six), siete (seven), ocho (eight), nueve (nine) y diez (ten). So we can do, is take these two microphone recorders and give them to an Unsupervised Learning algorithm called the cocktail party algorithm, and tell the algorithm - find structure in this data for you. And what the algorithm will do is listen to these audio recordings and say, you know it sounds like the two audio recordings are being added together or that have being summed together to produce these recordings that we had. Moreover, what the cocktail party algorithm will do is separate out these two audio sources that were being added or being summed together to form other recordings and, in fact, here’s the first output of the cocktail party algorithm. Your browser does not support the audio element. One, two, three, four, five, six, seven, eight, nine, ten. So, I separated out the English voice in one of the recordings. And here’s the second of it. Your browser does not support the audio element. Uno, dos, tres, quatro, cinco, seis, siete, ocho, nueve y diez. Not too bad, to give you one more example, here’s another recording of another similar situation, here’s the first microphone : Your browser does not support the audio element. One, two, three, four, five, six, seven, eight, nine, ten. OK so the poor guy’s gone home from the cocktail party and he ‘s now sitting in a room by himself talking to his radio. Here’s the second microphone recording. Your browser does not support the audio element. One, two, three, four, five, six, seven, eight, nine, ten. When you give these two microphone recordings to the same algorithm, what it does, is again say, you know, it sounds like there are two audio sources, and moreover, the album says, here is the first of the audio sources I found. Your browser does not support the audio element. One, two, three, four, five, six, seven, eight, nine, ten. So that wasn’t perfect, it got the voice, but it also got a little bit of the music in there. Then here’s the second output to the algorithm. Your browser does not support the audio element. Not too bad, in that second output it managed to get rid of the voice entirely. And just, you know, cleaned up the music, got rid of the counting from one to ten. So you might look at an Unsupervised Learning algorithm like this.Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don’t necessarily know the effect of the variables. We can derive this structure by clustering the data based on relationships among the variables in the data. With unsupervised learning there is no feedback based on the prediction results. Summary Clustering: Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles, and so on. Non-clustering: The “Cocktail Party Algorithm”, allows you to find structure in a chaotic environment. (i.e. identifying individual voices and music from a mesh of sounds at a cocktail party ). References Machine Learning by Andrew NG]]></content>
      <categories>
        <category>英文</category>
      </categories>
      <tags>
        <tag>Machine Learning by Andrew NG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-linear-algebra-review note3]]></title>
    <url>%2F2018%2F01%2F01%2F03-linear-algebra-review%2F</url>
    <content type="text"><![CDATA[NoteThis personal note is written after studying the coursera opening course, Machine Learning by Andrew NG . And images, audios of this note all comes from the opening course. Matrices and VectorsMatrices are 2-dimensional arrays: $$\begin{bmatrix}a&amp;b&amp;c\\d&amp;e&amp;f\\g&amp;h&amp;i\\j&amp;k&amp;l\\\end{bmatrix}$$The above matrix has four rows and three columns, so it is a $4 \times 3$ matrix.A vector is a matrix with one column and many rows:$$\begin{bmatrix}w\\x\\y\\z\end{bmatrix}$$ So vectors are a subset of matrices. The above vector is a $4 \times 1$ matrix. Notation and terms : ​ $A_{ij}$ refers to the element in the ith row and jth column of matrix A. ​ A vector with ‘n’ rows is referred to as an ‘n’-dimensional vector. ​ $v_i$ refers to the element in the ith row of the vector. ​ In general, all our vectors and matrices will be 1-indexed. Note that for some programming languages, the arrays are 0-indexed. ​ Matrices are usually denoted by uppercase names while vectors are lowercase. ​ “Scalar” means that an object is a single value, not a vector or matrix. ​ $\mathbb{R}$ refers to the set of scalar real numbers. ​ $\mathbb{R}^n$ refers to the set of n-dimensional vectors of real numbers. Run the cell below to get familiar with the commands in Octave/Matlab. Feel free to create matrices and vectors and try out different things. 1234567891011121314151617% The ; denotes we are going back to a new row.A = [1, 2, 3; 4, 5, 6; 7, 8, 9; 10, 11, 12]% Initialize a vector v = [1;2;3] % Get the dimension of the matrix A where m = rows and n = columns[m,n] = size(A)% You could also store it this waydim_A = size(A)% Get the dimension of the vector v dim_v = size(v)% Now let's index into the 2nd row 3rd column of matrix AA_23 = A(2,3) Addition and Scalar MultiplicationAddition and subtraction are element-wise , so you simply add or subtract each corresponding element: $$\begin{bmatrix} a &amp; b \\ c &amp; d \\ \end{bmatrix} + \begin{bmatrix} w &amp; x \\ y &amp; z \\ \end{bmatrix} = \begin{bmatrix} a+w &amp; b+x \\ c+y &amp; d+z \\ \end{bmatrix}$$ Subtracting Matrices: $$\begin{bmatrix} a &amp; b \\ c &amp; d \\ \end{bmatrix} - \begin{bmatrix} w &amp; x \\ y &amp; z \\ \end{bmatrix} =\begin{bmatrix} a-w &amp; b-x \\ c-y &amp; d-z \\ \end{bmatrix}$$ To add or subtract two matrices, their dimensions must be the same . In scalar multiplication, we simply multiply every element by the scalar value: $$ \begin{bmatrix} a & b \\ c & d \\ \end{bmatrix} * x =\begin{bmatrix} a*x & b*x \\ c*x & d*x \\ \end{bmatrix} $$ In scalar division, we simply divide every element by the scalar value:$$\begin{bmatrix} a &amp; b \\ c &amp; d \\ \end{bmatrix} / x =\begin{bmatrix} a /x &amp; b/x \\ c /x &amp; d /x \\ \end{bmatrix}$$ Experiment below with the Octave/Matlab commands for matrix addition and scalar multiplication. Feel free to try out different commands. Try to write out your answers for each command before running the cell below. 123456789101112131415161718192021% Initialize matrix A and B A = [1, 2, 4; 5, 3, 2]B = [1, 3, 4; 1, 1, 1]% Initialize constant s s = 2% See how element-wise addition worksadd_AB = A + B % See how element-wise subtraction workssub_AB = A - B% See how scalar multiplication worksmult_As = A * s% Divide A by sdiv_As = A / s% What happens if we have a Matrix + scalar?add_As = A + s Matrix-Vector MultiplicationWe map the column of the vector onto each row of the matrix, multiplying each element and summing the result. $$ \begin{bmatrix} a & b \\ c & d \\ e & f \end{bmatrix} *\begin{bmatrix} x \\ y \\ \end{bmatrix} =\begin{bmatrix} a*x + b*y \\ c*x + d*y \\ e*x + f*y\end{bmatrix} $$ The result is a vector. The number of columns of the matrix must equal the number of rows of the vector. An m x n matrix multiplied by an n x 1 vector results in an m x 1 vector . Below is an example of a matrix-vector multiplication. Make sure you understand how the multiplication works. Feel free to try different matrix-vector multiplications. 12345678% Initialize matrix A A = [1, 2, 3; 4, 5, 6;7, 8, 9] % Initialize vector v v = [1; 1; 1] % Multiply A * vAv = A * v Matrix-Matrix MultiplicationWe multiply two matrices by breaking it into several vector multiplications and concatenating the result. $$ \begin{bmatrix} a & b \\ c & d \\ e & f \end{bmatrix} *\begin{bmatrix} w & x \\ y & z \\ \end{bmatrix} =\begin{bmatrix} a*w + b*y & a*x + b*z \\ c*w + d*y & c*x + d*z \\ e*w + f*y & e*x + f*z\end{bmatrix} $$ An m x n matrix multiplied by an n x o matrix results in an m x o matrix. In the above example, a 3 x 2 matrix times a 2 x 2 matrix resulted in a 3 x 2 matrix. To multiply two matrices, the number of columns of the first matrix must equal the number of rows of the second matrix. For example: 12345678910% Initialize a 3 by 2 matrix A = [1, 2; 3, 4;5, 6]% Initialize a 2 by 1 matrix B = [1; 2] % We expect a resulting matrix of (3 by 2)*(2 by 1) = (3 by 1) mult_AB = A*B% Make sure you understand why we got that result Matrix Multiplication Properties ​ Matrices are not commutative: $A∗B≠B∗A,A∗B≠B∗A$ ​ Matrices are associative: $(A∗B)∗C=A∗(B∗C)$ The identity matrix , when multiplied by any matrix of the same dimensions, results in the original matrix. It’s just like multiplying numbers by 1. The identity matrix simply has 1’s on the diagonal (upper left to lower right diagonal) and 0’s elsewhere.$$\begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ \end{bmatrix}$$When multiplying the identity matrix after some matrix (A∗I), the square identity matrix’s dimension should match the other matrix’s columns. When multiplying the identity matrix before some other matrix (I∗A), the square identity matrix’s dimension should match the other matrix’s rows . 12345678910111213141516171819202122% Initialize random matrices A and B A = [1,2;4,5]B = [1,1;0,2]% Initialize a 2 by 2 identity matrixI = eye(2)% The above notation is the same as I = [1,0;0,1]% What happens when we multiply I*A ? IA = I*A % How about A*I ? AI = A*I % Compute A*B AB = A*B % Is it equal to B*A? BA = B*A % Note that IA = AI but AB != BA Inverse and Transpose The inverse of a matrix $A$ is denoted $A^{−1}$. Multiplying by the inverse results in the identity matrix. A non square matrix does not have an inverse matrix. We can compute inverses of matrices in octave with the pinv(A) function and in Matlab with the inv(A) function. Matrices that don’t have an inverse are singular or degenerate . The transposition of a matrix is like rotating the matrix 90 ° in clockwise direction and then reversing it. We can compute transposition of matrices in matlab with the transpose(A) function or A&#39; :$$A = \begin{bmatrix} a &amp; b \\ c &amp; d \\ e &amp; f \end{bmatrix}$$ $$A^T = \begin{bmatrix} a &amp; c &amp; e \\ b &amp; d &amp; f \\ \end{bmatrix}$$ In other words: $$A_{ij} = A^T_{ji}$$ 1234567891011% Initialize matrix A A = [1,2,0;0,5,6;7,0,9]% Transpose A A_trans = A' % Take the inverse of A A_inv = inv(A)% What is A^(-1)*A? A_invA = inv(A)*A]]></content>
      <categories>
        <category>英文</category>
      </categories>
      <tags>
        <tag>Machine Learning by Andrew NG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反向传播算法（Backpropagation）推导]]></title>
    <url>%2F2018%2F01%2F01%2Fneural_work_backpropagation_reasoning%2F</url>
    <content type="text"><![CDATA[反向传播算法（Backpropagation）是目前用来训练人工神经网络（Artificial Neural Network，ANN）的最常用且最有效的算法。其主要思想是： （1）将训练集数据输入到ANN的输入层，经过隐藏层，最后达到输出层并输出结果，这是ANN的前向传播过程； （2）由于ANN的输出结果与实际结果有误差，则计算估计值与实际值之间的误差，并将该误差从输出层向隐藏层反向传播，直至传播到输入层； （3）在反向传播的过程中，根据误差调整各种参数的值；不断迭代上述过程，直至收敛。 ​ 反向传播算法的思想比较容易理解，但具体的公式则要一步步推导，因此本文着重介绍公式的推导过程。 1. 变量定义 上图是一个三层人工神经网络，layer1 至 layer3 分别是输入层、隐藏层和输出层。如图，先定义一些变量: $w^l_{j,k}$ 表示第$l-1$层的第$k$个神经元连接到第$l$层的第$j$个神经元的权重； $b_j^l$ 表示第 $l$ 层的第 $j$ 个神经元的偏置； $z_j^l$ 表示第 $l$ 层的第 $j$ 个神经元的输入，即：$z^l_j=\sum_kw^l_{j,k}a_k^{l-1}+b_j^l$ $a_j^l$ 表示第 $l$ 层的第 $j$ 个神经元的输出，即：$a_j^l=\sigma(\sum_kw^l_{j,k}a^{l-1}_k+b^l_j)$ ，$\sigma$ 是激活函数。 2. 代价函数​ 代价函数被用来计算ANN输出值与实际值之间的误差。常用的代价函数是二次代价函数（Quadratic cost function）：$$C=\frac{1}{2m}\sum\limits_{i=1}^{m}||y(x_i)-a^L(x_i)||^2$$​ 其中 $x$ 表示输入的样本，$m$ 表示样本数， $y$ 表示实际的分类，$a^L$ 表示预测的输出，$L$ 表示神经网络的最大层数。 3. 公式及其推导​ 本节将介绍反向传播算法用到的4个公式，并进行推导。如果不想了解公式推导过程，请直接看第4节的算法步骤。 ​ 首先，将第 $l$ 层第 $j$ 个神经元中产生的错误（即实际值与预测值之间的误差）定义为：$$\delta_j^l\equiv \frac{\partial{C}}{\partial{z_j^l}}$$​ 本文将以一个输入样本为例进行说明，此时代价函数表示为：$$C=\frac{1}{2}||y-a^L||^2 = \frac{1}{2}\sum\limits_j(y_j-a_j^L)^2$$ 公式1（计算最后一层神经网络产生的错误）$$\delta^L=\nabla_aC\bigodot\sigma’(z^L)$$ 其中，$\bigodot$ 表示 Hadamard 乘积，用于矩阵或向量之间点对点的乘法运算。 推导过程$$\begin{align}&amp; \because \,\delta^L_j=\frac{\partial{C}}{\partial{z_j^L}}=\frac{\partial{C}}{\partial{a_j^L}}\cdot\frac{\partial{a_j^L}}{\partial{z_j^L}} \\&amp; \therefore \, \delta^L=\frac{\partial{C}}{\partial{a^L}}\bigodot\frac{\partial{a^L}}{\partial{z^L}}=\nabla_aC\bigodot\sigma’(z^L)\end{align}$$ 公式2（由后往前，计算每一层神经网络产生的错误）：$$\delta^l=( (w^{l+1})^T \delta^{l+1})\bigodot\sigma’(z^l)$$ 推导过程$$\begin{align}\because\ \delta_j^l &amp;= \frac{\partial{C}}{\partial{z_j^l}}=\sum_k\frac{\partial{C}}{\partial{z_k^{l+1}}}\cdot\frac{\partial{z^{l+1}_k}}{\partial{a_j^l}}\cdot\frac{\partial{a_j^l}}{\partial{z_j^l}} \\&amp;= \sum_k \delta_k^{l+1} \cdot \frac{\partial({w_{k,j}^{l+1}} a_j^l+b_k^{l+1})}{\partial{a_j^l}}\cdot\sigma’(z_j^l)\\&amp;=\sum_k \delta^{l+1}_k\cdot w_{k,l}^{l+1}\cdot \sigma’(z_j^l) \\\therefore\ \delta^l &amp;= ((w^{l+1})^T\delta^{l+1})\bigodot \sigma’(z^l)\end{align}$$ 公式3（计算权重的梯度）$${\partial C \over \partial w_{j,k}^l } = a^{l-1}_k\delta^l_j$$ 推导过程$$\frac{\partial{C}}{\partial{w_{j,k}^l}}=\frac{\partial{C}}{\partial{z_j^l}}\frac{\partial{z_j^l}}{\partial{w_{j,k}^l}} = \delta_j^l\cdot\frac{\partial(w_{j,k}^l a_k^{l-1} + b_j^l)}{\partial w_{j,k}^l} = a_k^{l-1}\delta^l_j$$ 公式4（计算偏置的梯度）$$\frac{\partial{C}}{\partial{b_j^l}}=\delta_j^l$$ 推导过程$$\frac{\partial{C}}{\partial{b_j^l}} = \frac{\partial{C}}{\partial z_j^l}\frac{\partial{z_j^l}}{\partial{b_j^l}} = \delta_j^l \cdot \frac{\partial({w_{j,k}^la_k^{l-1}} + b _j^l)}{\partial{b^l_j}} = \partial^l_j$$ 4. 反向传播算法伪代码 输入训练集 对于训练集中的每个样本x，设置输入层（Input layer）对应的激活值： 前向传播：$$z^l = w^la^{l-1}+b^l,a^l=\sigma(z^l)$$ 计算输出层产生的错误：$$\delta^L=\nabla_aC\bigodot\sigma’(z^L)$$ 反向传播错误：$$\delta^l=((w^{l+1})^T\delta^{l+1})\bigodot\sigma’(z^l)$$ 使用梯度下降（gradient descent），训练参数：$$\begin{align}&amp; w^l\rightarrow w^l - \frac{\alpha}{m}\sum\limits_{i=1}^{i=m}\delta^{x_i,l}(a^{x_i,l-1})^T\\&amp;b^l\rightarrow b^l - \frac{\alpha}{m}\sum\limits_{i=1}^{i=m}\delta^{x_i,l} \\\end{align}$$ 参考 http://www.cnblogs.com/wlzy/p/7751297.html https://blog.csdn.net/u014313009/article/details/51039334 [Neural Networks and Deep Learning]]]></content>
      <categories>
        <category>english</category>
      </categories>
      <tags>
        <tag>Machine Learning by Andrew NG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04_linear-regression-with-multiple-variables note4]]></title>
    <url>%2F2018%2F01%2F01%2F04_linear-regression-with-multiple-variables%2F</url>
    <content type="text"><![CDATA[Multiple FeaturesNote: [7:25 - $θ^T$ is a 1 by (n+1) matrix and not an (n+1) by 1 matrix] Linear regression with multiple variables is also known as “multivariate linear regression”. We now introduce notation for equations where we can have any number of input variables. $$ \begin{align*}x_j^{(i)} &= \text{value of feature } j \text{ in the }i^{th}\text{ training example} \\ x^{(i)}& = \text{the input (features) of the }i^{th}\text{ training example} \\ m &= \text{the number of training examples} \\ n &= \text{the number of features} \end{align*} $$ The multivariable form of the hypothesis function accommodating these multiple features is as follows: $$h_\theta (x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_3 + \cdots + \theta_n x_n$$ In order to develop intuition about this function, we can think about $θ_0$ as the basic price of a house, $θ_1$ as the price per square meter, $θ_2$ as the price per floor, etc. $x_1$ will be the number of square meters in the house, $x_2$ the number of floors, etc. Using the definition of matrix multiplication, our multivariable hypothesis function can be concisely represented as : $$ \begin{align*}h_\theta(x) =\begin{bmatrix}\theta_0 \hspace{2em} \theta_1 \hspace{2em} ... \hspace{2em} \theta_n\end{bmatrix}\begin{bmatrix}x_0 \\ x_1 \\ \vdots \\ x_n\end{bmatrix}= \theta^T x\end{align*} $$ This is a vectorization of our hypothesis function for one training example; see the lessons on vectorization to learn more. Remark : Note that for convenience reasons in this course we assume $x^{(i)}_0=1 \text{ for }(i∈1,…,m)$ . This allows us to do matrix operations with theta and x. Hence making the two vectors ‘ $θ$ ‘ and $x^{(i)}$ match each other element-wise (that is, have the same number of elements: n+1) .] Gradient Descent For Multiple VariablesThe gradient descent equation itself is generally the same form; we just have to repeat it for our ‘n’ features : $$ \begin{align*} & \text{repeat until convergence:} \; \lbrace \newline \; & \theta_0 := \theta_0 - \alpha \frac{1}{m} \sum\limits_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x_0^{(i)}\newline \; & \theta_1 := \theta_1 - \alpha \frac{1}{m} \sum\limits_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x_1^{(i)} \newline \; & \theta_2 := \theta_2 - \alpha \frac{1}{m} \sum\limits_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x_2^{(i)} \newline & \cdots \newline \rbrace \end{align*} $$ In other words : $$ \begin{align*}& \text{repeat until convergence:} \; \lbrace \newline \; & \theta_j := \theta_j - \alpha \frac{1}{m} \sum\limits_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} \; & \text{for j := 0...n}\newline \rbrace\end{align*} $$ The following image compares gradient descent with one variable to gradient descent with multiple variables: Gradient Descent in Practice I - Feature Scaling Note: [6:20 - The average size of a house is 1000 but 100 is accidentally written instead] We can speed up gradient descent by having each of our input values in roughly the same range. This is because $θ$ will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven. The way to prevent this is to modify the ranges of our input variables so that they are all roughly the same. Ideally:$$−1 ≤ x_{(i)} ≤ 1 \text{ or } −0.5 ≤ x_{(i)} ≤ 0.5$$These aren’t exact requirements; we are only trying to speed things up. The goal is to get all input variables into roughly one of these ranges, give or take a few. Two techniques to help with this are feature scaling and mean normalization . Feature scaling involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable, resulting in a new range of just 1. Mean normalization involves subtracting the average value for an input variable from the values for that input variable resulting in a new average value for the input variable of just zero. To implement both of these techniques, adjust your input values as shown in this formula: $$x_i := \dfrac{x_i - \mu_i}{s_i}$$ Where $μ_i$ is the average of all the values for feature (i) and $s_i$ is the range of values (max - min), or $s_i$ is the standard deviation. Note that dividing by the range, or dividing by the standard deviation, give different results. The quizzes in this course use range - the programming exercises use standard deviation. For example, if $x_i$ represents housing prices with a range of 100 to 2000 and a mean value of 1000, then, $x_i := \dfrac{price-1000}{1900}$ Gradient Descent in Practice II - Learning RateNote: [5:20 - the x -axis label in the right graph should be $θ$ rather than No. of iterations ] Debugging gradient descent. Make a plot with number of iterations on the x-axis. Now plot the cost function, $J(θ)$ over the number of iterations of gradient descent. If $J(θ)$ ever increases, then you probably need to decrease $α$. Automatic convergence test. Declare convergence if $J(θ)$ decreases by less than E in one iteration, where E is some small value such as $10^{−3}$. However in practice it’s difficult to choose this threshold value. It has been proven that if learning rate $α$ is sufficiently small, then $J(θ)$ will decrease on every iteration. To summarize: If $α$ is too small: slow convergence. If $α$ is too large: ￼$J(\theta)$ may not decrease on every iteration and thus may not converge. Features and Polynomial RegressionWe can improve our features and the form of our hypothesis function in a couple different ways. We can combine multiple features into one. For example, we can combine $x_1$ and $x_2$ into a new feature $x_3$ by taking $x_1⋅x_2$ . Polynomial RegressionOur hypothesis function need not be linear (a straight line) if that does not fit the data well. We can change the behavior or curve of our hypothesis function by making it a quadratic, cubic or square root function (or any other form). For example, if our hypothesis function is $h_\theta(x) = \theta_0 + \theta_1 x_1$, then we can create additional features based on $x_1$, to get the quadratic function $h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_1^2$, or the cubic function $h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_1^2 + \theta_3 x_1^3$ . In the cubic version, we have created new features $x_2$ and $x_3$ where $x_2=x_1^2$ and $x_3=x_1^3$. To make it a square root function, we could do: $h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 \sqrt{x_1}$ One important thing to keep in mind is, if you choose your features this way then feature scaling becomes very important. eg. if $x_1$ has range 1 - 1000 then range of $x_1^2$ becomes 1 - 1000000 and that of $x_1^3$ becomes 1 - 1000000000 Normal EquationNote: [8:00 to 8:44 - The design matrix $X$ (in the bottom right side of the slide) given in the example should have elements $x$ with subscript 1 and superscripts varying from 1 to m because for all m training sets there are only 2 features $x_0$ and $x_1$. 12:56 - The $X$ matrix is m by (n+1) and NOT n by n. ] Gradient descent gives one way of minimizing $J$ . Let’s discuss a second way of doing so, this time performing the minimization explicitly and without resorting to an iterative algorithm. In the “Normal Equation” method, we will minimize $J$ by explicitly taking its derivatives with respect to the θj’s, and setting them to zero. This allows us to find the optimum theta without iteration. The normal equation formula is given below:$$\theta = (X^T X)^{-1}X^T y$$ There is no need to do feature scaling with the normal equation. The following is a comparison of gradient descent and the normal equation: Gradient Descent Normal Equation Need to choose alpha No need to choose alpha Needs many iterations No need to iterate O ( $kn^2$ ) O ($n^3$), need to calculate inverse of $X^TX$ Works well when n is large Slow if n is very large With the normal equation, computing the inversion has complexity $O(n^3)$ . So if we have a very large number of features, the normal equation will be slow. In practice, when n exceeds 10,000 it might be a good time to go from a normal solution to an iterative process. Normal Equation NoninvertibilityWhen implementing the normal equation in octave we want to use the pinv function rather than inv The pinvfunction will give you a value of $θ$ even if $X^TX$ is not invertible. ( pinv(A) means calculating the pseudo inverse of matrix A ) If $X^TX$ is noninvertible, the common causes might be having : Redundant features, where two features are very closely related (i.e. they are linearly dependent) Too many features (e.g. m ≤ n). In this case, delete some features or use “regularization” (to be explained in a later lesson). Solutions to the above problems include deleting a feature that is linearly dependent with another or deleting one or more features when there are too many features.]]></content>
      <categories>
        <category>english</category>
      </categories>
      <tags>
        <tag>Machine Learning by Andrew NG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05_octave-matlab-tutorial note5]]></title>
    <url>%2F2018%2F01%2F01%2F05_octave-matlab-tutorial%2F</url>
    <content type="text"><![CDATA[5.1 基本操作在这段视频中，我将教你一种编程语言：Octave语言。你能够用它来非常迅速地实现这门课中我们已经学过的，或者将要学的机器学习算法。 过去我一直尝试用不同的编程语言来教授机器学习，包括C++、Java、Python、Numpy和Octave。我发现当使用像Octave这样的高级语言时，学生能够更快更好地学习并掌握这些算法。事实上，在硅谷，我经常看到进行大规模的机器学习项目的人，通常使用的程序语言就是Octave。 Octave是一种很好的原始语言(prototyping language)，使用Octave你能快速地实现你的算法，剩下的事情，你只需要进行大规模的资源配置，你只用再花时间用C++或Java这些语言把算法重新实现就行了。开发项目的时间是很宝贵的，机器学习的时间也是很宝贵的。所以，如果你能让你的学习算法在Octave上快速的实现，基本的想法实现以后，再用C++或者Java去改写，这样你就能节省出大量的时间。 据我所见，人们使用最多的用于机器学习的原始语言是Octave、MATLAB、Python、NumPy 和R。 Octave很好，因为它是开源的。当然MATLAB也很好，但它不是每个人都买得起的。貌似国内学生喜欢用收费的matlab，matlab功能要比Octave强大的多，网上有各种D版可以下载。这次机器学习课的作业也是用matlab的。如果你能够使用MATLAB，你也可以在这门课里面使用。 如果你会Python、NumPy或者R语言，我也见过有人用 R的，据我所知，这些人不得不中途放弃了，因为这些语言在开发上比较慢，而且，因为这些语言如：Python、NumPy的语法相较于Octave来说，还是更麻烦一点。正因为这样，所以我强烈建议不要用NumPy或者R来完整这门课的作业，我建议在这门课中用Octave来写程序。 本视频将快速地介绍一系列的命令，目标是迅速地展示，通过这一系列Octave的命令，让你知道Octave能用来做什么。 启动Octave： 现在打开Octave，这是Octave命令行。 现在让我示范最基本的Octave代码： 输入5 + 6，然后得到11。输入3 – 2、5×8、1/2、2^6等等，得到相应答案。 这些都是基本的数学运算。 你也可以做逻辑运算，例如 1==2，计算结果为 false ( 假)，这里的百分号命令表示注释，1==2 计算结果为假，这里用0表示。 请注意，不等于符号的写法是这个波浪线加上等于符号 ( ~= )，而不是等于感叹号加等号( != )，这是和其他一些编程语言中不太一样的地方。 让我们看看逻辑运算 1 &amp;&amp; 0，使用双&amp;符号表示逻辑与，1 &amp;&amp; 0判断为假，1和0的或运算 1 || 0，其计算结果为真。 还有异或运算 如 XOR ( 1, 0 )，其返回值为1 从左向右写着 Octave 324.x版本，是默认的Octave提示，它显示了当前Octave的版本，以及相关的其它信息。 如果你不想看到那个提示，这里有一个隐藏的命令 输入命令 现在命令提示已经变得简化了。 接下来，我们将谈到Octave的变量。 现在写一个变量，对变量A赋值为3，并按下回车键，显示变量A等于3。 打印变量如果你想分配一个变量，但不希望在屏幕上显示结果，你可以在命令后加一个分号，可以抑制打印输出**，敲入回车后，不打印任何东西。 其中这句命令不打印任何东西。 现在举一个字符串的例子：变量b等于”hi”。 C等于3大于等于1，所以，现在C变量的值是真。 如果你想打印出变量，或显示一个变量，你可以像下面这么做： 设置A等于圆周率π，如果我要打印该值，那么只需键入A像这样 就打印出来了。 对于更复杂的屏幕输出，也可以用DISP命令显示： 这是一种，旧风格的C语言语法，对于之前就学过C语言的同学来说，你可以使用这种基本的语法来将结果打印到屏幕。 例如 sprintf命令的六个小数：0.6%f ,a，这应该打印π的6位小数形式。 也有一些控制输出长短格式的快捷命令： 下面，让我们来看看向量和矩阵： 比方说 建立一个矩阵A 对A矩阵进行赋值 考虑到这是一个三行两列的矩阵 你同样可以用向量 建立向量V并赋值1 2 3，V是一个行向量，或者说是一个3 ( 列 )×1 ( 行 )的向量，或者说，一行三列的矩阵。 如果我想，分配一个列向量，我可以写“1;2;3”，现在便有了一个3 行 1 列的向量，同时这是一个列向量。 通过增量或步长来构造矩阵下面是一些更为有用的符号，如： 1V=1:0.1:2 这个该如何理解呢：这个集合V是一组值，从数值1开始，增量或说是步长为0.1，直到增加到2，按照这样的方法对向量V操作，可以得到一个行向量，这是一个1行11列的矩阵，其矩阵的元素是11.1 1.2 1.3，依此类推，直到数值2。 1V=[1:0.5:2;3:0.5:4] 我也可以建立一个集合V并用命令“1:6”进行赋值，这样V就被赋值了1至6的六个整数。 这里还有一些其他的方法来生成矩阵 ones &amp; zeros例如“ones(2, 3)”，也可以用来生成矩阵： 元素都为2，两行三列的矩阵，就可以使用这个命令： 你可以把这个方法当成一个生成矩阵的快速方法。 w为一个一行三列的零矩阵，一行三列的A矩阵里的元素全部是零： 还有很多的方式来生成矩阵。 如果我对W进行赋值，用Rand命令建立一个一行三列的矩阵，因为使用了Rand命令，则其一行三列的元素均为随机值，如“rand(3,3)”命令，这就生成了一个3×3的矩阵，并且其所有元素均为随机。 数值介于0和1之间，所以，正是因为这一点，我们可以得到数值均匀介于0和1之间的元素。 如果，你知道什么是高斯随机变量，或者，你知道什么是正态分布的随机变量，你可以设置集合W，使其等于一个一行三列的N矩阵，并且，来自三个值，一个平均值为0的高斯分布，方差或者等于1的标准偏差。 linspace &amp; logspacelinspace(x1,x2,N) 创建一个N个元素的向量,均匀分布于x1和x2之间 logspace(x1,x2,N) 创建一个N个元素的向量,指数分布与10的x1次方和10的x2次方之间 histogram 直方图并用hist命令绘制直方图。 单位矩阵 identity matrix绘制单位矩阵： help如果对命令不清楚，建议用help命令： 以上讲解的内容都是Octave的基本操作。希望你能通过上面的讲解，自己练习一些矩阵、乘、加等操作，将这些操作在Octave中熟练运用。 在接下来的视频中，将会涉及更多复杂的命令，并使用它们在Octave中对数据进行更多的操作。 5.2 移动数据在这段关于 Octave的辅导课视频中，我将开始介绍如何在 Octave 中移动数据。 如果你有一个机器学习问题，你怎样把数据加载到 Octave 中？ 怎样把数据存入一个矩阵？ 如何对矩阵进行相乘？ 如何保存计算结果？ 如何移动这些数据并用数据进行操作？ 进入我的 Octave 窗口， 我键入 A，得到我们之前构建的矩阵 A，也就是用这个命令生成的： sizeA = [1 2; 3 4; 5 6] 这是一个3行2列的矩阵，Octave 中的 size() 命令返回矩阵的尺寸。 所以 size(A) 命令返回3 2 实际上，size() 命令返回的是一个 1×2 的矩阵，我们可以用 sz 来存放。 设置 sz = size(A) 因此 sz 就是一个1×2的矩阵，第一个元素是3，第二个元素是2。 所以如果键入 size(sz) 看看 sz 的尺寸，返回的是1 2，表示是一个1×2的矩阵，1 和 2分别表示矩阵sz的维度 。 你也可以键入 size(A, 1)，将返回3，这个命令会返回A 矩阵的第一个元素，A矩阵的第一个维度的尺寸，也就是 A 矩阵的行数。 同样，命令 size(A, 2)，将返回2，也就是 A 矩阵的列数。 length如果你有一个向量 v，假如 v = [1 2 3 4]，然后键入length(v)，这个命令将返回最大维度的大小，返回4。 你也可以键入 length(A)，由于矩阵A是一个3×2的矩阵，因此最大的维度应该是3，因此该命令会返回3。 但通常我们还是对向量使用 length 命令，而不是对矩阵使用 length 命令，比如length([1;2;3;4;5])，返回5。 加载数据和寻找数据如何在系统中加载数据和寻找数据： 当我们打开 Octave 时，我们通常已经在一个默认路径中，这个路径是 Octave的安装位置，pwd 命令可以显示出Octave 当前所处路径。 cd命令，意思是改变路径，我可以把路径改为C:\Users\ang\Desktop，这样当前目录就变为了桌面。 如果键入 ls，ls 来自于一个 Unix 或者 Linux 命令，ls命令将列出我桌面上的所有路径。 事实上，我的桌面上有两个文件：featuresX.dat 和priceY.dat，是两个我想解决的机器学习问题。 featuresX 文件如这个窗口所示，是一个含有两列数据的文件，其实就是我的房屋价格数据，数据集中有47行，第一个房子样本，面积是2104平方英尺，有3个卧室，第二套房子面积为1600，有3个卧室等等。 priceY这个文件就是训练集中的价格数据，所以 featuresX 和priceY就是两个存放数据的文档，那么应该怎样把数据读入 Octave 呢？我们只需要键入 load featuresX.dat，这样我将加载了 featuresX 文件。同样地我可以加载priceY.dat。其实有好多种办法可以完成，如果你把命令写成字符串的形式load(&#39;featureX.dat&#39;)，也是可以的，这跟刚才的命令效果是相同的，只不过是把文件名写成了一个字符串的形式，现在文件名被存在一个字符串中。Octave中使用引号来表示字符串。 另外 who 命令，能显示出 在我的 Octave工作空间中的所有变量 所以我可以键入featuresX 回车，来显示 featuresX 这些就是存在里面的数据。 还可以键入 size(featuresX)，得出的结果是 47 2，代表这是一个47×2的矩阵。 类似地，输入 size(priceY)，结果是 471，表示这是一个47维的向量，是一个列矩阵，存放的是训练集中的所有价格 Y 的值。 who and whoswho 函数能让你看到当前工作空间中的所有变量，同样还有另一个 whos命令，能更详细地进行查看。 同样也列出我所有的变量，不仅如此，还列出了变量的维度。 double 意思是双精度浮点型，这也就是说，这些数都是实数，是浮点数。 删除变量如果你想删除某个变量，你可以使用 clear 命令，我们键入 clear featuresX，然后再输入 whos 命令，你会发现 featuresX 消失了。 另外，我们怎么储存数据呢？ 我们设变量 v= priceY(1:10) 这表示的是将向量 Y 的前10个元素存入 v 中。 保存数据假如我们想把它存入硬盘，那么用 save hello.mat v 命令，这个命令会将变量v存成一个叫 hello.mat 的文件，这个命令把数据按照二进制形式储存，或者说是更压缩的二进制形式，因此，如果v是很大的数据，那么压缩幅度也更大，占用空间也更小。如果你想把数据存成一个人能看懂的形式，那么可以键入： save hello.txt v -ascii 这样就会把数据存成一个文本文档或者将数据的 ascii 码存成文本文档。 我键入了这个命令以后，我的桌面上就有了 hello.txt文件。如果打开它，我们可以发现这个文本文档存放着我们的数据。 这就是读取和储存数据的方法。 接下来我们再来讲讲操作数据的方法： 假如 A 还是那个矩阵 A(3,2)这将索引到A 矩阵的 (3,2) 元素。 取单行/列数据A(2,:) 来返回第二行的所有元素，冒号表示该行或该列的所有元素。 类似地，如果我键入 A(:,2)，这将返回 A 矩阵第二列的所有元素。 你也可以在运算中使用这些较为复杂的索引。 A([1 3],:)，这个命令意思是取 A 矩阵第一个索引值为1或3的元素，也就是说我取的是A矩阵的第一行和第三行的每一列，冒号表示的是取这两行的每一列元素，即： 可能这些比较复杂一点的索引操作你会经常用到。 我们还能做什么呢？依然是 A 矩阵，A(:,2) 命令返回第二列。 你也可以为它赋值，我可以取 A 矩阵的第二列，然后将它赋值为10 11 12，我实际上是取出了 A 的第二列，然后把一个列向量[10;11;12]赋给了它，因此现在 A 矩阵的第一列还是 1 3 5，第二列就被替换为 10 11 12。 连接矩阵列追加A = [A, [100, 101, 102]]，这样做的结果是在原矩阵的右边附加了一个新的列矩阵，就是把 A矩阵设置为原来的 A 矩阵再在右边附上一个新添加的列矩阵。 行追加A=[A;[0,0,0]] 拼接我还是把 A 重新设为 [1 2; 3 4; 5 6]，我再设一个 B为[11 12; 13 14; 15 16]，我可以新建一个矩阵 C，C = [A B]，这个意思就是把这两个矩阵直接连在一起，矩阵 A 在左边，矩阵 B 在右边，这样组成了 C 矩阵，就是直接把 A 和 B 合起来。 我还可以设C = [A; B]，这里的分号表示把分号后面的东西放到下面。所以，[A;B]的作用依然还是把两个矩阵放在一起，只不过现在是上下排列，所以现在 A 在上面 B在下面，C 就是一个 6×2 矩阵。 简单地说，分号的意思就是换到下一行，所以 C 就包括上面的A，然后换行到下面，然后在下面放上一个 B。 另外顺便说一下，这个[A B]命令跟 [A, B] 是一样的，这两种写法的结果是相同的。 矩阵变向量最后，还有一个小技巧，如果你就输入 A(:)，这是一个很特别的语法结构，意思是把 A中的所有元素放入一个单独的列向量，这样我们就得到了一个 9×1 的向量，这些元素都是A 中的元素排列起来的。 通过以上这些操作，希望你现在掌握了怎样构建矩阵，也希望我展示的这些命令能让你很快地学会怎样把矩阵放到一起，怎样取出矩阵，并且把它们放到一起，组成更大的矩阵。 5.3 计算数据现在，你已经学会了在Octave中如何加载或存储数据，如何把数据存入矩阵等等。在这段视频中，我将介绍如何对数据进行运算，稍后我们将使用这些运算操作来实现我们的学习算法。 这是我的 Octave窗口，我现在快速地初始化一些变量。比如设置A为一个3×2的矩阵，设置B为一个3 ×2矩阵，设置C为2 × 2矩阵。 矩阵乘法我想算两个矩阵的乘积，比如说 A × C，我只需键入A×C，这是一个 3×2 矩阵乘以 2×2矩阵，得到这样一个3×2矩阵。 基于元素的运算通常来说，在Octave中点号一般用来表示元素位运算。你也可以对每一个元素，做运算方法是做点乘运算 A .*B，这么做Octave将矩阵 A中的每一个元素与矩阵 B 中的对应元素相乘 A .* B 这里第一个元素1乘以11得到11，第二个元素2乘以12得到24，这就是两个矩阵的元素位运算。 这里是一个矩阵A，这里我输入A .^ 2，这将对矩阵A中每一个元素平方。 我们设V是一个向量，设V为 [1; 2; 3] 是列向量，你也可以输入1 ./V，得到每一个元素的倒数，所以这样一来，就会分别算出 1/1 1/2 1/3。 矩阵也可以这样操作，1 ./ A 得到A中每一个元素的倒数。 同样地，这里的点号还是表示对每一个元素进行操作。 求对数运算我们还可以进行求对数运算，也就是对每个元素进行求对数运算。 幂运算还有自然数e的幂次运算，就是以e为底，以这些元素为幂的运算。 绝对值运算我还可以用 abs来对 v 的每一个元素求绝对值，当然这里 v都是正数。我们换成另一个这样对每个元素求绝对值，得到的结果就是这些非负的元素。 相反数运算还有–v，给出V中每个元素的相反数，这等价于 -1 乘以 v，一般就直接用 -v 就好了，其实就等于 -1*v。 加法我们想对v中的每个元素都加1，那么我们可以这么做，首先构造一个3行1列的1向量，然后把这个1向量跟原来的向量相加，因此 v 向量从[1 2 3] 增至 [2 3 4]。我用了一个，length(v)命令，因此这样一来，ones(length(v) ,1) 就相当于ones(3,1)，然后我做的是v +ones(3,1)，也就是将 v 的各元素都加上这些1，这样就将 v 的每个元素增加了1。 另一种更简单的方法是直接用 v+1，v + 1 也就等于把 v 中的每一个元素都加上1。 转置矩阵A 如果你想要求它的转置，那么方法是用A’,将得出 A 的转置矩阵。当然，如果我写(A’)’，也就是 A 转置两次，那么我又重新得到矩阵 A。 最大值还有一些有用的函数，比如： a=[1 15 2 0.5]，这是一个1行4列矩阵，val=max(a)，这将返回A矩阵中的最大值15。 我还可以写 [val, ind] =max(a)，这将返回a矩阵中的最大值存入val，以及该值对应的索引，元素15对应的索引值为2存入ind，所以 ind 等于2 特别注意一下，如果你用命令 max(A)，A是一个矩阵的话，这样做就是对每一列求最大值。 我们还是用这个例子，这个 a 矩阵a=[1 15 2 0.5]，如果输入a&lt;3，这将进行逐元素的运算，所以元素小于3的返回1，否则返回0。 因此，返回[1 1 0 1]。也就是说，对a矩阵的每一个元素与3进行比较，然后根据每一个元素与3的大小关系，返回1和0表示真与假。 find如果我写 find(a&lt;3)，这将告诉我a 中的哪些元素是小于3的。 如果我输入 [r,c] = find(A&gt;=7)，这将找出所有A矩阵中大于等于7的元素，因此，r 和c分别表示行和列，这就表示，第一行第一列的元素大于等于7，第三行第二列的元素大于等于7，第二行第三列的元素大于等于7。 顺便说一句，其实我从来都不去刻意记住这个 find 函数，到底是怎么用的，我只需要会用help 函数就可以了，每当我在使用这个函数，忘记怎么用的时候，我就可以用 help函数，键入 help find 来找到帮助文档。 magic设A = magic(3)，magic 函数将返回一个矩阵，称为魔方阵或幻方 (magic squares)，它们具有以下这样的数学性质：它们所有的行和列和对角线加起来都等于相同的值。 当然据我所知，这在机器学习里基本用不上，但我可以用这个方法很方便地生成一个3行3列的矩阵，而这个魔方矩阵这神奇的方形屏幕。每一行、每一列、每一个对角线三个数字加起来都是等于同一个数。 在其他有用的机器学习应用中，这个矩阵其实没多大作用。 sum\ceil\floor最后再讲两个内容，一个是求和函数，这是 a 矩阵： 键入 sum(a)，就把 a 中所有元素加起来了。 如果我想把它们都乘起来，键入 prod(a)，prod 意思是product(乘积)，它将返回这四个元素的乘积。 floor(a) 是向下四舍五入，因此对于 a 中的元素0.5将被下舍入变成0。 还有 ceil(a)，表示向上四舍五入，所以0.5将上舍入变为最接近的整数，也就是1。 键入 type(3)，这通常得到一个3×3的矩阵 每行\列最大值假如我输入max(A,[],1)，这样做会得到每一列的最大值。 所以第一列的最大值就是8，第二列是9，第三列的最大值是7，这里的1表示取A矩阵第一个维度的最大值。 相对地，如果我键入max(A,[],2)，这将得到每一行的最大值，所以，第一行的最大值是等于8，第二行最大值是7，第三行是9。 所以你可以用这个方法来求得每一行或每一列的最值，另外，你要知道，默认情况下max(A)返回的是每一列的最大值，如果你想要找出整个矩阵A的最大值，你可以输入max(max(A))，或者你可以将A 矩阵转成一个向量，然后键入 max(A(:))，这样做就是把 A 当做一个向量，并返回 A向量中的最大值。 如果键入 max(rand(3),rand(3))，这样做的结果是返回两个3×3的随机矩阵，并且逐元素比较取最大值。 最后，让我们把 A设为一个9行9列的魔方阵，魔方阵具有的特性是每行每列和对角线的求和都是相等的。 列行和这是一个9×9的魔方阵，我们来求一个 sum(A,1)，这样就得到每一列的总和，这也验证了一个9×9的魔方阵确实每一列加起来都相等，都为369。 现在我们来求每一行的和，键入sum(A,2)，这样就得到了A 中每一行的和加起来还是369。 对角元素和现在我们来算A 的对角线元素的和。我们现在构造一个9×9 的单位矩阵， 键入 eye(9) 然后我们要用 A 逐点乘以这个单位矩阵，除了对角线元素外，其他元素都会得到0。 键入sum(sum(A.*eye(9)) 这实际上是求得了，这个矩阵对角线元素的和确实是369。 你也可以求另一条对角线的和也是是369：sum(flipup(A)*eye(9)) 矩阵向上/向下翻转flipup/flipud 表示向上/向下翻转。 同样地，如果你想求这个矩阵的逆矩阵，键入pinv(A)，通常称为伪逆矩阵，你就把它看成是矩阵 A 求逆，因此这就是 A矩阵的逆矩阵。 设 temp = pinv(A)，然后再用temp 乘以 A，这实际上得到的就是单位矩阵，对角线为1，其他元素为0。 5.4 绘图数据当开发学习算法时，往往几个简单的图，可以让你更好地理解算法的内容，并且可以完整地检查下算法是否正常运行，是否达到了算法的目的。 例如在之前的视频中，我谈到了绘制成本函数 $J(θ)$，可以帮助确认梯度下降算法是否收敛。通常情况下，绘制数据或学习算法所有输出，也会启发你如何改进你的学习算法。幸运的是，Octave有非常简单的工具用来生成大量不同的图。当我用学习算法时，我发现绘制数据、绘制学习算法等，往往是我获得想法来改进算法的重要部分。在这段视频中，我想告诉你一些Octave的工具来绘制和可视化你的数据。 我们先来快速生成一些数据用来绘图。 如果我想绘制正弦函数，这是很容易的，我只需要输入plot(t,y1)，并回车，就出现了这个图： 横轴是t变量，纵轴是y1，也就是我们刚刚所输出的正弦函数。 axis([0.5 1 -1 1]) 改变坐标轴范围，横坐标：[0.5，1] 纵坐标：[-1，1] 让我们设置y2 Octave将会消除之前的正弦图，并且用这个余弦图来代替它，这里纵轴cos(x)从1开始， 如果我要同时表示正弦和余弦曲线。我要做的就是，输入：plot(t, y1)，得到正弦函数，我使用函数hold on，hold on函数的功能是将新的图像绘制在旧的之上 ，我现在绘制y2，输入：plot(t, y2)。 我要以不同的颜色绘制余弦函数，所以我在这里输入带引号的r绘制余弦函数，r表示所使用的颜色：plot(t,y2,’r’)，再加上命令xlabel(&#39;time&#39;)，来标记X轴即水平轴，输入ylabel(&#39;value&#39;)，来标记垂直轴的值。 同时我也可以来 标记函数曲线，用这个命令 legend(&#39;sin&#39;,&#39;cos&#39;) 将这个图例放在右上方，表示这两条曲线表示的内容。最后输入title(&#39;myplot&#39;)，在图像的顶部显示这幅图的标题。 如果你想 保存这幅图像，你输入print –dpng &#39;myplot.png&#39;，png是一个图像文件格式，如果你这样做了，它可以让你保存为一个文件。 Octave也可以保存为很多其他的格式，你可以键入help plot。 最后如果你想，删掉这个图像，用命令close会让这个图像关掉。 Octave也可以让你为图像标号你键入figure(1); plot(t, y1);将显示第一张图，绘制了变量t y1。键入figure(2); plot(t, y2); 将显示第一张图，绘制了变量t y2。 subplotsubplot命令，我们要使用subplot(1,2,1)，它将图像分为一个1*2的格子，也就是前两个参数，然后它使用第一个格子，也就是最后一个参数1的意思。 我现在使用第一个格子，如果键入plot(t,y1)，现在这个图显示在第一个格子。如果我键入subplot(1,2,2)，那么我就要使用第二个格子，键入plot(t,y2)；现在y2显示在右边，也就是第二个格子。 最后一个命令，你可以改变轴的刻度，比如改成[0.5 1 -1 1]，输入命令：axis([0.5 1 -1 1])也就是设置了右边图的x轴和y轴的范围。具体而言，它将右图中的横轴的范围调整至0.5到1，竖轴的范围为-1到1。 你不需要记住所有这些命令，如果你需要改变坐标轴，或者需要知道axis命令，你可以用Octave中用help命令了解细节。最后，还有几个命令。 Clf（清除一幅图像）。 让我们设置A等于一个5×5的magic方阵： 我有时用一个巧妙的方法来可视化矩阵，也就是imagesc(A)命令，它将会绘制一个55的矩阵，一个55的彩色格图，不同的颜色对应A矩阵中的不同值。 我还可以使用函数colorbar，让我用一个更复杂的命令 imagesc(A)，colorbar，colormap gray。这实际上是在同一时间运行三个命令：运行imagesc，然后运行，colorbar然后运行colormap gray。 它生成了一个颜色图像，一个灰度分布图，并在右边也加入一个颜色条。所以这个颜色条显示不同深浅的颜色所对应的值。 你可以看到在不同的方格，它对应于一个不同的灰度。 输入imagesc(magic(15))，colorbar，colormap gray 这将会是一幅15*15的magic方阵值的图。 最后，总结一下这段视频。你看到我所做的是使用逗号连接函数调用。如果我键入a=1,b=2,c=3然后按Enter键，其实这是将这三个命令同时执行，或者是将三个命令一个接一个执行，它将输出所有这三个结果。 这很像a=1; b=2;c=3;如果我用分号来代替逗号，则没有输出出任何东西。 这里我们称之为逗号连接的命令或函数调用。 用逗号连接是另一种Octave中更便捷的方式，将多条命令例如imagesc colorbar colormap，将这多条命令写在同一行中。 现在你知道如何绘制Octave中不同的图像，在下面的视频中，我将告诉你怎样在Octave中，写控制语句，比如ifwhile for语句，并且定义和使用函数。 5.5 控制语句：for，while，if语句在这段视频中，我想告诉你怎样为你的 Octave 程序写控制语句。诸如：”for” “while” “if” 这些语句，并且如何定义和使用方程。 我先告诉你如何使用 “for” 循环。首先，我要将 v 值设为一个10行1列的零向量。 接着我要写一个 “for” 循环，让 i 等于 1 到 10，写出来就是 i = 1:10。我要设 v(i)的值等于 2 的 i 次方，循环最后写上“end”。向量 v 的值就是这样一个集合 2的一次方、2的二次方，依此类推。这就是我的 i 等于 1 到 10的语句结构，让 i 遍历 1 到 10的值。 另外，你还可以通过设置你的 indices (索引) 等于 1一直到10，来做到这一点。这时indices 就是一个从1到10的序列。 你也可以写 i = indices，这实际上和我直接把 i 写到 1 到 10 是一样。你可以写 disp(i)，也能得到一样的结果。所以 这就是一个 “for” 循环。 如果你对 “break” 和 “continue” 语句比较熟悉，Octave里也有 “break” 和 “continue”语句，你也可以在 Octave环境里使用那些循环语句。但是首先让我告诉你一个 while 循环是如何工作的： 这是什么意思呢：我让 i 取值从 1 开始，然后我要让 v(i) 等于 100，再让 i 递增 1，直到 i 大于 5停止。 现在来看一下结果，我现在已经取出了向量的前五个元素，把他们用100覆盖掉，这就是一个while循环的句法结构。现在我们来分析另外一个例子： 这里我将向你展示如何使用break语句。比方说 v(i) = 999，然后让 i = i+1，当 i 等于6的时候 break (停止循环)，结束 (end)。 当然这也是我们第一次使用一个 if 语句，所以我希望你们可以理解这个逻辑，让 i 等于1 然后开始下面的增量循环，while语句重复设置 v(i) 等于999，不断让i增加，然后当 i 达到6，做一个中止循环的命令，尽管有while循环，语句也就此中止。所以最后的结果是取出向量 v 的前5个元素，并且把它们设置为999。 所以，这就是if 语句和 while 语句的句法结构。并且要注意要有end，上面的例子里第一个 end 结束的是 if语句，第二个 end 结束的是 while 语句。 现在让我告诉你使用 if-else 语句： 最后，提醒一件事：如果你需要退出 Octave，你可以键入exit命令然后回车就会退出 Octave，或者命令quit也可以。 function最后，让我们来说说函数 (functions)，如何定义和调用函数。 我在桌面上存了一个预先定义的文件名为 “squarethisnumber.m”，这就是在 Octave 环境下定义的函数。 让我们打开这个文件。请注意，我使用的是微软的写字板程序来打开这个文件，我只是想建议你，如果你也使用微软的Windows系统，那么可以使用写字板程序，而不是记事本来打开这些文件。如果你有别的什么文本编辑器也可以，记事本有时会把代码的间距弄得很乱。如果你只有记事本程序，那也能用。我建议你用写字板或者其他可以编辑函数的文本编辑器。 现在我们来说如何在 Octave 里定义函数： 这个文件只有三行： 第一行写着 function y = squareThisNumber(x)，这就告诉 Octave，我想返回一个 y值，我想返回一个值，并且返回的这个值将被存放于变量 y 里。另外，它告诉了Octave这个函数有一个参数，就是参数 x，还有定义的函数体，也就是 y 等于 x 的平方。 还有一种更高级的功能，这只是对那些知道“search path (搜索路径)”这个术语的人使用的。所以如果你想要修改Octave的搜索路径，你可以把下面这部分作为一个进阶知识，或者选学材料，仅适用于那些熟悉编程语言中搜索路径概念的同学。 你可以使用addpath 命令添加路径，添加路径“C:\Users\ang\desktop”将该目录添加到Octave的搜索路径，这样即使你跑到其他路径底下，Octave依然知道会在 Users\ang\desktop目录下寻找函数。这样，即使我现在在不同的目录下，它仍然知道在哪里可以找到“SquareThisNumber” 这个函数。 但是，如果你不熟悉搜索路径的概念，不用担心，只要确保在执行函数之前，先用 cd命令设置到你函数所在的目录下，实际上也是一样的效果。 Octave还有一个其他许多编程语言都没有的概念，那就是它可以允许你定义一个函数，使得返回值是多个值或多个参数。这里就是一个例子，定义一个函数叫： “SquareAndCubeThisNumber(x)” (x的平方以及x的立方) 这说的就是函数返回值是两个： y1 和 y2 接下来就是y1是被平方后的结果，y2是被立方后的结果，这就是说，函数会真的返回2个值。 有些同学可能会根据你使用的编程语言，比如你们可能熟悉的C或C++，通常情况下，认为作为函数返回值只能是一个值，但Octave 的语法结构就不一样，可以返回多个值。如果我键入 [a,b] = SquareAndCubeThisNumber(5)，然后，a 就等于25，b 就等于5的立方125。所以说如果你需要定义一个函数并且返回多个值，这一点常常会带来很多方便。 最后，我来给大家演示一下一个更复杂一点的函数的例子。 比方说，我有一个数据集，像这样，数据点为[1,1], [2,2],[3,3]，我想做的事是定义一个 Octave 函数来计算代价函数 $J(θ)$，就是计算不同 $θ$ 值所对应的代价函数值 $J$。 首先让我们把数据放到 Octave 里，我把我的矩阵设置为X = [1 1; 1 2; 1 3]; 请仔细看一下这个函数的定义，确保你明白了定义中的每一步。 现在当我在 Octave 里运行时，我键入 $J = costFunctionJJ (X, y, theta)$，它就计算出 $j$ 等于0，这是因为如果我的数据集x 为 [1;2;3]， y 也为 [1;2;3] 然后设置 $θ_0$ 等于0，$θ_1$ 等于1，这给了我恰好45度的斜线，这条线是可以完美拟合我的数据集的。 而相反地，如果我设置theta 等于[0;0]，那么这个假设就是0是所有的预测值，和刚才一样，设置 $θ_0$ = 0，$θ_1$ 也等于0，然后我计算的代价函数，结果是2.333。实际上，他就等于1的平方，也就是第一个样本的平方误差，加上2的平方，加上3的平方，然后除以2m，也就是训练样本数的两倍，这就是2.33。 因此这也反过来验证了我们这里的函数，计算出了正确的代价函数。这些就是我们用简单的训练样本尝试的几次试验，这也可以作为我们对定义的代价函数J进行了完整性检查。确实是可以计算出正确的代价函数的。至少基于这里的 X和 y是成立的。也就是我们这几个简单的训练集，至少是成立的。 现在你知道如何在 Octave 环境下写出正确的控制语句，比如 for 循环、while 循环和 if语句，以及如何定义和使用函数。在接下来的Octave 教程视频里，我会讲解一下向量化，这是一种可以使你的 Octave程序运行非常快的思想。 5.6 向量化在这段视频中，我将介绍有关向量化的内容，无论你是用Octave，还是别的语言，比如MATLAB或者你正在用Python、NumPy 或 Java C C++，所有这些语言都具有各种线性代数库，这些库文件都是内置的，容易阅读和获取，他们通常写得很好，已经经过高度优化，通常是数值计算方面的博士或者专业人士开发的。 而当你实现机器学习算法时，如果你能好好利用这些线性代数库，或者数值线性代数库，并联合调用它们，而不是自己去做那些函数库可以做的事情。如果是这样的话，那么通常你会发现：首先，这样更有效，也就是说运行速度更快，并且更好地利用你的计算机里可能有的一些并行硬件系统等等；其次，这也意味着你可以用更少的代码来实现你需要的功能。因此，实现的方式更简单，代码出现问题的有可能性也就越小。 举个具体的例子：与其自己写代码做矩阵乘法。如果你只在Octave中输入a乘以b就是一个非常有效的两个矩阵相乘的程序。有很多例子可以说明，如果你用合适的向量化方法来实现，你就会有一个简单得多，也有效得多的代码。 让我们来看一些例子：这是一个常见的线性回归假设函数： 如果你想要计算hθ(x)，注意到右边是求和，那么你可以自己计算 j = 0 到 j = n 的和。但换另一种方式来想想，把 hθ(x) 看作 $θ^Tx$ ，那么你就可以写成两个向量的内积，其中 $θ$ 就是$θ_0, θ_1, θ_2$，如果你有两个特征量，如果 n = 2，并且如果你把 x 看作 $x_0, x_1, x_2$，这两种思考角度，会给你两种不同的实现方式。 比如说，这是未向量化的代码实现方式： 计算 $h_{θ(x)}$ 是未向量化的，我们可能首先要初始化变量 prediction 的值为0.0，而这个变量prediction 的最终结果就是hθ(x)hθ(x)，然后我要用一个 for 循环，j 取值 0 到n+1，变量prediction 每次就通过自身加上 theta(j) 乘以 x(j)更新值，这个就是算法的代码实现。 顺便我要提醒一下，这里的向量我用的下标是0，所以我有θ0、θ1、θ2，但因为MATLAB的下标从1开始，在 MATLAB 中θ0θ0，我们可能会用 theta(1) 来表示，这第二个元素最后就会变成，theta(2) 而第三个元素，最终可能就用theta(3)表示，因为MATLAB中的下标从1开始，这就是为什么这里我的 for 循环，j 取值从 1 直到n+1，而不是从 0 到 n。这是一个未向量化的代码实现方式，我们用一个 for 循环对 n 个元素进行加和。 作为比较，接下来是向量化的代码实现： 你把x和θ看做向量，而你只需要令变量prediction等于theta转置乘以x，你就可以这样计算。与其写所有这些for循环的代码，你只需要一行代码，这行代码就是利用 Octave 的高度优化的数值，线性代数算法来计算两个向量θ以及x的内积，这样向量化的实现更简单，它运行起来也将更加高效。这就是 Octave 所做的而向量化的方法，在其他编程语言中同样可以实现。 让我们来看一个C++ 的例子： 与此相反，使用较好的C++数值线性代数库，你可以写出像右边这样的代码，因此取决于你的数值线性代数库的内容。你只需要在C++中将两个向量相乘，根据你所使用的数值和线性代数库的使用细节的不同，你最终使用的代码表达方式可能会有些许不同，但是通过一个库来做内积，你可以得到一段更简单、更有效的代码。 现在，让我们来看一个更为复杂的例子，这是线性回归算法梯度下降的更新规则： 我们用这条规则对 j 等于 0、1、2等等的所有值，更新对象θj，我只是用θ0、θ1、θ2来写方程，假设我们有两个特征量，所以n等于2，这些都是我们需要对θ0、θ1、θ2进行更新，这些都应该是同步更新，我们用一个向量化的代码实现，这里是和之前相同的三个方程，只不过写得小一点而已。 你可以想象实现这三个方程的方式之一，就是用一个 for 循环，就是让 j等于0、等于1、等于2，来更新θj。但让我们用向量化的方式来实现，看看我们是否能够有一个更简单的方法。基本上用三行代码或者一个for 循环，一次实现这三个方程。让我们来看看怎样能用这三步，并将它们压缩成一行向量化的代码来实现。做法如下： 我打算把θ看做一个向量，然后我用θ-α 乘以某个别的向量δ 来更新θ。 这里的 δ 等于 让我解释一下是怎么回事：我要把θ看作一个向量，有一个 n+1 维向量，α 是一个实数，δ在这里是一个向量。 所以这个减法运算是一个向量减法，因为 α 乘以 δ是一个向量，所以θ就是θ - αδ得到的向量。 那么什么是向量 δ 呢 ? X(i)是一个向量 你就会得到这些不同的式子，然后作加和。 实际上，在以前的一个小测验，如果你要解这个方程，我们说过为了向量化这段代码，我们会令u = 2v +5w因此，我们说向量u等于2 乘以向量v 加上5乘以向量w。用这个例子说明，如何对不同的向量进行相加，这里的求和是同样的道理。 这就是为什么我们能够向量化地实现线性回归。 所以，我希望步骤是有逻辑的。请务必看视频，并且保证你确实能理解它。如果你实在不能理解它们数学上等价的原因，你就直接实现这个算法，也是能得到正确答案的。所以即使你没有完全理解为何是等价的，如果只是实现这种算法，你仍然能实现线性回归算法。如果你能弄清楚为什么这两个步骤是等价的，那我希望你可以对向量化有一个更好的理解，如果你在实现线性回归的时候，使用一个或两个以上的特征量。 有时我们使用几十或几百个特征量来计算线性归回，当你使用向量化地实现线性回归，通常运行速度就会比你以前用你的for循环快的多，也就是自己写代码更新θ0、θ1、θ2。 因此使用向量化实现方式，你应该是能够得到一个高效得多的线性回归算法。而当你向量化我们将在之后的课程里面学到的算法，这会是一个很好的技巧，无论是对于Octave 或者一些其他的语言 如C++、Java 来让你的代码运行得更高效。 5.7 工作和提交的编程练习在这段视频中，我想很快地介绍一下这门课程做作业的流程，以及如何使用作业提交系统。这个提交系统可以即时检验你的机器学习程序答案是否正确。 在’ml-class-ex1’目录中，我们提供了大量的文件，其中有一些需要由你自己来编辑，因此第一个文件应该符合编程练习中pdf文件的要求，其中一个我们要求你编写的文件是warmUpExercise.m这个文件，这个文件只是为了确保你熟悉提交系统。 你需要做的就是提交一个5×5的矩阵，就是A = eye(5)这将修改该函数以产生5×5的单位矩阵，现在warmUpExercise()这个方程就实现了返回5x5的单位矩阵，将它保存一下，所以我已经完成了作业的第一部分。 现在回到我的 Octave 窗口，现在来到我的目录C:\Users\ang\Desktop\ml-class-ex1如果我想确保我已经实现了程序 像这样输入’warmUpExercise()’好了它返回了我们用刚才写的代码创建的一个5x5的单位矩阵 我现在可以按如下步骤提交代码，我要在这里目录下键入submit()。我要提交第一部分 所以我选择输入’1’。这时它问我的电子邮件地址，我们打开课程网站，输入用户名密码。 按下回车键，它连接到服务器，并将其提交，然后它就会立刻告诉你：恭喜您！已成功完成作业1第1部分。这就确认了你已经做对了第一部分练习，如果你提交的答案不正确，那么它会给你一条消息，说明你没有完全答对，您还可以继续使用此提交密码，也可以生成新密码。你的密码是否会显示出来取决于你使用的操作系统。这就是提交作业的方法，你完成家庭作业的时候，我希望你都能答对。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Machine Learning by Andrew NG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02_linear-regression-with-one-variable note2]]></title>
    <url>%2F2018%2F01%2F01%2F02-linear-regression-with-one-variable%2F</url>
    <content type="text"><![CDATA[NoteThis personal note is written after studying the coursera opening course, Machine Learning by Andrew NG . And images, audios of this note all comes from the opening course. Model Representation To establish notation for future use, we’ll use $x^{(i)}$ to denote the “input”variables (living area in this example), also called input features, and $y^{(i)}$ to denote the “output” or target variable that we are trying to predict(price). A pair ( $x^{(i)},y^{(i)}$ ) is called a training example, and the dataset that we’ll be using to learn—a list of m training examples ( $x^{(i)},y^{(i)} ) ;i=1,…,m$ — is called a training set. Note that the superscript “(i)” in the notation is simply an index into the training set, and has nothing to do with exponentiation. We will also use X to denote the space of input values, and Y to denote the space of output values. In this example, X = Y = ℝ. To describe the supervised learning problem slightly more formally, our goal is, given a training set, to learn a function h : X → Y so that h(x) is a “good” predictor for the corresponding value of y. For historical reasons, this function h is called a hypothesis. Seen pictorially, the process is therefore like this: When the target variable that we’re trying to predict is continuous, such as in our housing example, we call the learning problem a regression problem.When y can take on only a small number of discrete values (such as if, given the living area, we wanted to predict if a dwelling is a house or an apartment, say), we call it a classification problem. Cost FunctionWe can measure the accuracy of our hypothesis function by using a cost function . This takes an average difference (actually a fancier version of an average) of all the results of the hypothesis with inputs from x’s and the actual output y’s. $ J(θ_0,θ_1)={1\over2m}\sum\limits_{i=1}^m (\hat{y}_i−y_i)^2=\frac{1}{2m}\sum\limits_{i=1}^m(h_{θ(xi)}−y_i)^2$ To break it apart, it is ${1\over 2}\bar{x}$ where $\bar{x}$ is the mean of the squares of $h_{θ(xi)}−y_i$ , or the difference between the predicted value and the actual value. This function is otherwise called the “Squared error function”, or “Mean squared error”. The mean is halved $({1\over 2})$ as a convenience for the computation of the gradient descent, as the derivative term of the square function will cancel out the $({1\over 2})$ term. The following image summarizes what the cost function does: Cost Function - Intuition I If we try to think of it in visual terms, our training data set is scattered on the x-y plane. We are trying to make a straight line (defined by $h_{θ(x)}$ ) which passes through these scattered data points. Our objective is to get the best possible line. The best possible line will be such so that the average squared vertical distances of the scattered points from the line will be the least. Ideally, the line should pass through all the points of our training data set. In such a case, the value of $J(θ_0,θ_1)$ will be $0$. The following example shows the ideal situation where we have a cost function of $0$. ​When $θ_1=1$, we get a slope of 1 which goes through every single data point in our model. Conversely, when $θ_1=0.5$, we see the vertical distance from our fit to the data points increase. This increases our cost function to $0.58​$. Plotting several other points yields to the following graph: Thus as a goal, we should try to minimize the cost function. In this case, $θ_1=1$ is our global minimum. Cost Function - Intuition II A contour plot is a graph that contains many contour lines. A contour line of a two variable function has a constant value at all points of the same line. An example of such a graph is the one to the right below. Taking any color and going along the ‘circle’, one would expect to get the same value of the cost function. For example, the three green points found on the green line above have the same value for $J(θ_0,θ_1)$ and as a result, they are found along the same line. The circled x displays the value of the cost function for the graph on the left when $θ_0 = 800$ and $θ_1= -0.15$ . Taking another $h(x)$ and plotting its contour plot, one gets the following graphs: When $θ_0 = 360$ and $θ_1 = 0$, the value of $J(θ_0,θ_1)$ in the contour plot gets closer to the center thus reducing the cost function error. Now giving our hypothesis function a slightly positive slope results in a better fit of the data. The graph above minimizes the cost function as much as possible and consequently, the result of $\theta_1$ and $\theta_0$ tend to be around $0.12$ and $250$ respectively. Plotting those values on our graph to the right seems to put our point in the center of the inner most ‘circle’. Gradient DescentSo we have our hypothesis function and we have a way of measuring how well it fits into the data. Now we need to estimate the parameters in the hypothesis function. That’s where gradient descent comes in. Imagine that we graph our hypothesis function based on its fields $θ_0$ and $θ_1$ (actually we are graphing the cost function as a function of the parameter estimates). We are not graphing x and y itself, but the parameter range of our hypothesis function and the cost resulting from selecting a particular set of parameters. We put $θ_0$ on the x axis and $θ_1$ on the y axis, with the cost function on the vertical z axis. The points on our graph will be the result of the cost function using our hypothesis with those specific theta parameters. The graph below depicts such a setup. We will know that we have succeeded when our cost function is at the very bottom of the pits in our graph, i.e. when its value is the minimum. The red arrows show the minimum points in the graph. The way we do this is by taking the derivative (the tangential line to a function) of our cost function. The slope of the tangent is the derivative at that point and it will give us a direction to move towards. We make steps down the cost function in the direction with the steepest descent. The size of each step is determined by the parameter $α$ , which is called the learning rate. For example, the distance between each ‘star’ in the graph above represents a step determined by our parameter $α$ . A smaller $α$ would result in a smaller step and a larger $α$ results in a larger step. The direction in which the step is taken is determined by the partial derivative of $J(θ_0,θ_1)$. Depending on where one starts on the graph, one could end up at different points. The image above shows us two different starting points that end up in two different places. The gradient descent algorithm is:$$\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1)$$repeat until convergence: where $j=0,1$ represents the feature index number. At each iteration $j$ , one should simultaneously update the parameters $θ_1,θ_2,…,θ_n$. Updating a specific parameter prior to calculating another one on the $j^{(th)}$ iteration would yield to a wrong implementation. Gradient Descent IntuitionIn this video we explored the scenario where we used one parameter $θ_1$ and plotted its cost function to implement a gradient descent. Our formula for a single parameter was : Repeat until convergence:$$\theta_1:=\theta_1-\alpha \frac{d}{d\theta_1} J(\theta_1)$$Regardless of the slope’s sign for $\frac{d}{d\theta_1} J(\theta_1)$, eventually converges to its minimum value. The following graph shows that when the slope is negative, the value of $θ_1$ increases and when it is positive, the value of $θ_1$ decreases. On a side note, we should adjust our parameter $α$ to ensure that the gradient descent algorithm converges in a reasonable time. Failure to converge or too much time to obtain the minimum value imply that our step size is wrong. How does gradient descent converge with a fixed step size α?The intuition behind the convergence is that $\frac{d}{d\theta_1} J(\theta_1)$ , approaches 0 as we approach the bottom of our convex function. At the minimum, the derivative will always be 0 and thus we get:$$\theta_1:=\theta_1-\alpha * 0$$ Gradient Descent For Linear Regression​ Note: [At 6:15 “ $h(x) = -900 - 0.1x$ “ should be “ $h(x) = 900 - 0.1x$ “] When specifically applied to the case of linear regression, a new form of the gradient descent equation can be derived. We can substitute our actual cost function and our actual hypothesis function and modify the equation to : $$ \begin{align*} \text{repeat until convergence: } \lbrace & \\ \theta_0 := & \theta_0 - \alpha \frac{1}{m} \sum\limits_{i=1}^{m}(h_\theta(x_{i}) - y_{i}) \\ \theta_1 := & \theta_1 - \alpha \frac{1}{m} \sum\limits_{i=1}^{m}\left((h_\theta(x_{i}) - y_{i}) x_{i}\right) \\ \rbrace& \end{align*} $$ where m is the size of the training set, $θ_0$ a constant that will be changing simultaneously with $θ_1$ and $x_i,y_i$ are values of the given training set (data). Note that we have separated out the two cases for $θ_j$ into separate equations for $θ_0$ and $θ_1$ ; and that for $θ_1$ we are multiplying $x_i$ at the end due to the derivative. The following is a derivation of $\frac{∂}{∂θ_j}J(θ)$ for a single example : The point of all this is that if we start with a guess for our hypothesis and then repeatedly apply these gradient descent equations, our hypothesis will become more and more accurate. So, this is simply gradient descent on the original cost function J. This method looks at every example in the entire training set on every step, and is called batch gradient descent . Note that, while gradient descent can be susceptible to local minima in general, the optimization problem we have posed here for linear regression has only one global, and no other local, optima; thus gradient descent always converges (assuming the learning rate α is not too large) to the global minimum. Indeed, J is a convex quadratic function.Here is an example of gradient descent as it is run to minimize a quadratic function. The ellipses shown above are the contours of a quadratic function. Also shown is the trajectory taken by gradient descent, which was initialized at $(48,30)$. The $x$’s in the figure (joined by straight lines) mark the successive values of $θ$ that gradient descent went through as it converged to its minimum.]]></content>
      <categories>
        <category>english</category>
      </categories>
      <tags>
        <tag>Machine Learning by Andrew NG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录 - 伯努利和泊松随机变量的均值方差]]></title>
    <url>%2F2017%2F08%2F28%2Fmean_and_variance_of_Bernoulli_and_Possion_random%2F</url>
    <content type="text"><![CDATA[Example 2.5. Mean and Variance of the Bernoulli.伯努利随机变量的均值和方差Consider the experiment of tossing a coin, which comes up a head with probability $p$ and a tail with probability $1 - p$. and the Bernoulli random variable $X$ with $PMF$ :$$p_X(k)=\cases{p, &amp; if $k=1$\\1-p, &amp; if $k=0$}$$The mean. second moment. and variance of $X$ are given by the following calculations:$$E[X]=1\cdot p + 0 \cdot (1-p) = p ,\\E[X^2]=1^2\cdot p + 0 \cdot (1-p) = p, \\var(x)=E[X^2]-(E[X])^2=p-p^2=p(1-p)$$ Example 2.7. The Mean of the Poisson. 泊松随机变量的均值方差The mean of the Poisson $PMF $ :$$p_X(k)=e^{-\lambda}\frac{\lambda^k}{k!}, k=0,1,2,\ldots$$can be calculated is follows:$$\begin{eqnarray}E[X] &amp;=&amp; \sum\limits^{\infty}_{k=0}ke^{-\lambda}\frac{\lambda^k}{k!}\\&amp;=&amp; \sum\limits^{\infty}_{k=1}ke^{-\lambda}\frac{\lambda^k}{k!} \quad (\text{k=0的项等于0})\\&amp;=&amp; \lambda\sum\limits_{k=1}^{\infty}e^{-\lambda}\frac{\lambda^{k-1}}{k-1!}\\&amp;=&amp; \lambda\sum\limits_{m=0}^{\infty}e^{-\lambda}\frac{m^{k-1}}{m!} \quad (\text{让m=k-1})\\&amp;=&amp; \lambda\end{eqnarray}$$The last equality is obtained by noting that is the normalization property for the Poisson $PMF$. Example 2.20. Variance of the Binomial and the Poisson. 二项随机变量和泊松随机变量的方差We consider $n$ independent coin tosses, with each toss having probability $p$ of coming up a head. For each $i$, we let $X_i$ be the Bernoulli random variable which is equal to $1$ if the $i$th toss comes up a head, and is 0 otherwise. Then, $X = X_l + X_2 + . . . + X_n$ is a binomial random variable. Its mean is $E[X] = np$. as derived in Example 2. 10. By the independence of the coin tosses. the random variables $X_1 , . . . . X_n$ are independent, and$$var(X)=\sum\limits_{i=1}^{n}var(x_i)=np(1-p)$$As we discussed in Section 2.2. a Poisson random variable $Y$ with parameter $\lambda$ can be viewed as the “limit” of the binomial as $n\rightarrow \infty, p\rightarrow 0$. while $np = \lambda$. Thus, taking the limit of the mean and the variance of the binomial. we informally obtain the mean and variance of the Poisson: $E[Y] = var(Y) = \lambda $ . We have indeed verified the formula $E[Y] = \lambda$ in Example 2.7. To verify the formula $var(Y) = \lambda$, we write$$\begin{eqnarray}E[Y^2] &amp;=&amp; \sum\limits_{k=1}^{\infty}k^2e^{-\lambda}\frac{\lambda^k}{k!} \\&amp;=&amp; \lambda\sum\limits_{k=1}^{\infty}k\frac{e^{-\lambda}\lambda^{k-1}}{(k-1)!} \\&amp;=&amp; \lambda\sum\limits_{m=0}^{\infty}(m+1)\frac{e^{-\lambda}\lambda^{m}}{m!}, m = k-1 \\&amp;=&amp; \lambda[\sum\limits_{m=0}^{\infty}m\frac{e^{-\lambda}\lambda^{m}}{m!}+\sum\limits_{m=0}^{\infty}\frac{e^{-\lambda}\lambda^{m}}{m!}], \\&amp;=&amp; \lambda(E[Y]+1) , \\&amp;=&amp; \lambda(\lambda+1) \\\end{eqnarray}$$ from which$$var(Y)=E[Y^2]-(E[Y])^2=\lambda(\lambda+1)-\lambda^2=\lambda$$]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-Bayes' rule贝叶斯定律]]></title>
    <url>%2F2017%2F08%2F28%2FBayes'_rule%2F</url>
    <content type="text"><![CDATA[说明：全文摘自Introduction to probability, 2nd Edition 本文讨论条件概率定律的应用，首先引入一个计算事件概率的定理。 The law of total probability设 $A_1, A_2, … , A_n$ 是一组互不相容的事件，它形成样本空间的一个分割（每个试验结果必定使得其中一个事件发生！）。又假定对每个 $i, P(A_i) &gt; 0$ 。则对任何事件 $B$ ，下列公式成立$$\begin{eqnarray}P(B) &amp;=&amp; P(A_1\cap B )+\cdots+P(A_n\cap B) \\&amp;=&amp; P(A_1)P(B|A_1)+\cdots+P(B)P(B|A_n)\end{eqnarray}$$这是总概率定律（或翻译为：全概率定律），下面有图示和证明。直观上，将样本空间分割成若干事件 $A_i$ 的并（ $A_1, \cdots, A_n$ 形成样本空间的一个分割）然后任意事件 $B$ 的概率等于事件 $B$ 在 $A_i$ 发生的情况下的条件概率的加权平均，而权重刚好等于这些事件 $A_i$ 的无条件概率。这条定理的一个主要应用是计算事件 $B$ 的概率。直接计算事件 $B$ 的概率有点难度，但是若条件概率 $P(B|A_i)$ 是已知的或是很容易推导计算时，总概率定律定理就成为了计算 $P(B)$ 的有力工具。应用这条定理的关键是找到合适的分割 $A_1,\cdots, A_n$ ，而合适的分割又与问题的实际背景有关。 由于事件 $A_1, A_2, \cdots, A_n$ 形成一个样本空间的一个分割，事件 $B$ 可以分解成不想交的 $n$ 个事件的并，即： $$B=(A_!\cap B)\cup\cdots\cup(A_n\cap B) \quad (1)$$利用可加定理，得到： $$P(B) = P(A_1 \cap B)+\cdots+P(A_n \cap B) \quad (2)$$利用条件概率的定义，得到： $$P(A_i\cap B) = P(A_i)P(B|A_i) \quad (3)$$将 $(3)$ 式子代入 $(2)$ 式子中得到： $$P(B)=P(A_1)P(B|A_1)+\cdots+P(A_n)P(B|A_n)$$也可以用等价的序列树形图来说明总概率定律（如上右边图）：叶子 $A_i \cap B$ 的概率等于由叶子到根部上的概率的乘积 $P(A_i)P(B|A_i)$ 。而事件 $B$ 由图上显示的3个叶子组成，将它们的概率相加就得到 $P(B)$ 。 总概率定律的例子例 1.13 你参加一个棋类比赛，其中 $50\%$ 是一类棋手，你赢他们的概率为 $0.3\%$ ； $25\%$ 是二类棋手，你赢他们的概率是 $0.4$ ；剩下的是三类棋手，你赢得他们的概率是 $0.5$ 。从他们中间随机地选一位棋手与你比赛，你胜算的概率有多大？ 记 $A_i$ 表示与你下棋的棋手的类别。依题意 $$P(A_1)=0.5,\quad P(A_2) =0.25, \quad P(A_3) = 0.25$$记 $B$ 为你赢得比赛的事件，那么得到： $$P(B|A_1)=0.3,\quad P(B|A_2)=0.4,\quad P(B|A_3)=0.5$$那么利用总概率定律，你在不比赛中胜出的概率为：$$\begin{eqnarray}P(B) &amp;=&amp; P(A_1)P(B|A_1)+P(A_2)P(B|A_2)+P(A_3)P(B|A_3) \\&amp;=&amp; 0.5 \cdot 0.3+ 0.25 \cdot 0.4 + 0.25 \cdot 0.5 \\&amp;=&amp; 0.375\end{eqnarray}$$ Inference and Bayes’ Rule 推断与贝叶斯定律总概率定律经常与著名的贝叶斯定律联系起来，贝叶斯定律将形如 $P(A|B)$ 的条件概率与形如 $P(B|A)$ 的条件概率联系起来。 Bayes’ Rule贝叶斯定律设 $A_1,A_2,\ldots,A_n$ 是一组互斥的事件，它形成样本空间的一个分割（每个试验结果必定使得其中一个事件发生）。又假定对每一个 $i, P(A_i)&gt;0$ ，则对于任何事件 $B$ ，只要它满足 $P(B)&gt;0$ ，下列公式成立：$$\begin{eqnarray}P(A_i|B) &amp;=&amp; \frac{P(A_i)P(B|A_i)}{P(B)}\\&amp;=&amp;\frac{P(A_i)P(B|A_i)}{P(A_1)P(B|A_1)+\cdots+P(A_n)P(B|A_n)}\end{eqnarray}$$为证明贝叶斯定律，只需注意到 $P(A_i)P(B|A_i)$ 与 $P(B)P(A_i|B)$ 是相等的，它们都等于 $P(A_i \cap B)$ ，这样得到了第一个等式，至于第二个等式，只需对 $P(B)$ 利用总概率定律即可。 贝叶斯定律还可以用来进行因果推理。有许多”原因“可以造成某一”结果“。现在设我们观察到某一结果，希望推断造成这个结果出现的”原因“。现在设事件 $A_1,\ldots, A_n​$ 是原因，而 $B​$ 代表由原因引起的结果。 $P(B|A_i)​$ 表示在因果模型中由”原因“ $A_i​$ 造成结果 $B​$ 的概率（见下图）。当观察到结果 $B​$ 的时候，希望反推结果 $B​$ 是由原因 $A_i​$ 造成的概率 $P(A_i|B)​$ 。 $P(A_i|B)​$ 为由于代表新近得到的信息 $B​$ 之后 $A_i​$ 出现的概率，称之为 posterior probability 后验概率，而原来的 $P(A_i)​$ 就称为 prior probability 先验概率。 贝叶斯定律进行推断的例子医学在某病人X光片中发现一个阴影，（用 $B$ 表示，代表”结果“）。希望对造成这种结果的3个原因进行分析。这3个原因互斥，并且造成这个结果的原因一定是三者之一：原因1（事件 $A_1$）是恶性肿瘤，原因2（事件 $A_2$）是良性肿瘤，原因3（事件 $A_3$）是肿瘤外的其他原因。假定已经知道 $P(A_i)$ 和 $P(B|A_i), i=1,2,3$ 。现在已经发现了阴影（事件 $B$ 发生），利用贝叶斯公式，这些原因的条件概率为： $$P(A_i|B)=\frac{P(A_i)P(B|A_i)}{P(A_1)P(B|A_1)+P(A_2)P(B|A_2)+P(A_3)P(B|A_3)},i=1,2,3$$在右图给出序列树形图，可用序列树形图给出条件概率计算的另外一种等价的解释。图中第一个深灰的叶子表示恶性肿瘤并出现阴影，其概率为 $P(A_1\cap B)$ ，且所有深灰的叶子表示片子中出现阴影，其概率为 $P(B)$ ，而由恶性肿瘤造成阴影的条件概率 $P(A_1|B)$ 是两个概率相除的结果。 比赛继续使用例 1.13 你参加一个棋类比赛，其中 $50\%$ 是一类棋手，你赢他们的概率为 $0.3\%$ ； $25\%$ 是二类棋手，你赢他们的概率是 $0.4$ ；剩下的是三类棋手，你赢得他们的概率是 $0.5$ 。现在假定你已经得胜，问你的对手为一类棋手的概率有多大？用 $A_i$ 表示你与 $i$ 类棋手相遇的事件。由例中给出的条件知道：$$P(A_1)=0.5,\quad P(A_2)=0.25,\quad P(A_3)=0.25$$记 $B$ 表示你赢的比赛的事件，你胜出的概率为：$$P(B|A_1)=0.3,\quad P(B|A_2)=0.4,\quad P(B|A_3)=0.5$$利用贝叶斯公式得：$$\begin{eqnarray}P(A_1|B) &amp;=&amp; \frac{P(A_1)P(B|A_1)}{P(A_1)P(B|A_1)+P(A_2)P(B|A_2)+P(A_3)P(B|A_3)} \\&amp;=&amp; \frac{0.5\cdot 0.3}{0.5\cdot 0.3+0.25\cdot 0.4+0.25\cdot 0.5} \\&amp;=&amp; 0.4\end{eqnarray}$$ 假阳性之谜 设对于某种少见的疾病的检出率为 $0.95$ ；如果一个被检查的病人有某种疾病，其检查结果为阳性的概率为 $0.95$ ；如果该人没有这种疾病，其检查结果为阴性的概率是 $0.95$ 。现在假定某一人群中患有这种病的概率为 $0.001$ ，并从这个总体中随机地抽取一个人进行检测，检查结果为阳性。现在问这个人患有这种病的概率有多大？ 设 $A$ 为这个人有这种疾病， $B$ 为经检验这个人为阳性。利用贝叶斯公式：$$\begin{eqnarray}P(A|B) &amp;=&amp; \frac{P(A)P(B|A)}{P(A)P(B|A)+P(A^c)P(B|A^c)} \\&amp;=&amp; \frac{0.001\cdot 0.95}{0.001\cdot 0.95 + 0.999\cdot 0.05} \\&amp;=&amp; 0.0187\end{eqnarray}$$尽管检验方法非常精确，一个经检测为阳性的人仍然不大可能真正患有这种疾病（患有该疾病的概率小于 $2\%$ ）。根据《经济学人》杂志 $1999$ 年 $2$ 月 $20$ 日的报道，在一家著名的大医院中 $80\%$ 的受访者不知道这类问题的正确答案，而大部分人回答，这个经检测为阳性的人患病概率为 $0.95$ ! 连续随机变量的贝叶斯定律在许多情况下，我们会遇到一个没有观察到的对象。用随机变量 $X$ 代表这种未观察到的量，设其概率密度函数是 $ f_X(x)$ 。我们能够观察到的量是经过噪声干扰的量 $Y$ ，$Y$ 的分布函数是条件分布函数，其条件概率密度函数为： $f_{X|Y}(y|x)$ 。当 $Y$ 的值被观察到以后，它包含 $X$ 的多少信息呢？这类问题与离散随机变量的推断问题类似。现在唯一的不同之处在于处理的是连续随机变量。 上图是推断问题的框图，有一个未观察到的变量 $X$ ，其概率密度函数 $f_X$ 是已知的，同时得到一个观察到的随机变量 $Y$ ，其条件概率密度函数为 $f_{Y|X}(y|x)$ 。给定 $Y$ 的观察值 $y$ ，推断问题变成条件概率密度函数 $f_{X|Y}(x|y)$ 的计算问题。 注意到：当观察到事件 $Y=y$ 以后，所有的信息都包含在条件概率密度函数 $f_{X|Y}(x|y)$ 中，现在只需计算这个条件概率密度函数。利用公式 $f_Xf_{Y|X}=f_{X,Y}=f_Yf_{X|Y}$ 可以得到： $$f_{X|Y}(x|y)=\frac{f_X(x)f_{Y|X}(y|x)}{f_Y(y)}$$这个即所求的公式，与之等价的公式： $$f_{X|Y}(x|y)=\frac{f_X(x)f_{Y|X}(y|x)}{\int_{-\infty}^{+\infty}f_X(t)f_{Y|X}(y|t)dt}$$ 例子通用照明公司生产一种灯泡，已知其使用寿命 $Y$ 为指数随机变量，其概率密度函数为 $\lambda e^{-\lambda y}, y&gt;0$ ，按过往经验，在任意给定的一天参数 $\lambda$ 实际上是一个随机变量，其概率密度函数为区间 $[1, \frac{3}{2}]$ 上的均匀分布。现在随机地取已知灯泡进行试验，得到灯泡的寿命数据。得到数据以后，对于 $\lambda$ 的分布有什么新的认识？ 将 $\lambda$ 看成一个随机变量 $\Lambda$ ，作为对 $\lambda$ 的初始认识，那么根据题意 $\Lambda$ 的概率密度函数是： $$f_{\Lambda(\lambda)}=2, 1\le \lambda \le \frac{3}{2}$$当得到数据 $y$ 以后，关于 $\Lambda$ 的信息包含于条件概率密度函数 $f_{\Lambda, y}(\lambda|y)$ 中，利用连续贝叶斯公式得到： $$f_{ \Lambda|y}(\lambda|y)=\frac{f_\Lambda(\lambda)f_{Y|\Lambda}(y|\lambda)}{\int_{+\infty}^{-\infty}f_{\Lambda}(t)f_{Y|\Lambda}(y|t)dt}=\frac{2\lambda e^{-\lambda y}}{\int_{1}^{\frac{3}{2}}2te^{-ty}dt}，1\le \lambda \le \frac{3}{2}$$ 关于连续随机变量的推断在许多实际问题中，未观察到的随机变量可能是连续的随机变量。例如，在通信问题中传输的信号是一个二进制的信号，经过传输以后，混入的噪声是正态随机变量，这样，观测到的随机变量就是连续的随机变量；或者在医疗诊断中，观察到的量也是连续的测量值，例如：体温或血液样本中的指标。这种情况下需要将贝叶斯公式作适当改变。 现在研究一种特殊情况，未观察到的是一个事件$A$ 。不知道 $A$ 是否发生了。事件 $A$ 的概率 $P(A)$ 是已知的。设 $Y$ 是一个连续的随机变量，并且假定条件概率密度函数 $f_{Y|A}(y)$ 和 $f_{Y|A^c}(y)$ 是已知的。令人兴趣的是事件 $A$ 的条件概率密度函数 $P(A|Y=y)$ 。这个量代表得到的观察值 $y$ 以后关于事件 $A$ 的信息。 由于事件 ${Y=y}$ 是一个零概率事件，转而去考虑事件 ${y \le Y \le y+\delta}$ ，其中 $\delta$ 是一个很小的正数，然后令 $\delta$ 趋于0 。利用贝叶斯公式，令 $f_{Y}(y)&gt;0$ ，我们得到：$$\begin{eqnarray}P(A|Y=y) &amp;\approx&amp; P(A|y\le Y \le y+\delta) \\&amp;=&amp; \frac{P(A)P(y\le Y \le y+\delta|A)}{P(y\le Y \le y+\delta)} \\&amp;\approx&amp;\frac{P(A)f_{Y|A}(y)\delta}{f_Y(y)\delta} \\&amp;=&amp; \frac{P(A)f_{Y|A}(y)}{f_Y(y)}\end{eqnarray}$$利用总概率定律，可将上式的分母写成：$$f_{Y}(y)=P(A)f_{Y|A}(y)+P(A^c)f_{Y|A^c}(y)$$这样得到：$$P(A|Y=y)=\frac{P(A)f_{Y|A}(y)}{P(A)f_{Y|A}(y)+P(A^c)f_{Y|A^c}(y)}$$现在令事件 $A$ 具有形式 $\{N=n\}$ ，其中 $N$ 是一个离散的随机变量，代表未观察到的随机变量。记 $p_N$ 为 $N$ 的分布函数。令 $Y$ 为连续随机变量，对任意 $N$ 的取值 $n$，$Y$ 具有条件概率密度函数 $f_{Y|N}(y|n)$ 。 这样上面的公式变成 ：$$P(N=n|Y=y)=\frac{p_N(n)f_{Y|N}(y|n)}{f_Y(y)}$$利用下面的总概率定律：$$f_Y(y)=\sum\limits_{i}p_N(i)f_{Y|N}(y|i)$$得到：$$P(N=n|Y=y)=\frac{p_N(n)f_{Y|N}(y|n)}{\sum\limits_{i}p_N(i)f_{Y|N}(y|i)}$$ 例子-信号检测设 $S$ 是一个只取2个值的信号（signal）。记 $P(S=1)=p$ 和 $P(S=-1)=1-p$ 。在接收端，得到的信号为 $Y=N+S$ ，其中 $N$ 是一个正态分布的噪声（noise），期望为0，方差为1，并且与 $S$ 相互独立。当观察到的信号为 $y$ 的时候，$S=1$ 的概率是多少？ 对于给定的 $S=s=1, Y$ 是一个正态随机变量，期望为 $s=1$ ，方差为 $1$ 。应用刚才得到的公式：$$P(S=1|Y=y)=\frac{p_S(1)f_{Y|S}(y|1)}{f_Y(y)}=\frac{\frac{p}{\sqrt{2\pi}}e^{-\frac{(y-1)^2}{2}}}{\frac{p}{\sqrt{2\pi}}e^{-\frac{(y-1)^2}{2}}+\frac{1-p}{\sqrt{2\pi}}e^{-\frac{(y+1)^2}{2}}}$$将上式化简得：$$P(S=1|Y=y)=\frac{pe^y}{pe^y+(1-p)e^{-y}}$$注意：当 $y\rightarrow -\infty, P(S=1|Y=y)\rightarrow 0$ ，当 $y\rightarrow \infty, P(S=1|Y=y)\rightarrow 1$ 。 $y$ 在实数轴上变化时， $P(S=1|Y=y)$ 是 $y$ 的严格上升函数，这符合直观的理解。 基于离散观察值的推断在前文连续随机变量的贝叶斯定律中得到的：$$\begin{eqnarray}P(A|Y=y) &amp;\approx&amp; P(A|y\le Y \le y+\delta) \\&amp;=&amp; \frac{P(A)P(y\le Y \le y+\delta|A)}{P(y\le Y \le y+\delta)} \\&amp;\approx&amp;\frac{P(A)f_{Y|A}(y)\delta}{f_Y(y)\delta} \\&amp;=&amp; \frac{P(A)f_{Y|A}(y)}{f_Y(y)}\end{eqnarray}$$反解得到：$$f_{Y|A}(y)=\frac{f_Y(y)P(A|Y=y)}{P(A)}$$根据归一性（$\int_{-\infty}^{+\infty}f_{Y|A}(y)dy=1$），那么得到一个等价的表达式：$$f_{Y|A}(y)=\frac{f_Y(y)P(A|Y=y)}{\int_{-\infty}^{+\infty}f_Y(t)P(A|Y=t)dt}$$这个公式可以用于当事件 $A$ 被观测到时候，对随机变量 $Y$ 进行推断。对于事件 $A$ 是 $\{N=n\}$ 的形式，根据前文：$$P(N=n|Y=y)=\frac{p_N(n)f_{Y|N}(y|n)}{\sum\limits_{i}p_N(i)f_{Y|N}(y|i)}$$得到一个相似的公式对随机变量 $Y$ 进行推断：$$f_{Y|N}(y|n)=\frac{P(N=n|Y=y)\sum\limits_{i}p_N(i)f_{Y|N}(y|i)}{p_N(n)}$$ 总结令 $Y$ 为连续随机变量。 若 $X$ 为连续随机变量，则有：$$f_{X|Y}(x|y)f_Y(y)=f_X(x)f_{Y|X}(y|x)$$和$$f_{X|Y}(x|y)=\frac{f_X(x)f_{Y|X}(y|x)}{f_Y(y)}=\frac{f_X(x)f_{Y|X}(y|x)}{\int_{-\infty}^{+\infty}f_X(t)f_{Y|X}(y|t)dt}$$ 若 $N$ 为离散随机变量，则有：$$f_Y(y)P(N=n|Y=y)=p_N(n)f_{Y|N}(y|n)$$得到贝叶斯定律为：$$P(N=n|Y=y)=\frac{p_N(n)f_{Y|N}(y|n)}{f_Y(y)}=\frac{p_N(n)f_{Y|N}(y|n)}{\sum\limits_{i}p_N(i)f_{Y|N}(y|i)}$$和$$f_{Y|N}(y|n)=\frac{f_Y(y)P(N=n|Y=y)}{p_N(n)}=\frac{f_Y(y)P(N=n|Y=y)}{\int_{-\infty}^{+\infty}f_Y(t)P(N=n|Y=t)dt}$$ 对于事件 $A$ ，关于 $P(A|Y=y)$ 和 $f_{Y|A}(y)$ 具有类似的贝叶斯定律。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-正态随机变量]]></title>
    <url>%2F2017%2F08%2F27%2Fnormal_random_variables%2F</url>
    <content type="text"><![CDATA[说明：全文摘自 Introduction to probability, 2nd Edition 3.3 normal random variables 正态随机变量如果一个连续的随机变量 $X$ 的概率密度具有下列形式， 那么这个随机变量称为正态(normal)的或高斯(Gaussian)的。$$f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^2}{2\sigma^2}}$$其中 $u$ 和 $\sigma$ 是密度函数的两个参数，$\sigma$ 还必须是正数。可以证明，$f_X(x)$ 满足下面的概率密度函数的归一化条件（见本章关于定理的习题）：$$\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{+\infty}e^{\frac{-(x-\mu)^2}{2\sigma^2}}dx=1$$下图是正态分布的密度函数和分布函数 $(\mu=1 \text{ 和 } \sigma^2=1)$ 。 由图可以看出，正态随机变量的概率密度函数是相对于均值 $\mu$ 对称的钟形曲线。当 $x$ 离开 $\mu$ 的时候，概率密度函数的表达式中的项 $e^{\frac{-(x-\mu)^2}{2\sigma^2}}$ 很快地下降。在图中，概率密度函数在区间 $[-1,3]$ 之外非常接近 $0$ 。 正态随机变量的均值和方差可由下列式子给出：$$E[X]=\mu,\quad var(X)=\sigma^2$$由于 $X$ 的概率密度函数相对于 $\mu$ 对称，其均值只能是 $\mu$ 。至于方差的公式，一句定义得：$$var(X)=\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{+\infty}(x-\mu)^2e^{-\frac{(x-\mu)^2}{2\sigma^2}}dx$$将公式中的积分作积分变量替换 $y=\frac{(x-\mu)}{\sigma}$ 以及分布积分得到：$$\begin{eqnarray}var(X) &amp;=&amp; \frac{\sigma^2}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}y^2e^{-\frac{y^2}{2}}dy \\&amp;=&amp; \frac{\sigma^2}{\sqrt{2\pi}}(-ye^{-\frac{y^2}{2}})|^{+\infty}_{-\infty}+\frac{\sigma^2}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{\frac{y^2}{2}}dy \\&amp;=&amp; \frac{\sigma^2}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{-\frac{y^2}{2}}dy \\&amp;=&amp; \sigma^2\end{eqnarray}$$上面最后的等式，是由于$$\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{-\frac{y^2}{2}}dy=1$$这个公式正好是当 $\mu=0$ 和 $\sigma^2=1$ 的时候的正态随机变量的概率密度函数的归一化条件，在本章习题第14题得以证明，截图如下： 正态随机变量具有若干重要的性质。下面的性质尤其重要，并且将在 第四章 Further Topicson Random Variables 的第一节加以证明。 随机变量的正态性在线性变换之下保持不变设 $X$ 是正态随机变量，其均值为 $\mu$ ，方差为 $\sigma^2$ 。若 $a\ne 0$ 和 $b$ 为两个常数，则随机变量$$Y=aX+b$$仍然是正态随机变量，其均值和方差由下式定义给出：$$E[Y]=a\mu+b,\quad var(Y)=a^2\sigma^2$$ 标准正态随机变量设正态随机变量 $Y$ 的期望为 $0$ ，方差为 $1$，则 $Y$ 称为标准正态随机变量。以 $\Phi$ 记为它的 CDF ：$$\Phi(y)=P(Y\le y)=P(Y&lt; y)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{y}e^{\frac{-t^2}{2}}dt$$通常将它的值列成一个表——标准正态累积分布表（见下表：），这是计算有关正态随机变量的概率的重要的工具。标准正态表的每一项提供了 $\Phi(y)=P(Y\le y)$ 的数值，这里 $Y$ 是一个正态随机变量，这个表中 $y\in [0,4.09]$ 。怎么使用这个表呢？举例，为了查找 $\Phi(1.71)$ 的值，查看关于 $1.7$ 所在的行和 $0.01$ 所在的列，得到 $\Phi(1.71)=0.95637$ 。 注意到下表只列出当 $y &gt; 0， \Phi(y) $ 的值，可以利用标准正态随机变量的概率密度函数的对称性，可将 $y &lt; 0$ 时 $\Phi(y)$ 的值推导出来。例如：$$\begin{eqnarray}\Phi(-0.5) &amp;=&amp; P(Y\le -0.5)=P(Y\ge 0.5)=1-P(Y &lt; 0.5) \\&amp;=&amp; 1- \Phi(0.5) = 1-0.69146=0.30854\end{eqnarray}$$可推广$$\forall\ y&gt;0, \Phi(-y)=1-\Phi(y)$$ y +0.00 +0.01 +0.02 +0.03 +0.04 +0.05 +0.06 +0.07 +0.08 +0.09 0.0 0.50000 0.50399 0.50798 0.51197 0.51595 0.51994 0.52392 0.52790 0.53188 0.53586 0.1 0.53983 0.54380 0.54776 0.55172 0.55567 0.55966 0.56360 0.56749 0.57142 0.57535 0.2 0.57926 0.58317 0.58706 0.59095 0.59483 0.59871 0.60257 0.60642 0.61026 0.61409 0.3 0.61791 0.62172 0.62552 0.62930 0.63307 0.63683 0.64058 0.64431 0.64803 0.65173 0.4 0.65542 0.65910 0.66276 0.66640 0.67003 0.67364 0.67724 0.68082 0.68439 0.68793 0.5 0.69146 0.69497 0.69847 0.70194 0.70540 0.70884 0.71226 0.71566 0.71904 0.72240 0.6 0.72575 0.72907 0.73237 0.73565 0.73891 0.74215 0.74537 0.74857 0.75175 0.75490 0.7 0.75804 0.76115 0.76424 0.76730 0.77035 0.77337 0.77637 0.77935 0.78230 0.78524 0.8 0.78814 0.79103 0.79389 0.79673 0.79955 0.80234 0.80511 0.80785 0.81057 0.81327 0.9 0.81594 0.81859 0.82121 0.82381 0.82639 0.82894 0.83147 0.83398 0.83646 0.83891 1.0 0.84134 0.84375 0.84614 0.84849 0.85083 0.85314 0.85543 0.85769 0.85993 0.86214 1.1 0.86433 0.86650 0.86864 0.87076 0.87286 0.87493 0.87698 0.87900 0.88100 0.88298 1.2 0.88493 0.88686 0.88877 0.89065 0.89251 0.89435 0.89617 0.89796 0.89973 0.90147 1.3 0.90320 0.90490 0.90658 0.90824 0.90988 0.91149 0.91308 0.91466 0.91621 0.91774 1.4 0.91924 0.92073 0.92220 0.92364 0.92507 0.92647 0.92785 0.92922 0.93056 0.93189 1.5 0.93319 0.93448 0.93574 0.93699 0.93822 0.93943 0.94062 0.94179 0.94295 0.94408 1.6 0.94520 0.94630 0.94738 0.94845 0.94950 0.95053 0.95154 0.95254 0.95352 0.95449 1.7 0.95543 0.95637 0.95728 0.95818 0.95907 0.95994 0.96080 0.96164 0.96246 0.96327 1.8 0.96407 0.96485 0.96562 0.96638 0.96712 0.96784 0.96856 0.96926 0.96995 0.97062 1.9 0.97128 0.97193 0.97257 0.97320 0.97381 0.97441 0.97500 0.97558 0.97615 0.97670 2.0 0.97725 0.97778 0.97831 0.97882 0.97932 0.97982 0.98030 0.98077 0.98124 0.98169 2.1 0.98214 0.98257 0.98300 0.98341 0.98382 0.98422 0.98461 0.98500 0.98537 0.98574 2.2 0.98610 0.98645 0.98679 0.98713 0.98745 0.98778 0.98809 0.98840 0.98870 0.98899 2.3 0.98928 0.98956 0.98983 0.99010 0.99036 0.99061 0.99086 0.99111 0.99134 0.99158 2.4 0.99180 0.99202 0.99224 0.99245 0.99266 0.99286 0.99305 0.99324 0.99343 0.99361 2.5 0.99379 0.99396 0.99413 0.99430 0.99446 0.99461 0.99477 0.99492 0.99506 0.99520 2.6 0.99534 0.99547 0.99560 0.99573 0.99585 0.99598 0.99609 0.99621 0.99632 0.99643 2.7 0.99653 0.99664 0.99674 0.99683 0.99693 0.99702 0.99711 0.99720 0.99728 0.99736 2.8 0.99744 0.99752 0.99760 0.99767 0.99774 0.99781 0.99788 0.99795 0.99801 0.99807 2.9 0.99813 0.99819 0.99825 0.99831 0.99836 0.99841 0.99846 0.99851 0.99856 0.99861 3.0 0.99865 0.99869 0.99874 0.99878 0.99882 0.99886 0.99889 0.99893 0.99896 0.99900 3.1 0.99903 0.99906 0.99910 0.99913 0.99916 0.99918 0.99921 0.99924 0.99926 0.99929 3.2 0.99931 0.99934 0.99936 0.99938 0.99940 0.99942 0.99944 0.99946 0.99948 0.99950 3.3 0.99952 0.99953 0.99955 0.99957 0.99958 0.99960 0.99961 0.99962 0.99964 0.99965 3.4 0.99966 0.99968 0.99969 0.99970 0.99971 0.99972 0.99973 0.99974 0.99975 0.99976 3.5 0.99977 0.99978 0.99978 0.99979 0.99980 0.99981 0.99981 0.99982 0.99983 0.99983 3.6 0.99984 0.99985 0.99985 0.99986 0.99986 0.99987 0.99987 0.99988 0.99988 0.99989 3.7 0.99989 0.99990 0.99990 0.99990 0.99991 0.99991 0.99992 0.99992 0.99992 0.99992 3.8 0.99993 0.99993 0.99993 0.99994 0.99994 0.99994 0.99994 0.99995 0.99995 0.99995 3.9 0.99995 0.99995 0.99996 0.99996 0.99996 0.99996 0.99996 0.99996 0.99997 0.99997 4.0 0.99997 0.99997 0.99997 0.99997 0.99997 0.99997 0.99998 0.99998 0.99998 0.99998 现在用 $X$ 表示一个均值为 $\mu$ 和方差为 $\sigma^2$ 的正态随机变量。通过定义一个新的随机变量 $Y$ 来(“standardize”)标准化 $X$ ：$$Y=\frac{X-\mu}{\sigma}$$因为 $Y$ 是 $X$ 的线性函数，所以 $Y$ 也是正态随机变量。而且$$E[Y]=\frac{E[X]-u}{\sigma}=0,\quad var(Y)=\frac{var(X)}{\sigma^2}=1$$因此，$Y$ 是一个标准正态随机变量。这个事实可以让我们用 $Y$ 重新定义 $X$ 所表示的事件，然后使用标准正态表去计算。 使用正态分布表的例子某地区的年度降雪量是一个正态随机变量，期望为 $\mu=60$ 英寸，标准差为 $\sigma=20$ 。本年度降雪量至少为 $80$ 英寸的概率有多大？ 记 $X$ 为年降雪量，令$$Y=\frac{X-\mu}{\sigma}=\frac{X-60}{20}$$显然 $Y$ 是标准正态随机变量。$$P(X\ge 80)=P(\frac{X-60}{20} \ge \frac{80-60}{20})=P(Y\ge \frac{80-60}{20})=P(Y\ge 1)=1-\Phi(1)$$其中 $\Phi$ 为标准正态累积分布函数。通过查询上表得到：$\Phi(1)=0.84134$ ，因此$$P(X\ge 80)=1-\Phi(1)=0.15866$$推广这个例子中的方法，得到如下： 正态随机变量的累积分布函数计算对于均值为 $\mu$ 方差为 $\sigma^2$ 的正态随机变量 $X$ ，使用一下步骤： 标准化 $X$ ：先减去 $\mu$ 再除以 $\sigma$ 来获取标准随机变量 $Y$ 。 从标准正态表中读取累积分布函数值：$$P(X\le x)=P(\frac{X-\mu}{\sigma}\le \frac{x-\mu}{\sigma})=P(Y\le \frac{x-\mu}{\sigma})=\Phi(\frac{x-\mu}{\sigma})$$正态随机变量经常使用在信号处理和通信工程中去对噪音和信号失真进行建模。 例3.8 信号侦测二进制信息用信号 $s$ 传输，这个信息要么是 $-1$ 和 $+1$ 。信号在信道传输过程中会伴随一些噪声，噪声满足均值为 $\mu=0$ ，方差为 $\sigma^2$ 的正态分布。接收器会接收到混有噪音的信号 ，如果接收到的值为小于 $0$ ，那么就认为信号为 $-1$ ，如果接收到的值为大于 $0$ ，那么就认为接收到的信号为 $+1$ 。问这种判断方法的误差有多大？ 误差只有出现在下面两种情况： 实际被传输的信号为 $-1$，但是噪声变量 $N$ 值至少是 $1$ ，因此 $s+N=-1+N \ge 0$ 。 实际被传输的信号为 $+1$，但是噪声变量 $N$ 值小于 $-1$ 。因此 $s+N=1+N &lt;0$ 。 因此这种判断方法在情况1下出现误差的概率为：$$\begin{eqnarray}P(N\ge 1) &amp;=&amp; 1-P(N &lt; 1) = 1 - P(N&lt;1)=1-P(\frac{N-\mu}{\sigma}&lt;\frac{1-\mu}{\sigma}) \\&amp;=&amp; 1- \Phi(\frac{1-\mu}{\sigma}) \\&amp;=&amp; 1-\Phi(\frac{1}{\sigma})\end{eqnarray}$$在第2种情况下出现误差的概率根据正态分布的对称性得到与前一种情况一样。$\Phi(\frac{1}{\sigma})$ 能够从正态分布表得到。例如对于 $\sigma=1$ ，$\Phi(\frac{1}{\sigma})=\Phi(1)=0.84134$ ，所以出现误差的概率为 $0.15864$ 。 正态随机变量扮演一个重要的角色在各种广泛的概率模型中，其原因是在物理、工程和统计中，正态随机变量能够很好地模拟许多独立因素的叠加效应。数学上，关键事实是大量独立同分布的随机变量（不必为正态）的和的分布近似地服从正态分布，而这个事实与各个和项的具体的分布无关的。这个事实就是著名的中心极限定理，这个将在本书第五章详细说明。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-分段常数概率密度函数的均值和方差]]></title>
    <url>%2F2017%2F08%2F27%2Fmean_and_variance_of_a_piecewise_constant_PDF%2F</url>
    <content type="text"><![CDATA[本文摘录自 Introduction to probability, 2nd Edition Example 3.17 Mean and Variance of a Piecewise Constant PDF 假设一个随机变量 $X$ 有分段常数的概率密度函数 $$f_x(x)=\cases{\frac{1}{3}, &amp; if $0 \le x \le 1$, \\ \frac{2}{3}, &amp; if $ 1 &lt; x \le 2$, \\0, &amp; if otherwise}$$ 考虑事件： $$A_1=\{\text{X 位于第一个区间 [0,1]}\}$$ $$A_2=\{\text{X 位于第二个区间 (1,2]}\}$$ 我们从已知的概率密度函数得到： $$P(A_1)=\int_{0}^{1}f_X(x)dx=\frac{1}{3}, \quad P(A_2)=\int_{1}^{2}f_X(x)dx=\frac{2}{3}$$ 因此，条件均值和 $X$ 的条件二阶矩容易计算，因为相关的概率密度函数 $PDF_S$： $f_{X|A_1}$ 和 $f_{X|A_2}$ 是均匀的，回忆例子3.4得到， 均匀分布在区间 $[a,b]$ 上的的随机变量的均值是：$\frac{(a+b)}{2}$ ，它的二阶矩是 $\frac{(a^2+ab+b^2)}{3}$ ，因此： $$\begin{eqnarray}E[X|A_1]&amp;=&amp;\frac{1}{2},\quad E[X|A_2]&amp;=&amp;\frac{3}{2}\\E[X^2|A_1]&amp;=&amp;\frac{1}{3},\quad E[X^2|A_2]&amp;=&amp;\frac{7}{3}\end{eqnarray}$$ 使用总期望定理得到：$$\begin{eqnarray}E[X] &amp;=&amp; P(A_1)E[X|A_1]+P(A_2)E[X|A_2] &amp;=&amp; \frac{1}{3} \cdot \frac{1}{2}+\frac{2}{3}\cdot\frac{3}{2} &amp;=&amp; \frac{7}{6} \\E[X^2] &amp;=&amp; P(A_1)E[X^2|A_1]+P(A_2)E[X^2|A_2] &amp;=&amp; \frac{1}{3}\cdot\frac{1}{3}+\frac{2}{3}\cdot\frac{7}{3} &amp;=&amp; \frac{15}{9}\end{eqnarray}$$那么可以得到方差： $$var(x)=E[X^2]-(E[X])^2=\frac{15}{9}-\frac{49}{36}=\frac{11}{36}$$ 注意： 对于计算均值和方差的方法是容易推广到多分段的常数概率密度函数。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-[累积]分布函数CDF]]></title>
    <url>%2F2017%2F08%2F26%2Fcumulative_distribution_function%2F</url>
    <content type="text"><![CDATA[说明：全文摘自 Introduction to probability, 2nd Edition 分布函数我们分别用概率质量函数 PMF(Probability Mass Function) 和概率密度函数 PDF(Probability Density Function) 来刻画随机变量 $X$ 的取值规律。现在希望用一个统一的数学工具去刻画随机变量的取值规律。 ​分布函数（用记号 CDF 表示简称）就能完成这个任务。 $X$ 的 CDF 是一个 $x$ 的函数，对每一个 $x$ ，$F_X(x)$ 定义为 $P(X\le x)$ 。特别地，当 $X$ 为离散或连续的情况下：$$F_X(x)=P(X\le x)=\cases{\sum\limits_{k\le x}p_X(k), \text{若 $X$ 是离散的}\\\int_{-\infty}^{x}f_X(x)dt, \text{若 $X$ 是连续的 }}$$分布函数又称为累积分布函数（cumulative distribution function），累积意味着 $F_X(x)$ 将 $X$ 取值的概率由 $-\infty\rightarrow x$。 在一个概率模型中，随机变量可以有不同的类型，可以是离散的，也可以是连续的，甚至可以是既非离散的也非连续的。但不管是什么类型的随机变量，它们有一个共同的特征，即都有一个分布函数，这是因为 $\{X\le x\}$ 是一个随机事件，这些事件的概率形成概率分布。今后，凡是通过 PMF\PDF\CDF刻画事件 $\{X\le x\}$ 概率的，都称为随机变量 $X$ 的概率律。因此离散情况下的分布列，连续情况下的概率密度函数以及一般情况下的分布函数都是相应的随机变量的概率律。 下图分别给出不同的离散随机变量和连续随机变量的 CDF 的一些说明。从这些图像以及 CDF 的定义，可以得到 CDF 的某些性质。 上图这些离散随机变量的 CDF ，通过随机变量的概率质量函数（PMF）可求得相应的分布函数：$$F_X(x)=P(X\le x)=\sum\limits_{k\le x}p_{X}(k)$$这个函数是一个阶梯函数，在具有正概率的那些点上具有跳跃。在跳跃点上， $F_X(x)$ 取较大的那个值，即 $F_X(x)$ 保持右连续。 上图的这些连续随机变量的 $CDF$ 。通过随机变量的概率密度函数（PDF）可求得相应的分布函数：$$F_X(x)=P(X\le x)=\int_{-\infty}^{+\infty}f_X(t)dt$$概率密度函数 $f_X(x)$ 可由 CDF 经求微分得到：$$f_X(x)=\frac{dF_X(x)}{dx}(x)$$对于连续随机变量，CDF 是连续的 CDF 的性质假设 $X$ 的 CDF $F_X(x)$ 是由下式定义的 ：$$F_X(x)=P(X\le x), \forall x$$并且 $F_X(x)$ 具有下列性质： $F_X(x)$ 是 $x$ 的单调非减函数：若 $x\le y$ ，则 $F_X(x)\le F_X(y)$ 。 当 $x\rightarrow -\infty$ 的时候，则 $F_X(x)\rightarrow 0$ ，当 $x\rightarrow +\infty$ ，则 $F_X(x)\rightarrow 1$ 。 当 $X$ 是离散随机变量的时候， $F_X(x)$ 为阶梯函数。 当 $X$ 是连续随机变量的时候， $F_X(x)$ 为 $x$ 的连续函数。 当 $X$ 是离散随机变量并且取整数数值的时候，分布函数和概率质量函数（PMF）可以利用求和或差分互求：$$F_X(k)=\sum\limits_{i=-\infty}^{k}p_X(i)\\p_X(k)=P(X\le k)-P(X\le k-1)=F_X(k)-F_X(k-1)$$其中 $k$ 可以是任意整数。 当 $X$ 是连续随机变量的时候，分布函数与概率密度函数可以利用积分和微分互求：$$F_X(x)=\int_{-\infty}^{x}f_X(t)dt,\quad f_X(x)=\frac{dF_X}{dx}(x)$$(第二个等式只在分布函数可微的那些点上成立) 有时候为了计算随机变量的概率质量函数或概率密度函数，首先计算随机变量的分布函数会更方便些。在连续随机变量的情况下，将在4.1节系统地介绍用该方法求随机变量的函数的分布。下面是一个离散随机变量的计算例子。 例子几个随机变量的最大值你参加某种测试，按规定三次测试的最高成绩作为你的最后成绩，设 $X=max\{X_1,X_2,X_3\}$ ，其中 $X_1,X_2,X_3$ 是三次测试成绩，$X$ 是你的最后的成绩。假设你的每次测试成绩是 1 分到 10 分之间，并且 $P(X=i)=\frac{1}{10}, i=1,…,10$ 。现在求最终成绩 $X$ 的概率质量函数。 采用间接方法求分布函数。首先计算 $X$ 的 CDF，然后通过$$p_X(k)=F_X(k)-F_X(k-1), i=1,\ldots,10$$得到 $X$ 的概率质量函数。对于 $F_X(k)$ ，得到：$$\begin{eqnarray}F_X(k) &amp;=&amp; P(X\le k) \\&amp;=&amp; P(X_1\le k, X_2\le k, X_3\le k) \\&amp;=&amp; P(X_1\le k)P(X_2\le k)P(X_3\le k) \\&amp;=&amp; (\frac{k}{10})^3\end{eqnarray}$$此处第三个等式是由事件 $\{X_1\le k\},\{X_2\le k\},\{X_3\le k\}$ 相互独立所致。这样 $X$ 的概率质量函数为：$$p_X(k)=(\frac{k}{10})^3-(\frac{k-1}{10})^3, k=1,\ldots,10$$本例的方法可推广到 $n$ 个随机变量 $X_1,\ldots,X_n$ 的情况。如果对每一个 $x$ ，事件 $\{X_1\le x\},\ldots, \{X_n\le x\}$ 相互独立，则 $X=max\{X_1,\ldots,X_n\}$ 的 CDF 为：$$F(x)=F_{X_1}(x)\cdots F_{X_n}(x)$$利用这个公式，在离散情况下通过差分可得到 $P_X(x)$ ，在连续情况下通过微分可得到 $f_X(x)$ 。 距离的分布函数和概率密度函数习题3.5 ：按照均匀分布律，在一个三角形中随机的选取一个点，设已知三角形的高，求这个点到底边的距离 $X$ 的分布函数和概率密度函数。 用 $b$ 表示底的长度，$h$ 表示三角形的高度，$A=\frac{bh}{2}$ 表示三角形的面积。随机地在三角形内选取一个点，然后画一条平行于三角形底边的辅助直线，用 $A_x$ 表示由这条辅助线构成的小三角形的面积，那么这个小三角形的高度即 $h-x$ ，它的底边按比例求得：$b\frac{h-x}{h}$ ，因此 $A_x=\frac{b(h-x)^2}{2h}$ 。对于 $x\in [0,h]$ ，得到：$$F_X(x)=P(0&lt; x \le x)=1-P(X&gt;x)=1-\frac{A_x}{A}=1-\frac{\frac{b(h-x)^2}{2h}}{\frac{bh}{2}}=1-(\frac{h-x}{h})^2$$当 $x&lt;0,$ 那么 $F_X(x)=0$ ; 当 $x&gt;h,$ 那么 $F_X(x)=1$ 。 概率密度函数可以对累积分布函数 CDF 进行求微分得到：$$f_X(x)=\frac{dF_X}{dx}(x)=\cases{\frac{2(h-x)}{h^2}, &amp; 当 $0\le x \le h$\\0, &amp; 其他情况}$$ 等待时间习题3.6 ：Jane去银行取款，有1个或0个顾客在她前面，这两种情况是等可能的。已知一个顾客的服务时间是一个指数随机变量，参数为 $\lambda$ 。那么Jane所等待的时间分布函数是？ 用 $X$ 表示等待的时间，用 $Y$ 表示在Jane之前顾客的数量。于是得到：$\forall x &lt;0, F_X(x)=0$ ，其他情况下，根据题意得：$$F_X(x)=P(X\le x)=\frac{1}{2}P(X\le x| Y=0)+\frac{1}{2}P(X\le x|Y=1)$$又因为$$P(X\le x|Y=0)=1,\quad P(X\le x|Y=1)=1-e^{-\lambda x}$$得到$$F_X(x)=\cases{\frac{1}{2}(2-e^{-\lambda x}), &amp; if $x \ge 0$ \\0, &amp; 其他情况}$$注意：这个累积分布函数 CDF 在 $x=0$ 处连续，随机变量 $X$ 既不是离散的也不是连续的。 投飞标游戏Alvin在进行飞镖游戏，飞镖的靶是一块半径为 r 的圆板。记 $X$ 为飞镖的落点到靶心的距离。假设落点在靶板上均匀地分布。 (a) 求出 $X$ 的概率密度函数、均值和方差。 $X$ 的累积分布函数比较容易求得：$$F_X(x)=\cases{P(X\le x)=\frac{\pi x^2}{\pi r^2}=(\frac{x}{r})^2, &amp; if $\forall x\in [0,r]$\\0, &amp; if $x &lt; 0$\\1, &amp; if $x&gt;r$}$$通过微分，得到概率密度函数：$$f_X(x)=\cases{\frac{2x}{r^2}, &amp; if $0\le x\le r$\\0, &amp; otherwise}$$进而通过积分得到：$$E[X]=\int_{0}^{r}\frac{2x^2}{r^2}dx=\frac{2r}{3}\\E[X^2]=\int_{0}{r}\frac{2x^3}{r^2}dx=\frac{r^2}{2}\\var(X)=E[X^2]-(E[X])^2=\frac{r^2}{2}-\frac{4r^2}{9}=\frac{r^2}{18}$$(b) 靶上画出了一个半径为 $t$ 的同心圆。若 $X\le t$ ，Alvin的得分为 $S=\frac{1}{X}$ ，其他情况 $S=0$ 。求出 $S$ 的分布函数。 $S$ 是不是连续随机变量？ 由题意得：当且仅当 $X\le t$ ，Alvin 获得一个介于 $[\frac{1}{t}, +\infty)$ 的分数s，其它情况下，他的得分为 0 。因此：$$F_S(s)=\cases{0, \quad \text{if $s&lt;0$}\\P(S\le s)=1-P(X\le t), \quad \text{if $0\le s\le \frac{1}{t}$ (即Alvin击中了内圆之外)} \\P(S\le s)=P(X\le t)P(S\le s|X\le t)+P(X&gt;t)P(S\le s|X&gt;t) \quad \text{if $s &gt; \frac{1}{t}$}}$$根据题意，得到：$$P(X\le t)=\frac{t^2}{r^2},\quad P(X&gt;t)=1-\frac{t^2}{r^2}$$而且因为当 $X&gt;t, S=0$ ， 所以 $P(S\le s|X&gt; t)=1$ 。 进而得到：$$P(S\le s| X\le t)=P(\frac{1}{X}\le s|X\le t)=P(\frac{1}{s}\le X|X\le t) = \frac{P(\frac{1}{s}\le X \le t)}{P(X\le t)} =\frac{\frac{\pi t^2 -\pi(\frac{1}{s})^2}{\pi r^2}}{\frac{\pi t^2}{\pi r^2}}=1-\frac{1}{s^2t^2}$$最后得到：$$F_S(s)=\cases{ 0, &amp; \text{if }s&lt;0 \\ 1-\frac{t^2}{r^2}, &amp; \text{if } 0\le s \le \frac{1}{t}\\ 1-\frac{1}{s^2r^2} &amp; \text{if } \frac{1}{t}&lt;s}$$因为 $F_S(s)$ 在 $s=0$ 处不连续，所以随机变量 $S$ 不是连续的。 几何和指数随机变量的分布函数由于分布函数对一切随机变量都适用，可以利用它来探索离散和连续随机变量之间的关系。特别地，此处讨论几何随机变量和指数随机变量之间的关系。 设 $X$ 是一个几何随机变量，其参数为 $p$ ，即 $X$ 是在伯努利独立试验序列中直到第一次成功所需要的试验次数，而伯努利试验的参数为 $p$ 。这样对于 $k=1,2\cdots,$ 得到 $P(X=k)=p(1-p)^{k-1}$ ，而 $X$ 的 CDF 为：$$F_{geo}(n)=\sum\limits_{k=1}^{n}p(1-p)^{k-1}=p\frac{1-(1-p)^n}{1-(1-p)}=1-(1-p)^n,\quad n=1,2,\cdots$$现在设 $X$ 是一个指数随机变量，其参数 $\lambda&gt;0$ 。其 CDF 是$$F_{exp}(x)=P(X\le x)=0,\quad x\le 0\\F_{exp}(x)=\int_{0}^{x}\lambda e^{-\lambda t}dt=-e^{-\lambda t}|^{x}_{0}=1-e^{-\lambda x},\quad x&gt;0$$现在比较两个分布函数，令 $\delta=\frac{-ln(1-p)}{\lambda}\rightarrow \delta\lambda=-ln(1 - p)$ ，这样得到：$$e^{-\lambda\delta}=1-p \quad (*)$$那么，将 $(*)​$ 代入 $F_{geo}(n)​$ 得：$1-(e^{-\lambda\delta})^n=1-e^{-n\lambda\delta}​$ ，而分布函数 $F_{exp}​$ 在 $x=n\delta​$ 处为： $1-e^{-\lambda n\delta}=1-e^{-n\lambda\delta}​$ 是与 $F_{geo}​$ 在 $n​$ 处相等的，$n=1,2,\cdots​$ ，即：$$F_{exp}(n\delta)=F_{geo}(n)=, n=1,2,\cdots$$现在假定以很快的速度抛掷一枚不均匀的硬币 (每 $\delta$ 秒抛掷一次，$\delta \ll 1$)，每次抛掷，正面向上的概率为 $p=1-e^{-\lambda\delta}$ 。这样第一次得到正面向上所抛掷的次数为 $X$ ，第一次得到正面向上的时刻为 $X\delta$ ，$X\delta$ 与参数为 $\lambda$ 的指数随机变量十分接近，这只需看它们的分布函数即可（看下图）。这在本书第六章讨论伯努利和泊松分布过程的时候，这种关系显得特别重要。 几何随机变量和指数随机变量的分布函数之间的关系。图中离散分布函数为 $X\delta$ 的分布函数，$X$ 是参数为 $p=1-e^{-\lambda x}$ 的几何随机变量。当 $\delta\rightarrow 0$ 时，$X\delta$ 的分布函数趋于指数分布函数 $1-e^{-\lambda x}$ 。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-均匀随机变量的均值和方差]]></title>
    <url>%2F2017%2F08%2F26%2Fmean_and_variance_of_uniform_random_variable%2F</url>
    <content type="text"><![CDATA[说明：全文摘自Introduction to probability, 2nd Edition 均匀分布的离散随机变量按照定义，离散均匀随机变量的取值范围由相邻的整数所组成的有限集合，而取每个整数的概率都是相等的。这样它的分布列： $$p_X(k)=\cases{\frac{1}{b-a+1}, &amp; if k=a, a+1, … ,b\\0, &amp; otherwise}$$ 其中$a,b$ 是两个整数，作为随机变量的值域的两个端点，$a&lt;b$。由于它的概率函数相对于(a+b)/2 是对称的，所以其均值为： $$E[X]=\frac{a+b}{2}$$ 为计算$X$的方差，先考虑a=1和b=n的简单情况。利用归纳法可以证明： $$E[X^2]=\frac{1}{n}\sum\limits_{k=1}^{n}k^2=\frac{1}{6}(n+1)(2n+1)$$ （具体证明过程留作习题）。这样利用一、二阶矩，可得到$X$的方差$$\begin{eqnarray*}var(X)&amp;=&amp; E[X^2]-(E[X])^2\\&amp;=&amp;\frac{1}{6}(n+1)(2n+1)-\frac{1}{4}(n+1)^2\\&amp;=&amp;\frac{n^2-1}{12}\end{eqnarray*}$$对于 $a$ 和 $b$ 的一般情况，实际上在区间 $[a,b]$上的均匀分布与在区间 $[1,b-a+1]$ 上的分布之间的差异，只是一个分布是另外一个分布的偏移，因此两者具有相同的方差（此处区间 $[a,b]$ 是指处于 $a$ 和 $b$ 之间的整数的集合）。这样在一般的情况下，$X$ 的方差只需将简单的情况下公式中的 $n$ 替换成 $b-a+1$ ，即： $$var(X)=\frac{(b-a+1)^2-1}{12}=\frac{(b-a)(b-a+2)}{12}$$ 均匀分布的连续随机变量摘录自 Example 3.4. Mean and Variance of the Uniform Random Variable 设随机变量 $X$ 的分布为 $[a,b]$ 上的均匀分布，得到：$$\begin{eqnarray*}E[X] &amp;=&amp; \int_{-\infty}^{+\infty}xf_X(x)dx \\&amp;=&amp; \int_{a}^{b}x\frac{1}{b-a}dx \\&amp;=&amp; \frac{1}{b-a}\cdot \frac{1}{2}x^2|^{b}_{a} \\&amp;=&amp; \frac{1}{b-a}\cdot\frac{b^2-a^2}{2} \\&amp;=&amp; \frac{b+a}{2}\end{eqnarray*}$$这个期望值刚好等于 $PDF$ 的对称中心 $\frac{b+a}{2}$ 。 为求得方差，先计算 $X$ 的二阶矩：$$\begin{eqnarray*}E[X^2] &amp;=&amp; \int_{a}^{b}\frac{x^2}{b-a}dx \\&amp;=&amp; \frac{1}{b-a}\cdot\int_{a}{b}x^2dx \\&amp;=&amp; \frac{1}{b-a}\cdot \frac{1}{3}x^3|_{a}^{b} \\&amp;=&amp; \frac{b^3-a^3}{3(b-a)} \\&amp;=&amp; \frac{a^2+ab+b^2}{3} \\\end{eqnarray*}$$这样随机变量 $X$ 的方差为：$$var(X)=E[X^2]-(E[X])^2=\frac{a^2+ab+b^2}{3}-\frac{(a+b)^2}{4}=\frac{(b-a)^2}{12}$$]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-样本均值的期望方差与模拟的方法估计概率]]></title>
    <url>%2F2017%2F08%2F25%2Fmean_and_variance_of_sample_and_estimating_probability_by_simulation%2F</url>
    <content type="text"><![CDATA[样本均值的期望方差摘录自：Introduction to probability, 2nd Edition Example 2.21. Mean and Variance of the Sample Mean 我们希望估计总统的支持率。为此，我们随机地选取n个选民，询问他们的看法。令 $x_i​$ 表示 $i​$ 个被问的选民的态度： $$X_i = \cases{1, \text{若第 $i$ 个被问的选民支持总统}\\0, \text{若第 $i$ 个被问的选民不支持总统}}$$ 假设$X_1,\ldots, X_n$为独立同分布的伯努利随机变量，其均值为 $p$，方差为 $p(1-p)$ 。此处我们将 $p$ 认为选民支持总统的概率，并且将对调查得到的回应进行平均处理，计算样本均值 $S_n$ ，把 $S_n$ 定义为 $$S_n=\frac{X_1+ \ldots + X_n}{n}$$ 因此，随机变量 $S_n$ 是对n个选民抽样的支持率。 由于 $S_n$ 是 $X_1, \ldots, X_n$ 的一个线性函数，我们利用均值的线性关系得到， $E[S_n]=\sum\limits_{i=1}^{n} E[\frac{X_i}{n}]=\sum\limits_{i=1}^{n}\frac{1}{n}E[X_i]= \sum\limits_{i=1}^{n}\frac{1}{n}p=p=E[X]$ 再利用$X_1,\ldots, X_n$ 的独立性，可以得到： $$var(S_n) = \sum\limits_{i=1}^{n}var(\frac{X_i}{n}) = \sum\limits_{i=1}^{n}\frac{1}{n^2}var(X_i) = \frac{p(1-p)}{n}$$ 样本均值为 $S_n$ 被认为是支持率很好的估计，这是因为它的期望值刚好是 $p$。然后反映精度的方差随着样本大小的$n$ 增大的时候，变得越来越小。 注意，上例中即使 $X_i$ 不是伯努利随机变量，结论 $$var(S_n) = \frac{var(X)}{n}$$ 仍然成立，只要 $X_i$ 之间相互独立，毕竟期望和方差与 $i$ 无关。因此，随着样本大小增加，样本均值仍然是随机变量的均值的一个很好的估计。我们将在第5章再详细讨论样本均值的这些属性，并且与大数定律结合起来。 模拟的方法估计概率摘录自：Introduction to probability, 2nd Edition Example 2.22. Estimating Probabilities by Simulation 在许多实际问题中，有时候计算一个事件的概率是十分困难的，然后我们可以用物理方法或计算机方法重复地进行试验，这些试验结果可以显示事件是否发生。利用这种模拟方法可以以很高的精度计算某事件的概率。可以独立地模拟试验 $n$ 次，并且记录 $n$ 次试验中的 $A$ 发生的次数 $m$，用 $\frac{m}{n}$ 去近似概率 $P(A)$。例如在抛掷硬币试验中，计算概率 $p=P$ （出现正面），独立地抛掷 $n$ 次，用比值（记录中出现的正面次数除以试验总次数n）去逼近概率$p$。 为计算这种方法的精确度，考虑 $n$ 个独立同分布的伯努利随机变量 $X_1,\ldots, X_n$，每个 $X_i$ 的概率质量函数： $$p_{X_i}(k)=\cases{P(A), if\ k=1\\1-P(A), if\ k=0}$$ 在模拟环境中，$X_i$ 有关于第 $i$ 次试验的结果，如果第 $i$ 次的试验结果属于 $A$ ，那么 $X_i$ 取值为1，那么随机变量的取值（$$X=\frac{X_1+X_2+\ldots+X_n}{n}$$） 就是概率 $P(A)$ 的估计值。由例 2.21 的结果知，$X$ 的期望为 $P(A)$，方差为 $\frac{P(A)(1-P(A))}{n}$。故 $n$ 很大时，$X$提供了 $P(A)$ 的精确的估计。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-指数型随机变量的均值和方差]]></title>
    <url>%2F2017%2F08%2F25%2Fexponential_random_variables%2F</url>
    <content type="text"><![CDATA[说明：全文摘自 Introduction to probability, 2nd Edition 一个指数型随机变量是拥有以下形式的概率密度函数：$$f_X(x)=\cases{ \lambda e^{-\lambda x}, &amp; if $x\ge 0$ \\ 0, &amp; 其他情况}$$这个公式中$\lambda$ 是一个正数，这是一个符合概率归一性的定义，因为：$$\int_{-\infty}^{+\infty}f_X(x)dx=\int_{-\infty}^{+\infty}\lambda e^{-\lambda}dx=-e^{\lambda x}|_0^{+\infty}=1$$注意，指数型概率密度函数具有这样的特性：$X$ 超过某个值的概率随着这个值的增加而按指数递减$$\forall a\ge 0,P(X\ge a)=\int_{a}^{\infty}\lambda e^{-\lambda x}dx=-e^{-\lambda x}|_a^{+\infty}=e^{-\lambda a}$$由概率密度函数得到累积分布函数：$$\forall x \ge 0, P(X\le x)=\int_{0}^{x}\lambda e^{-\lambda x}dx=1-e^{-\lambda x}$$ 指数型随机变量能够对直到事件发生的时间建模，例如：消息到达计算机的时间，设备的使用寿命，灯泡的寿命，事故发生的时间等等（An exponential random variable can, for example, be a good model for the amount of time until an incident of interest takes place）。将在后面的章节看到指数型随机变量与几何随机变量紧密关联，几何随机变量也与相关事件发生的（离散）时间相关联。指数型随机变量将在第六章随机过程的学习中扮演重要的角色。但是目前为止，仅仅视它为一种特殊的可分析追中的随机变量。 指数型随机变量的均值和方差：$$\begin{eqnarray}E[X] &amp;=&amp; \int_{0}^{\infty}x\lambda e^{-\lambda x}dx \\&amp;=&amp; (-xe^{-\lambda x})|_0^{\infty} + \int_{0}^{\infty}e^{-\lambda x}dx \quad\text{这一步利用分部积分法}\\&amp;=&amp; 0-\frac{e^{-\lambda x}}{\lambda}|_0^{\infty}\\&amp;=&amp; \frac{1}{\lambda}\end{eqnarray}$$在此利用分布积分法，可得到 $X$ 的二阶矩：$$\begin{eqnarray}E[X^2] &amp;=&amp; \int_{0}^{\infty}x^2\lambda e^{-\lambda x}dx \\&amp;=&amp; (-x^2e^{-\lambda x})|_0^{\infty}+\int_{0}^{\infty}2xe^{-\lambda x}dx&amp;=&amp; 0+ \frac{2}{\lambda}E[X]\\&amp;=&amp; \frac{2}{\lambda^2}\end{eqnarray}$$最后利用公式 $var(x)=E[X^2]-(E[X])^2$ ，得到：$$var(X)=\frac{2}{\lambda^2}-\frac{1}{\lambda}=\frac{1}{\lambda^2}$$ 例3.5小陨石落入非洲撒哈拉沙漠的时间是遵从指数族分布的。具体地说，从某一观察者开始观察，知道发现一个陨石落到沙漠中，这个时间被模拟成指数型随机变量，其均值为 $10$ 天，现在假定，目前时间为晚上 $12$ 点整。问第二天早晨 $6:00$ 到傍晚 $6:00$ 之间陨石首次落下的概率是多少？ 假定 $X$ 是为了观察陨石落下所需要的等待时间。由于 $X$ 满足指数型分布，均值为 $\frac{1}{\lambda}=10$ ，由此得：$\lambda=\frac{1}{10}$ 。所求的概率为：$$P(\frac{1}{4}\le X \le \frac{3}{4})=P(X\ge \frac{1}{4})-P(X\ge \frac{3}{4})=e^{-\frac{1}{40}}-e^{-\frac{3}{40}}=0.0476$$求解这个过程中利用了连续型随机变量 $P(X\ge a)=P(X&gt; a)=e^{-\lambda a}$ 。 指数随机变量的无记忆性一个灯泡的使用寿命 $T$ 是一个指数随机变量，其参数为 $\lambda$ 。Ariadne 将灯打开后离开房间，在外面呆了一段时间以后（时间长度为 $t$），他回到房间后，灯还亮着。这相当于事件 $A=\{T&gt;t\}$ 发生了。记 $X$ 为灯泡的剩余寿命，问 $X$ 的分布函数是什么？ 解答： 实际上 $X$ 是在 $A$ 发生条件下的寿命，得到：$$\begin{eqnarray}P(X&gt; x|A) &amp;=&amp; P(T&gt;t+x|T&gt;t) \\&amp;=&amp; \frac{P(T&gt;t+x, T &gt; t)}{P(T&gt;t)} \\&amp;=&amp; \frac{P(T&gt; t+x)}{P(T&gt;t)} \\&amp;=&amp; \frac{e^{-\lambda(t+x)}}{e^{-\lambda t}}\\&amp;=&amp; e^{-\lambda x}\end{eqnarray}$$灯泡的剩余寿命 $X$ 的分布函数是指数分布，其参数也是 $\lambda$ ，这和灯泡已经亮了多少个小时是无关的。指数分布的这个性质就是分布的无记忆性。一般地，若将完成某个任务所需要的时间的分布定位指数分布。那么只要这个任务没有完成，那么要完成这个任务所需要的剩余时间的分布仍然是指数分布，并且其参数也是不变化的。 应用一个粗心的教授错误地将两个学生的答疑时间安排在了同一个时间段。已知两位同学的答疑时间长度是两个相互独立的并且同分布的随机变量，分布是指数分布，期望值为 $30$ 分钟，第一个学生按时到达，5分钟以后，第二个学生也到达。从第一个学生到达起直到第二个学生离开所需要时间的期望值是？ 解答： 用 $T_{total}$ 表示教授答疑总共用时的随机变量，用 $T_{s_1}, T_{s_2} $ 表示教授分别对学生 $1$ 和学生 $2$ 答疑时间，那么$$E[T_{total}]=P(T_{s_1}&lt; 5) \cdot E[5+E[T_{s_2}]] + P(T_{s_1} \ge 5)(E[T_{s_1}|T_{s_1}\ge5]+E[T_{s_2}])$$据题目得：$E[T_{s_1}]=E[T_{s_2}]=30$ ，利用指数型随机变量的无记忆性得到：$E[T_{s_1}|T_{s_1}\ge5] = 5+E[T_{s_1}] = 35$ 。$$P(T_{s_1} \ge 5) = e^{-\frac{1}{30}\cdot5} \\P(T_{s_1} &lt; 5)=1-P(T_{s_1}\ge 5)=1-e^{-\frac{1}{30}\cdot5}\\$$因此：$$E[T_{total}]=(1-e^{-\frac{1}{30}\cdot5})\cdot (5+30)+(e^{-\frac{1}{30}\cdot5})\cdot (35+30)=35+30\cdot e^{-\frac{5}{30}}=60.394$$]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-两个信封的悖论]]></title>
    <url>%2F2017%2F08%2F24%2Fthe_two-envelopes_paradox%2F</url>
    <content type="text"><![CDATA[本文摘录自：Introduction to probability, 2nd Edition Example 2.18. The Two-Envelopes Paradox. 这是一个广泛兴趣的智力测验问题，它涉及有关条件期望的数学要点。 主持人给你两个信封，并且告诉你两个信封里有现金，其中一个信封里的钱是另一个信封里的$m$倍（$m&gt;1$且是一个整数）。当你打开一个信封的时候，看到信封里面的钱数以后，你有两个选择，一是收下这个信封里的钱作为你的奖金，二是放弃这个信封的钱，选择另一个信封里的钱作为你的奖金。那么有什么好的策略可使你拿到较多的奖金呢？ 下面有一条推理，它证明应该转向选择第二个信封的。用A表示你打开的信封，B 是你可能换的信封，$x$和$y$分别表示信封A和B中的钱。论证如下：由于要么$y={x\over m}$ 要么 $y=mx$ ，而且两种情况发生的概率都是${1\over 2}$，因此给定的 $x,y$ 的期望值为： $$\frac{1}{2}\cdot \frac{x}{m} + \frac{1}{2}\cdot mx= \frac{1}{2}(\frac{1}{m}+m)x=\frac{1+m^2}{2m}x&gt;x$$ 这样，你应该总是转向信封B。当你随机选择到B的时候，由于同样的理由，又得到转回到A。这样陷入了矛盾之中，因为按照这个推理是不管选择到信封是哪一个都要选择另外一个信封作为奖金。 其实在这个悖论中，有两个假设是有瑕疵的： 对于两个信封内的钱，你是无法预先知道的，当给定$x$的值以后，你以为知道的就是$y=\frac{x}{m}$或者$y=mx$ 。而且没有理由哪一种情况更有可能。 用随机变量$X$和$Y$表示两个信封内的钱，若$E[Y|X=x]&gt;x, x\in \forall$ 成立，那么总是转向选择另一个信封能得到更多的期望奖金。 让我们仔细审查这两个假设： 假设1是有瑕疵的，因为它依赖他一个不完整的确定的概率模型。事实上，各种模型的事件中，包含$X$和$Y$的可能取值，都必须有一个确定概率。有了这样$X$ $Y$的概率信息，$X$的值可能会揭示$Y$取值的大量信息。例如，假设下面这个概率模型：某个人选择 $Z$ 元放在一个信封内，$Z$ 的取值范围为 $[\underline{z}, \overline{z}]$ 的整数，并且服从某个概率分布（distribution ），而在另一个信封内存入$mZ$ 的钱。然后，你以等概率从两个信封中随机地抽取一个信封，看里边的钱数 $X$ 的值。当 $X$ 的值比 $Z$ 的上限 $\overline{z}$ 大的时候，你可以肯定你拿到的信封里的钱数是比较多的，因此你不必换信封。若你拿到的钱数等于 $\underline{z}$ 的值，那么你可以肯定另一个信封中的钱是比 $\underline{z}$ 多，因此你必须换信封。大致上可以这么说，如果你知道X的值域和X的值的可能性，你就能判断在信封A中的钱数X是相对比较小的还是比较大的，然后相应的做出选择。 从数学上，采用一个准确的概率模型，我们一定能够找到 $X$ 和 $Y$ 的联合概率函数。$X$ 和 $Y$ 的联合概率分可由两个信封中的钱的最小者 $Z$ 的分布律为 $P_Z$，则对一切 $z$，$p_{X,Y}(mz,z)=p_{X,Y}(z,mz)=\frac{1}{2}p_Z(z)$ ，对于不具有 $(mz, z)$ 或 $(z,mz)$ 的形式的 $(x,y)$ ，$p_{X,Y}(x,y)=0$。 当 $p_{X,Y}(x,y)$ 给定以后，我们可以用这个换信封的规则：换信封的充要条件为 $E[Y|X=x]&gt;x$ ，按照这个规则可以确定换或者不换信封。 现在的问题是：按照上诉的模型和转换规则是否可以按照某些x的值，转换信封，而另一些x的值不能换？一般情况下是可以的，例如早先局出的 $Z$ 的值域为有界集合的情况，就可以实现这样的转换规则。然而，下面的一个稍显怪癖的例子，使得你总是换信封： ​抛掷一枚均匀的硬币，直到出现正面为止。记 $N$ 为抛掷硬币的次数。此时你将 $m^N$ 元放进一个信封内，将 $m^{N-1}$ 元放进另一个信封内。令 $X$ 是你打开的那个信封（信封A）内的钱数， $Y$ 是令一个信封（信封 B）内的钱数。现在假定 A 中只有一元钱，显然 B 中含有 $m$元， 你应该换信封。当 A 内含有 $m^n$ 元的时候，B 中或者含有 $m^{n-1}$ 元钱或含有 $m^{n+1}$ 元钱。由于 $N$ 具有几何分布列， 我们有： $$\frac{P(Y=m^{m+1} | X=m^n)}{P(Y=m^{m-1} | X=m^n)} = \frac{P(Y=m^{m+1}, X=m^n)}{P(Y=m^{m-1}, X=m^n)}=\frac{P(N=n+1)}{P(N=n)}=\frac{1}{2}$$ 这样我们有: $$P(Y=m^{m-1}|X=m^n)=\frac{2}{3}，P(Y=m^{m+1}|X=m^n)=\frac{1}{3}$$ $$E\{信封B中的钱数|x=m^n\}=\frac{2}{3}m^{n-1}+\frac{1}{3}m^{n+1}=\frac{2+m^2}{3m}\cdot m^n$$ $\frac{2+m^2}{3m}&gt;1$ 的充要条件是 $m^2-3m + 2 &gt; 0$ 或 $(m-1)(m-2)&gt;0$。 若 $m&gt;2$， 则： $$E[信封 B 中的钱数 | X=m^n]&gt;m^n$$ 这样，为了获得最大的期望奖金，你应该转向信封 $B$。在这个例子中，由于对一切 $x$ 的值， $$E[Y|X=x]&gt;x$$ 你选择B。直观地看，利用全期望定理，应该有结论 $E[Y]&gt;E[X]$ 。然而，由于 $X$ 和 $Y$ 具有相同的概率函数（PMFs，probability mass function (PMF) ），结论$E[Y]&gt;E[X]$ 不可能成立。实际上，我们有： $$E[Y]=E[X]=\infty$$ 这个结论与 $E[Y|X=x]&gt;x, \forall x$ 并不矛盾。当 $E[Y]=E[X]=\infty$ 的情况下，利用关系式 $E[Y|X=x] &gt; x$ 而转换信封并不能够改进平均奖金。从而解决了悖论问题。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典摘录-几何随机变量的均值和方差]]></title>
    <url>%2F2017%2F08%2F23%2Fmean_and_variance_of_the_geometric%2F</url>
    <content type="text"><![CDATA[本文摘录自 Introduction to probability, 2nd Edition Example 2.17 mean_and_variance_of_the_geometric 你一次又一次地写一个计算机软件，每写一次都有一个成功的概率 $p$ 。假设每次成功与否与以前的历史记录相互独立。令 $X$ 是你一直到成功为止所写的次数（最后一次你成功了！） $X$ 的期望和方差是多少？ 由于 $X$ 是一个几何随机变量，那么我们视 $X$ 为几何随机变量，概率质量函数是： $$p_X(k)=(1-p)^{k-1}p, k = 1, 2, ….$$ 那么 $X$ 的方差和均值为： $$E[X] = \sum\limits_{k=1}^{\infty}k(1-p)^{k-1}p, var(X)=\sum\limits_{k=1}^{\infty}(k-E[X])^2(1-p)^{k-1}p$$ 但是衡量这些无限和有点麻烦。我们利用全期望定理进行计算。记 $A_1=\{X=1\}=\{\text{first try is a success}\}, A_2=\{X&gt;1\}=\{\text{first try is a failure}\}$。 如果第一次就成功，得到 $X=1​$ ，且 $$E[X|X=1]=\sum\limits_{}^{}xp_{X|X=1}=1p_{1|X=1}=1$$ 如果首次尝试失败 ( X &gt; 1)，我们将浪费一次尝试，我们重新开始，由于是在第一次失败的条件下，那么表示尝试次数的 $X$ 的均值一定是大于1的，剩余尝试的期望即 $E[X]$ 。 $$E[X|X&gt;1] = E[X+1] = 1+E[X]$$ 因此，由全期望定理： $$\begin{eqnarray}E[X] &amp;=&amp; P[X=1]E[X|X=1]+P(X&gt;1)E[X|X&gt;1] \\&amp;=&amp; p + (1 - p) (1+E[X])\end{eqnarray}$$从而可以得到： $$E[X]=\frac{1}{p}$$ 相似的推理，我们也得到 $$E[X^2|X=1]=1,\quad E[X^2|X&gt;1]=E[(1+X)^2]=1+2E[X]+E[X^2]$$ 因此， $$E[X^2]=p+(1-p)(1+2E[X]+E[X^2])$$ 联合 $E[X]=\frac{1}{p}$ 得到： $$E[X^2]=\frac{2}{p^2}-\frac{1}{p}$$ 总结： $$var(X)=E[X^2]-(E[X])^2= \frac{2}{p^2}-\frac{1}{p}-\frac{1}{p^2}=\frac{1-p}{p^2}$$]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[转载-LaTeX各种符号]]></title>
    <url>%2F2017%2F08%2F20%2FLaTeX_symbols%2F</url>
    <content type="text"><![CDATA[根据左侧文章目录，快速定位想要的符号 声调 语法 效果 语法 效果 语法 效果 \bar{x} \acute{\eta} \check{\alpha} \grave{\eta} \breve{a} \ddot{y} \dot{x} \hat{\alpha} \tilde{\iota} 函数 语法 效果 语法 效果 \sin\theta \cos\theta \arcsin\frac{L}{r} \arccos\frac{T}{r} \sinh g \cosh h \operatorname{sh}j \operatorname{argsh}k \operatorname{argch}l \operatorname{th}i k’(x)=\lim_{\Delta x\to 0}\frac{k(x)-k(x-\Delta x)}{\Deltax} \limsup S \max H \min L \sup t \exp!t \lg X \log X \ker x \deg x \Pr x \det x \arg x \dim x \tan\theta \arctan\frac{L}{T} \tanh i \operatorname{ch}h \operatorname{argth}m \liminf I \inf s \ln X \log_\alpha X \gcd(T,U,V,W,X) \hom x \lim_{t\to n}T 同余 语法 效果 语法 效果 \pmod{m} a \bmod b 微分 语法 效果 语法 效果 语法 效果 \nabla \partial x \mathrm{d}x \dot x \ddot y 集合 语法 效果 语法 效果 语法 效果 语法 效果 语法 效果 \forall \exists \empty \emptyset \varnothing \in \ni \not\in \notin \subset \subseteq \supset \supseteq \cap \bigcap \cup \bigcup \biguplus \sqsubset \sqsubseteq \sqsupset \sqsupseteq \sqcap \sqcup \bigsqcup 逻辑 语法 效果 语法 效果 语法 效果 语法 效果 p \land \wedge \bigwedge \bar{q} \to p \lor \vee \bigvee \lnot \neg q \setminus \smallsetminus 根号 语法 效果 语法 效果 \sqrt{3} \sqrt[n]{3} 关系符号 语法 效果 \Delta ABC\sim\Delta XYZ \sqrt{3}\approx1.732050808\ldots \simeq \cong \dot= \ggg \gg &gt; \ge \geqq = \leq \leqq &lt; \ll \lll (x-y)^2\equiv(-x+y)^2\equiv x^2-2xy+y^2 x\not\equiv N x\ne A x\neq C t\propto v \pm \mp 因为所以123456789101112\begin&#123;align&#125;\because\begin&#123;cases&#125;\acute&#123;a&#125;x^2+bx^2+c\gtrless0\gtrless\grave&#123;a&#125;x^2+bx^2+c\\\acute&#123;a&#125;&gt;0&gt;\grave&#123;a&#125;\end&#123;cases&#125;\\\therefore\frac&#123;-b\pm\sqrt&#123;b^2-4\acute&#123;a&#125;c&#125;&#125;&#123;2\acute&#123;a&#125;&#125;&#123;&#125;_\lessgtr^\gtrlessx_\lessgtr^\gtrless\frac&#123;-b\pm\sqrt&#123;b^2-4\grave&#123;a&#125;c&#125;&#125;&#123;2\grave&#123;a&#125;&#125;\end&#123;align&#125; ​ 几何符号 特征 语法 效果 菱形 \Diamond 正方形 \Box 三角形 Delta \Delta 图型 \triangle 角名 \angle\Alpha\Beta\Gamma 角度 \sin\!\frac{\pi}{3}=\sin60^\operatorname{\omicron}=\frac{\sqrt{3}}{2} 垂直 \perp 箭头符号 语法 效果 语法 效果 语法 效果 \leftarrow \gets \rightarrow \to \leftrightarrow \longleftarrow \longrightarrow \mapsto \longmapsto \hookrightarrow \hookleftarrow \nearrow \searrow \swarrow \nwarrow \uparrow \downarrow \updownarrow 语法 效果 语法 效果 语法 效果 语法 效果 \rightharpoonup \rightharpoondown \leftharpoonup \leftharpoondown \upharpoonleft \upharpoonright \downharpoonleft \downharpoonright 语法 效果 语法 效果 语法 效果 \Leftarrow \Rightarrow \Leftrightarrow \Longleftarrow \Longrightarrow \Longleftrightarrow (or \iff) \Uparrow \Downarrow \Updownarrow 特殊符号 语法 效果 语法 效果 语法 效果 语法 效果 语法 效果 语法 效果 \eth \S \P \% \dagger \ddagger \star * \ldots \smile \frown \wr 语法 效果 语法 效果 语法 效果 \oplus \bigoplus \otimes \bigotimes \times \cdot \div \circ \bullet \bigodot \boxtimes \boxplus 语法 效果 语法 效果 语法 效果 语法 效果 \triangleleft \triangleright \infty \bot \top \vdash \vDash \Vdash \models \lVert \rVert 语法 效果 语法 效果 语法 效果 \imath \hbar \ell \mho \Finv \Re \Im \wp \complement 语法 效果 语法 效果 语法 效果 语法 效果 \diamondsuit \heartsuit \clubsuit \spadesuit \Game \flat \natural \sharp 上标、下标及积分等 功能 语法 效果 上标 a^2 下标 a_2 组合 a^{2+2} a_{i,j} 结合上下标 x_2^3 前置上下标 {}_1^2\!X_3^4 导数（HTML） x&#39; 导数（PNG） x^\prime 导数（错误） x\prime 导数点 \dot{x} \ddot{y} 向量 \vec{c} \overleftarrow{a b} \overrightarrow{c d} \widehat{e f g} 上弧(注: 正确应该用 \overarc, 但在这里行不通。要用建议的语法作为解决办法) \overset{\frown} {AB} 上划线 \overline{h i j} 下划线 \underline{k l m} 上括号 \overbrace{1+2+\cdots+100} \begin{matrix} 5050 \\ \overbrace{ 1+2+\cdots+100 }\end{matrix} 下括号 \underbrace{a+b+\cdots+z} \begin{matrix} \underbrace{ a+b+\cdots+z } \\ 26\end{matrix} 求和 \sum_{k=1}^N k^2 \begin{matrix} \sum_{k=1}^N k^2 \end{matrix} 求积 \prod_{i=1}^N x_i \begin{matrix} \prod_{i=1}^N x_i \end{matrix} 上积 \coprod_{i=1}^N x_i \begin{matrix} \coprod_{i=1}^N x_i\end{matrix} 极限 \lim_{n \to \infty}x_n \begin{matrix} \lim_{n \to \infty}x_n\end{matrix} 积分 \int_{-N}^{N} e^x\, dx \begin{matrix} \int_{-N}^{N} e^x\, dx\end{matrix} 双重积分 \iint_{D}^{W} \, dx\,dy 三重积分 \iiint_{E}^{V} \, dx\,dy\,dz 四重积分 \iiiint_{F}^{U} \, dx\,dy\,dz\,dt 闭合的曲线、曲面积分 \oint_{C} x^3\, dx + 4y^2\, dy 交集 \bigcap_1^{n} p 并集 \bigcup_1^{k} p 分数、矩阵和多行列式 字体希腊字母斜体小写希腊字母一般用于在方程中显示变量。 正体希腊字母 特征 语法 效果 注释/外部链接 大写字母 \Alpha \Beta \Gamma \Delta \Epsilon \Zeta \Eta\Theta ΑΒ Γ ΔΕ Ζ ΗΘ \Iota \Kappa \Lambda \Mu \Nu \Xi \Omicron \Pi ΙΚ Λ ΜΝ Ξ ΟΠ \Rho \Sigma \Tau \Upsilon \Phi \Chi \Psi\Omega ΡΣ Τ ΥΦ Χ ΨΩ 小写字母 \alpha \beta \gamma \delta \epsilon \zeta \eta\theta \iota \kappa\varkappa \lambda \mu \nu \xi \omicron\pi \rho \sigma \tau \upsilon \phi \chi \psi\omega 异体字母 \Epsilon\epsilon\varepsilon \Theta\theta\vartheta \Kappa\kappa\varkappa \Pi\pi\varpi \Rho\rho\varrho \Sigma\sigma\varsigma \Phi\phi\varphi 已停用字母 \digamma Ϝ[1] 粗体希腊字母 特征 语法 效果 大写字母 \boldsymbol{\Alpha \Beta \Gamma \Delta \Epsilon \Zeta\Eta \Theta} \boldsymbol{\Iota \Kappa \Lambda \Mu \Nu \Xi \Omicron\Pi} \boldsymbol{\Rho \Sigma \Tau \Upsilon \Phi \Chi \Psi\Omega} 小写字母 \boldsymbol{\alpha \beta \gamma \delta \epsilon \zeta\eta \theta} \boldsymbol{\iota \kappa \lambda \mu \nu \xi \omicron\pi} \boldsymbol{\rho \sigma \tau \upsilon \phi \chi \psi\omega} 异体字母 \boldsymbol{\Epsilon\epsilon\varepsilon} \boldsymbol{\Theta\theta\vartheta} \boldsymbol{\Kappa\kappa\varkappa} \boldsymbol{\Pi\pi\varpi} \boldsymbol{\Rho\rho\varrho} \boldsymbol{\Sigma\sigma\varsigma} \boldsymbol{\Phi\phi\varphi} 已停用字母 \boldsymbol{\digamma} 黑板粗体 语法 \mathbb{ABCDEFGHIJKLMNOPQRSTUVWXYZ} 效果 黑板粗体（Blackboardbold）一般用于表示数学和物理学中的向量或集合的符号。 备注： 花括号中只有使用大写拉丁字母才能正常显示，使用小写字母或数字会得到其他符号。 正粗体 语法 \mathbf{012…abc…ABC…} 效果 备注 花括号{}内只能使用拉丁字母和数字，不能使用希腊字母如\alpha等。斜粗体 语法 \boldsymbol{012…abc…ABC…\alpha \beta\gamma…} 效果 备注 使用\boldsymbol{}可以加粗所有合法的符号。 斜体数字 语法 \mathit{0123456789} 效果 罗马体 语法 \mathrm{012…abc…ABC…}或\mbox{}或\operatorname{} 效果 备注 罗马体可以使用数字和拉丁字母。 哥特体 语法 \mathfrak{012…abc…ABC…} 效果 备注 哥特体可以使用数字和拉丁字母。 手写体 语法 \mathcal{ABC…} 效果 备注 手写体仅对大写拉丁字母有效。 希伯来字母 语法 \aleph\beth\gimel\daleth 效果 括号 功能 语法 显示 不好看 ( \frac{1}{2} ) 好看了 \left( \frac{1}{2} \right) 您可以使用 \left 和 \right 来显示不同的括号： 空格注意TEX能够自动处理大多数的空格，但是您有时候需要自己来控制。 功能 语法 显示 宽度 2个quad空格 \alpha\qquad\beta quad空格 \alpha\quad\beta 大空格 \alpha\ \beta 中等空格 \alpha\;\beta 小空格 \alpha\,\beta 没有空格 \alpha\beta 紧贴 \alpha\!\beta 颜色小型数学公式当要把分数等公式放进文字中的时候，我们需要使用小型的数学公式。 苹果原产于欧洲和中亚细亚。哈萨克的阿拉木图与新疆阿力麻里有苹果城的美誉。中国古代的林檎、柰、花红等水果被认为是中国土生苹果品种或与苹果相似的水果。苹果在中国的栽培记录可以追溯至西汉时期，汉武帝时，10的 是2。上林苑中曾栽培林檎和柰，当时多用于薰香衣裳等，亦有置于床头当香熏或置于衣服初作为香囊，总之一般不食用。但也有看法认为，林檎和柰是现在的沙果，曾被误认为苹果，真正意义上的苹果是元朝时期从中亚地区传入中国，当时只有在宫廷才可享用。并不好看。 苹果原产于欧洲和中亚细亚。哈萨克的阿拉木图与新疆阿力麻里有苹果城的美誉。中国古代的林檎、柰、花红等水果被认为是中国土生苹果品种或与苹果相似的水果。苹果在中国的栽培记录可以追溯至西汉时期，汉武帝时，10的 是2。上林苑中曾栽培林檎和柰，当时多用于薰香衣裳等，亦有置于床头当香熏或置于衣服初作为香囊，总之一般不食用。但也有看法认为，林檎和柰是现在的沙果，曾被误认为苹果，真正意义上的苹果是元朝时期从中亚地区传入中国，当时只有在宫廷才可享用。 好看些了。 可以使用 1\begin&#123;smallmatrix&#125;...\end&#123;smallmatrix&#125; 或直接使用 模板。 1&#123;&#123;Smallmath|f= f(x)=5+\frac&#123;1&#125;&#123;5&#125; &#125;&#125; 强制使用PNG假设我们现在需要一个PNG图的数学公式。 若输入 2x=1 的话： 这并不是我们想要的。 若你需要强制输出一个PNG图的数学公式的话，你可于公式的最后加上 \, （小空格，但于公式的最后是不会显示出来）。若输入 2x=1 \,的话：$2x=1 \,$ 是以PNG图输出的。你也可以使用 \,\!，这个亦能强制使用PNG图像。 阅读更多︰Help:Displayinga formula#Forced PNG rendering 本文的 巨人的肩膀 https://blog.csdn.net/garfielder007/article/details/51646604 http://zh.wikipedia.org/wiki/Help:MATH http://blog.csdn.net/anxiaoxi45/article/details/39449445]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Latex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Trees describe the sample space]]></title>
    <url>%2F2017%2F08%2F15%2Ftrees_describe_the_sample_space%2F</url>
    <content type="text"><![CDATA[This note comes from Introduction to Probability, 2nd Edition Example 1.9 Rada DetectionIf an aircraft is present in a certain area, a radar detects it and generates an alarm signal with probability 0.99. If an aircraf is not present. the radar generates a (false) alarm, with probability 0.10. We assume that an aircraft is present with probability 0.05. What is the probability of no aircraf presence and a false alarm? What is the probability of aircraf presence and no detection? $A$ sequential representation of the experiment is appropriate here, as shown in Fig. 1.9. Let $A$ and $B$ be the events $A = \{an\ aircraft\ is\ present\}$, $B = \{the\ radar\ generates\ an\ alarm\} $, and consider also their complements $A^c=\{an\ aircraft\ is\ not present\}$$，$$B^c=\{the\ radar\ does\ not\ generate\ an\ alarm\}$。 The given probabilities are recorded along the corresponding branches of the tree describing the sample space, as shown in Fig. 1.8. Each event of interest corresponds to a leaf of the tree and its probability is equal to the product of the probabilities associated with the branches in a path from the root to the corresponding leaf. The desired probabilities of false alarm and missed detection are $$P(false\ alarm) = P(A^c ∩ B) = P(A^c)P(B | A^c) = 0.95 · 0.10 = 0.095$$，$$P(missed\ detection) = P(A ∩ B^c) = P(A)P(B^c | A) = 0.05 · 0.01 = 0.0005$$. Extending the preceding example, we have a general rule for calculating various probabilities in conjunction with a tree-based sequential description of an experiment. In particular: (a) We set up the tree so that an event of interest is associated with a leaf. We view the occurrence of the event as a sequence of steps, namely, the traversals of the branches along the path from the root to the leaf. (b) We record the conditional probabilities associated with the branches of the tree. (c) We obtain the probability of a leaf by multiplying the probabilities recorded along the corresponding path of the tree. multiplication ruleIn mathematical terms, we are dealing with an event A which occurs if and only if each one of several events $A_1, . . . , A_n$ has occurred, i.e., $A = A_1 ∩ A_2 ∩ · · · ∩ A_n$. The occurrence of $A$ is viewed as an occurrence of $A_1$, followed by the occurrence of $A_2$, then of $A_3$, etc, and it is visualized as a path on the tree with $n$ branches, corresponding to the events $A_1, . . . , A_n$. The probability of $A$ is given by the following rule (see also Fig. 1.9). The multiplication rule can be verified by writing$$P(\cap^n_{i=1} A_i)=P(A_1)\frac{P(A_1\cap A_2)}{P(A_1)}\frac{P(A_1\cap A_2\cap A_3)}{P(A_1\cap A_2)}\cdots\frac{P(\cap_{i=1}^n A_i)}{P(\cap^{n-1}_{i=1} A_i)}$$, and by using the definition of conditional probability to rewrite the right-hand side above as $$P(A_1)P(A_2|A_1)P(A_3|A_1\cap A_2)\cdots P(A_N|\cap^{n-1}_{i=1} A_i)$$. The intersection event $A = A_1∩A_2∩· · ·∩A_n$ is associated with a path on the tree of a sequential description of the experiment. We associate the branches of this path with the events $A_1, . . . , A_n$, and we record next to the branches the corresponding conditional probabilities. The final node of the path corresponds to the intersection event $A$, and its probability is obtained by multiplying the conditional probabilities recorded along the branches of the path $$P(A_1\cap A_2\cap\cdots\cap A_3)=P(A_1)P(A_2|A_1)\cdots P(A_n|A_1\cap A_2\cdots \cap A_{n-1}).$$ Note that any intermediate node along the path also corresponds to some intersection event and its probability is obtained by multiplying the corresponding conditional probabilities up to that node. For example, the event $A_1 ∩ A_2 ∩ A_3$ corresponds to the node shown in the figure, and its probability is $$P(A_1\cap A_2\cap A_3)=P(A_1)P(A_2|A_1)P(A_3|A_1\cap A_2).$$ For the case of just two events, A1 and A2, the multiplication rule is simply the definition of conditional probability.]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[期望定义的由来]]></title>
    <url>%2F2017%2F08%2F14%2Fdefinition_of_expectation%2F</url>
    <content type="text"><![CDATA[前言我们很早就学到某个随机变量$X$的期望就是$X$的所有取值相对于它的概率的加权平均， 但是这是为什么呢？很多人都有疑问，后来看了MIT教授写的 Introduction to Probability, 2nd Edition 书，豁然开朗，以此小计一篇。 例子我们先以一个例子入手：假设你有机会转动一个幸运轮许多次，每次转动后幸运轮都会出现一个数字（数字即奖金数），不妨设为$m_i, i$表示第$i$次转动幸运轮，而且这些数字出现的概率分别为$p_i$，那么每次你期望得到的奖金数是多少呢？此处“每次”和”期望“都是一些不确定的词汇，我们来一一明确它们的含义。 假设一共转动幸运轮$k$次，而其中有$k_i$次转动的结果为$m_i$。你所得到的总钱数为：$\sum\limits_{i=1}^{n}m_i k_i$，那么每次转动的钱数为$M=\frac{\sum\limits_{i=1}^{n}{m_i k_i}}{k}$，现在假设$k$是一个很大的数字，那么我们可以假设概率与频率相互接近。即： $$\frac{k_i}{k}\approx p_i, i=1,\ldots,n$$ 这样你每次转动幸运轮所期望得到的钱数是： $$M=\frac{\sum\limits_{i=1}^{n}m_i k_i}{k}\approx \sum\limits_{i=1}^{n}m_i p_i$$ 有这个例子启发，才有了下面的定义。 期望的定义设随机变量$X$的概率函数是$p_X$，那么$X$的期望值（也称期望或均值）为： $$E[X]=\sum\limits_{x}xp_X(x)$$ 虽然内容较为简单，但是用频率接近概率进而引进概率的定义是很常见的思路，有了这个过程我们对期望才有了很直观的理解。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>probability</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[复数与复矩阵]]></title>
    <url>%2F2017%2F08%2F12%2Fcomplex_and_complex_matrix%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第12讲：复数与复矩阵 之前接触的大部分线性代数知识都只考虑实数情形，但复数情形不可避免会遇到。例如$\begin{pmatrix}cos\theta&amp;-sin\theta\\sin\theta&amp;cos\theta\end{pmatrix}$没有实特征值（除了极特殊情形），目的：比较实数和复数情形的异同，注意学习复数和实数的区别联系。 复数复习 $i^2=-1$， 一个复数$a+bi=z$，$a$是实部(real part)，$b$是虚部(imaginary part)，可以把实部$a$看成x轴分量，虚部$b$看成y轴分量。复数的共轭(complex conjugate) $z=a+bi\rightarrow \bar{z}=a-bi$，长度 $|z|=\sqrt{a^2+b^2}=(a-bi)(a+bi)=z\bar{z}$（$z$的长度不能定义为$\sqrt{(a+bi)^2}$，长度必须是正值，如果把复数$z$看成一个2维向量，那么它的长度显然就是定义中给出的）， 矩阵的共轭定义为： $A=(a_{ij})_{n\times n}, a_{ij}\in C \rightarrow \bar{A}=(\overline{a_{ij}})_{n\times n}$，性质：$\overline{AB}=\bar{A}\bar{B}\ z\bar{z}=|z|^2$。 {长度为1（单位圆上）的复数}$\rightarrow${二阶旋转矩阵}，且保持乘法。$z=cos\theta+isin\theta\rightarrow A_2=\begin{pmatrix}cos\theta&amp;-sin\theta\\sin\theta&amp;cos\theta\end{pmatrix}$。验证性质：$z_1=e^{i\theta_1},z_2=e^{i\theta_2}\rightarrow A_{z_1}=\begin{pmatrix}cos\theta&amp;-sin\theta\\sin\theta&amp;cos\theta\end{pmatrix}, A_{z_2}=\begin{pmatrix}cos\theta&amp;-sin\theta\\sin\theta&amp;cos\theta\end{pmatrix}\\\rightarrow z_1z_2=e^{i(\theta_1+\theta_2)}=\begin{pmatrix}cos(\theta_1+\theta_2)&amp;-sin(\theta_1+\theta_2)\\sin(\theta_1+\theta_2)&amp;cos(\theta_1+\theta_2)\end{pmatrix}=A_{z_1z_2}$ 欧拉公式(Euler formula) ：$e^{i\theta}=cos\theta+isin\theta$，极分解(polar decomposition)： $z=re^{i\theta}=r(cos\theta+isin\theta)\rightarrow z^n=r^ne^{in\theta}=r^n(cos(n\theta)+isin(n\theta)) $，这里z的公式中三角函数部分长度为1，所以r即z的长度，这样任何一个复数都可以用$re^{i\theta}$表示。 单位根$x^n=1$有n个复根$e^{2k\pi i\over n}, k=0,1,2,\ldots,n-1$，令$\omega=e^{2\pi i\over n}\rightarrow 1+\omega+\omega^2+\cdots+\omega^{n-1}=0$，例如：求$(1+i)^8\leftarrow1+i=\sqrt{2}e^{i{\pi\over 4}}, (1+i)^8={(\sqrt{2})}^8e^{i2\pi}=16$。$\frac{x^{2n+1}-1}{x-1}$。 代数基本定理：$a_nx^n+\cdots+a_1x+a_0=0, a_i\in C$有n个复数根(可能重复)，设$a_i\in R, a_nx^n+\cdots+a_1x+a_0=0$ 的非实数的复根也是成对出现，即若$z=a+bi(b\ne0)$是它的根，则$\bar{z}=a-bi$也是它的根，复数根是成对出现的。$\Rightarrow$ 奇次实系数方程总有一个实根。（注：公开课字幕内容如下：因为我们知道复根是成对出现的，所以对一个实系数方程，它的复根实际上是2的倍数，因为它是成对出现的，但是奇数次实系数呢，所以它必然除了复根应该有一个实根，不然的话它只有偶数的根，这样就跟它奇数次矛盾）。 实系数多项式（次数$\ge 1$）的$f(x)$可分解成$f(x)=a(x-\lambda_1)^{n_1}\cdots(x-\lambda_s)^{n_s}(x^2-b_1x+c)^{e_1}\cdots(x^2-b_tx+c)^{e_{t}}$，$\lambda_i$即实数根，后$t$项即复数根给出来的，后面这种形式无法写成实根的一次形式，也就是它的判别式小于0（有复数根），不能写成前$s$项的形式。例如：$x^m-1=\prod\limits_{k=0}^{m-1}(x-\omega_k), \omega_k=e^{i2k\pi\over m}$$\omega_{m-k}=e^{i2(m-k)\pi\over m}=e^{i{2\pi(1-{k\over m})}}=cos(2\pi(1-{k\over m}))+isin(2\pi(1-{k\over m}))=cos({2k\pi\over m})-isin({2k\pi\over m})=\overline{\omega_k}, \\ {k\over m} &lt;1\Rightarrow (x-\omega_k)(x-\omega_{m-k})=x^2-(\omega_k+\omega_{m-k})x+(\omega_k\omega_{m-k})=x^2-2cos({2k\pi\over m}x)+1$， 同理可得：$x^m+1=\prod\limits_{k=0}^{m-1}(x-\xi_k), \xi_k=e^{i(\pi+2k\pi)\over m}$ 。 例题：证明$cos{\pi\over 2n+1}cos{2\pi\over 2n+1}\cdots cos{n\pi\over 2n+1}={1\over 2^n}$要证明这个需要以下3点： (1)$-1-e^{i2\theta}=-1-cos2\theta-isin2\theta=-2cos\theta(cos\theta+isin\theta)\Rightarrow |-1-cos2\theta-isin2\theta|=2|cos\theta|$ (2)设$\omega=cos{2\pi\over 2n+1}+isin{2\pi\over 2n+1}=e^{i2{\pi\over 2n+1}}\Rightarrow|-1-\omega|=2|cos({\pi\over {2n+1}})|$，那么$x^{2n}+x^{2n-1}+\cdots+1=(x-\omega)(x-\omega^2)\cdots(x-\omega^{2n})\quad (*)$ 推导如下：${x^{2n+1}-1}=(x-1)(x-\omega)(x-\omega^2)\cdots(x-\omega^{2n})\Rightarrow \frac{x^{2n+1}-1}{x-1}=(x-\omega)(x-\omega^2)\cdots(x-\omega^{2n})\\\Rightarrow {1(1-x^{2n+1})\over {1-x}}=(x-\omega)(x-\omega^2)\cdots(x-\omega^{2n})$ (3)$cos{(2n+1-k)\pi\over 2n+1}=cos{k\pi\over 2n+1}$令$(*)$等式中$x=-1$，且取两边长度$1=|(-1-\omega)(-1-\omega^2)\cdots(-1-\omega^{2n})$中右边每一项利用(1)式子得到$|-1-\omega|=2|cos{\pi\over {2n+1}}|,\\ |-1-\omega^2|=2|cos{2\pi\over {2n+1}}|,\\\ldots\|-1-\omega^n|=2|cos{n\pi\over {2n+1}}|$ 从n+1项起根据(3)得： $$|-1-\omega^{n+1}|=2|cos{(n+1)\pi\over {2n+1}}|=2|cos{(2n+1-n)\pi\over {2n+1}}|=2|cos(\pi-{n\pi\over {2n+1}})|=2|cos({n\pi\over {2n+1}})|=|-1-\omega^n|$$ $$|-1-\omega^{n+2}|=2|cos{(n+2)\pi\over {2n+1}}|=2|cos{[(2n+1)-(n-1)]\pi\over {2n+1}}|=2|cos(\pi-{(n-1)\pi\over {2n+1}})|=2|cos{(n-1)\pi\over {2n+1}}|=|-1-\omega^{n-1}|$$$$\cdots\cdots$$ $|-1-\omega^{2n}|=2|cos{2n\pi\over {2n+1}}|=2|cos{(2n+1-1)\pi\over {2n+1}}|=2|cos(\pi-{\pi\over {2n+1}})|=2|cos({\pi\over {2n+1}})|=|-1-\omega|$ 复矩阵Hermitian矩阵复数矩阵$A=(a_{ij})_{m\times n},a_{ij}\in C$, 那么称$\overline{A^T}(=\bar{A}^T)$ 为 Hermitian 矩阵，记为$A^H$。例如： $Z=\begin{pmatrix}1+i\\i\end{pmatrix}\rightarrow Z^H=\begin{pmatrix}1-i&amp;-i\end{pmatrix}$，而且发现$ZZ^H=||Z||^2$，这个可以类比实数中的$x^Tx=||x||^2$。性质：$(A^H)H=A, (AB)^H=B^HA^H$（按照共轭转置即可求得），正如在$R^n$的定义内积，在$C$上也可以定义内积：$u,v\in C^n, u^Hv=(\bar{u}_1\cdots\bar{u}_n)\begin{pmatrix}v_1\\\vdots\\v_n\end{pmatrix}=\bar{u}_1v_1+\cdots+\bar{u}_nv_n$，内积的性质：$u^Hv=\overline{v^Hu}$。 厄米特Hermite矩阵在实数矩阵中有对称矩阵的概念和作用，复数矩阵有类似的——厄米特矩阵(Hermite matrix)，定义为：$A=A^H$，即一个矩阵的共轭转置等于它本身，那么称这种矩阵为Hermite阵。例：$\begin{pmatrix}2&amp;1+i\\1-i&amp;3\end{pmatrix}$。 性质1：Hermite阵对角线元素为实数。 性质2：$z\in C, A=A^H\Rightarrow z^HAz$ 是一个实数。证明如下：${\overline{z^HAz}}^T=(z^HAz)^H=z^HA^Hz=z^HAz$ 性质3：设$A,B$是Hermite阵，则$A+B$也是，证明：$(A+B)^H=A^H+B^H=A+B$。进一步，若$AB=BA$（即乘法可交换的时候），则$AB$是Hermite阵。$\Rightarrow A^n$是Hermite阵。 性质4：设$A$是一个$n$阶复矩阵，$AA^H, A+A^H$是Hermite阵，联系对比实对称矩阵的$AA^T, A^TA, A+A^T$。 性质5：一个Hermite矩阵A的特征值是实数。证明：设$Az=\lambda_0z$，则$z^HAz=\lambda_0z^Hz$。$z^HAz$和$z^Hz$均为实数$\Rightarrow \lambda_0 (z_0\ne 0)$是实数。 性质6：一个Hermite阵的不同特征值的特征向量相互正交。证明：设$(1) Az_1=\lambda_1z_1, (2) Az_2=\lambda_2z_2, \lambda_1 \ne \lambda_2$， 在(1)两边同乘以$z_2^H$得：$(3)z_2^HAz_1=z_2^H\lambda_1z_1 \Rightarrow (4)z_2^HA^Hz_1=(Az_2)^Hz_1=\overline{\lambda_2}z_2^Hz_1=\lambda_2z_2^Hz_1$，由$(3)(4)\Rightarrow \lambda_1z_2^Hz_1=\lambda_2z_2^Hz_1\Rightarrow (\lambda_1-\lambda_2)z_2^Hz_1=0$，因为$\lambda_1\ne \lambda_2$得：$z_2^Hz_1=0$。 酉unitary矩阵酉矩阵是正交阵的复数类比。$U_{n\times n}$是酉矩阵$\Leftrightarrow$ $\forall z\in C^n, ||Uz||=||z||$，证明：$U^HU=I_n\Rightarrow |U z|^2=z^HU^HUz = z^Hz=|z|^2\Rightarrow |Uz|=|z|\Rightarrow |\lambda|=1$ 。得出与实数矩阵类似的性质1：酉矩阵乘以任何向量不改变它的模长。性质2：$U$是酉矩阵，则$U$的特征值模长为1。 例：$u=\begin{pmatrix}{1\over \sqrt{2}}&amp;-\frac{1}{\sqrt{6}}&amp;\frac{1-i\sqrt{3}}{2\sqrt{3}}\\\frac{1}{\sqrt{2}}&amp;\frac{1}{\sqrt{6}}&amp;{-1+i\sqrt{3}\over 2\sqrt{3}}\\0&amp;{1+i\sqrt{3}\over \sqrt{6}}&amp;{1\over \sqrt{3}}\end{pmatrix}$ ，$|det U|=\prod{|\lambda_i|}=1$ (行列式的长度等于特征值长度的乘积)。 而实数的正交阵，也有类似的性质。下面证明正交阵不同特征值对应的特征向量相互正交： 因为$Q$正交阵,$Q^TQ=E,|Q|=1=λ_1λ_2\ldotsλ_n$,设$λ_1,λ_2$为$Q$的两个不同的特征值,$ξ_1,ξ_2$为对应的特征向量$ (1)Qξ_1=λ_1ξ_1, (2)Qξ_2=λ_2ξ_2,(3)(ξ_2)^T Q^T=λ_2(ξ_2)^T \Rightarrow (3)(1)\Rightarrow ξ_2^TQ^TQξ_1=λ_1λ_2ξ_2^Tξ_1\Rightarrow \(λ_1λ_2-1)ξ_2^Tξ_1=0$而$|λ_1|=|λ_2|=1,λ_1≠λ_2$,得$ξ2^Tξ1=0,因此ξ_2,ξ_1$正交。 复正规阵酉阵和Hermite矩阵均为复正规矩阵，即：$A^HA=AA^H$。 酉相似：设$A,B$是；两$n$阶复矩阵，若存在酉矩阵$U$，使得$A=U^HBU$，则$A$和$B$是酉相似（联系实数矩阵的正交相似）。定理：设$A$复正规阵，则 向量$u$是$A$的关于$\lambda$的特征向量$\Leftrightarrow u$是$A^H$的关于$\bar{\lambda}$的特征向量。证明：设$Au=\lambda u\Rightarrow (A-\lambda I)u=0$令$B=A-\lambda I\Rightarrow ||B^Hu||^2=u^HBB^Hu=u^HB^HBu=||Bu||^2=0$，因为$||B^Hu||^2=0\Rightarrow B^Hu=0, (A-\lambda I)^H=B^H\Rightarrow (A^H-\bar{\lambda}I)u=0\Rightarrow A^Hu=\bar{\lambda}u$ 不同特征值的特征向量正交。证明与Hermite矩阵一样。 定理(Schur)：任意一个复矩阵$A$酉相似于一个上三角阵。即：$\exists\ U\in $ unitary matrix,$\forall\ A\in$ complex matrix, $U^H=U^{-1}, U^HAU=\begin{pmatrix}\lambda_1&amp;*&amp;* \\0&amp;\ddots&amp;*\\0&amp;0&amp;\lambda_n\end{pmatrix} \Rightarrow$任意一个复正规阵酉相似于对角阵，特别地，酉相似于$\begin{pmatrix}1\\&amp;1\\&amp;&amp;\ddots\\&amp;&amp;&amp;1\end{pmatrix}$, $U^HAU=diag(\lambda_1,\ldots,\lambda_n)\Rightarrow AU=\lambda U$。 一个实矩阵$A$是正规的$\Leftrightarrow A^TA=AA^T$。例如，$A$是正交阵或者$A$是对称（反对称）矩阵。 如果$A$是正规的，那么存在正交阵$\Omega$使得： $\Omega^TA\Omega=\begin{pmatrix}\begin{pmatrix}a_1&amp;b_1 \\ -b_1&amp;a_1\end{pmatrix}\\&amp;\ddots\\&amp;&amp;\begin{pmatrix}a_s&amp;b_s \\ -b_s&amp;a_s\end{pmatrix}\\&amp;&amp;&amp;\lambda_{2s+1}\\&amp;&amp;&amp;&amp;\ddots\\&amp;&amp;&amp;&amp;&amp;\lambda_n\end{pmatrix}$，即实正规阵正交相似于分块对角阵。 对于复正规阵酉相似对角阵$U^HAU=diag(\lambda_1,\ldots,\lambda_n)\Rightarrow AU=\lambda U$，这里如果把$U$的列向量写成$u_k=\beta+i\gamma,\ \ k\in [1,n],\ \beta,\gamma \in R_n$，例如：$\begin{pmatrix}1+i\\1-i\end{pmatrix}=\begin{pmatrix}1\\1\end{pmatrix}+i\begin{pmatrix}1 \\ -1\end{pmatrix}$。 $Au_k=\lambda_ku_k\Rightarrow A(\beta+i\gamma)=\lambda_k(\beta+i\gamma)$，令$\lambda_k=a+ib$，得：$A\beta=a\beta-b\gamma, A\gamma=b\beta+a\gamma\Rightarrow$$A(\beta, \gamma)=(\beta,\gamma)\begin{pmatrix}a&amp;b \\ -b&amp;a\end{pmatrix}$ ，所以$\Omega$的实际上是由$U$的特征向量的实部和虚部组成的这样一个形式。 $\Omega$是一个正交阵，那$\beta$和$\gamma$是不是正交的？它们的长度相等嘛？不然无法保证$\Omega$是一个正交阵。 结论：设$A$是$n$解实正交阵。若$\lambda=a+ib(b\ne 0)$是$A$的特征值，$x=x_1+ix_2,\ x_1,x_2\in R_n$是对应的特征向量，则$||x_1||=||x_2||$，且$x_1,x_2$是相互正交的。 证明：如果$\lambda=a+ib$ 是$A$的特征值，那么$\lambda=a-ib$ 也是$A$的特征值。因为$A$实正交阵，所以对$Ax=\lambda x$取两边共轭得：$\overline{Ax}=A\bar{x}=\bar{\lambda}\bar{x}$。那么得到$\lambda,\bar{\lambda}$都是$A$的特征值，由于正交阵不同特征值对应的特征向量正交，所以${\bar{x}}^Hx=0, x=x_1+ix_2, \bar{x}=x_1-ix_2\Rightarrow ||x_1||=||x_2||, x_1^Tx_2=0$。 例2：证明：$\begin{pmatrix}cos\theta&amp;-sin\theta\\sin\theta&amp;cos\theta\end{pmatrix}​$和$\begin{pmatrix}e^{i\theta}&amp;0\\0&amp;e^{-i\theta}\end{pmatrix}​$ 酉相似。$U={1\over \sqrt{2}}\begin{pmatrix}i&amp;1\\1&amp;i\end{pmatrix}​$ 例3：设$A$是Hermite阵，则$I+iA$是非奇异的。由于A的特征值是实数，那么$I+iA$特征值的是$\lambda i+1$不可能是0，行列式就不可能是0，因此是非奇异的。如果A是Hermite阵，那么$U=(I-iA)(I+iA)^{-1}$是酉阵，验证$U^H=(I-iA)^{-1}(I+iA)=(I+iA)(I-iA)^{-1}$（注：分块是相同的矩阵是可交换即变成分块对角阵），这个是用来通过实对称阵或Hermite阵构造酉矩阵。 离散傅里叶变换DFT回忆若$f(x), f’(x)$是piecewise连续的且$f(x+L)=f(x)$， 则$f(x)=a_0+\sum(a_ncos({2\pi nx\over L})+b_nsin({2\pi nx \over L})), a_n={2\over L}\int_{0}^{L}f(x)cos{2\pi nx \over L}dx,\ b_n={2\over L}\int_{0}^{L}f(x)sin{2\pi nx \over L}dx$， 令$V=\{f(x)|f(x)\text{如上条件}\}\rightarrow R^{\infty}$$f(x)\rightarrow (a_0, a_1, b_1, a_2, b_2,\ldots)$这是一个线性映射，$(a_0, a_1,b_1,\ldots)$是$f(x)$的逆傅里叶变换。 当通过$f(x)$求系数$a_i,b_i,\ldots$即傅里叶变换，当通过系数$a_i,b_i,\ldots$求$f(x)$即逆傅里叶变换。 由前文分析得到傅里叶级数的复形式是$F=\sum\limits_{k=-\infty}^{\infty}c_ke^{ikx}, c_k={1\over 2\pi}\int_{-\pi}^{\pi}f(x)e^{-ikx}dx$，通过变量代换：$x={2\pi \over L}t$ 得：$c_k={1\over L}\int_{-{L\over 2}}^{L\over 2}f(t)e^{-i{2\pi k\over L}t}dt, f(t)=\sum\limits_{k=-\infty}^{+\infty}c_ke^{-i{2\pi k\over L}t}$令$n=k$，则得到新的傅里叶级数复数形式：$f(t)=\sum\limits_{n=-\infty}^{+\infty}c_ne^{-i{2\pi n\over L}t}, c_n={1\over L}\int_{-{L\over 2}}^{L\over 2}f(t)e^{-i{2\pi n\over L}t}dt\quad (1)$令$\omega_n={2\pi n\over L}$得到傅里叶级数的频率形式：$\hat{f}(\omega)=\int_{-\infty}^{+\infty}f(t)e^{i\omega_nt}dt\quad (2)$ 对(1)(2)进行离散化：$f(t_j)=\sum\limits_{k=-\infty}^{+\infty}c_ke^{-i{2\pi k\over L}t_j}$令 $\ t_j={jL\over N}$则得到：$f(t_j)\approx \sum\limits_{k=0}^{N-1}c_ke^{i{2\pi kj\over N}}, c_k={1\over L}\int_{-{L\over 2}}^{L\over 2}f(t_j)e^{i{2\pi kj\over N}}dt_j\quad (1*)$，然后再设置$A_j=f(t_j)，a_k=c_k$得到：$f(t)\rightarrow (A_0,A_1,\cdots, A_{N-1}), (c_k)\rightarrow (a_0,a_1,\cdots, a_{N-1})$。 由上可举N=4的例子：$A_0=f(t_0)=a_{0}e^{i2\pi 00\over 4}+a_1e^{i2\pi 10\over 4}+a_2e^{i2\pi 20\over 4}+a_3e^{i2\pi 30\over 4}=a_{0}+a_1+a_2+a_3=1a_{0}+1a_1+1a_2+1a_3$$A_1=f(t_1)=a_{0}e^{i2\pi 01\over 4}+a_1e^{i2\pi 11\over 4}+a_2e^{i2\pi 21\over 4}+a_3e^{i2\pi 31\over 4}= a_{0}+ia_1-a_2-ia_3=1a_{0}+ia_1+i^2a_2+i^3a_3$$A_2=f(t_2)=a_{0}e^{i2\pi 02\over 4}+a_1e^{i2\pi 12\over 4}+a_2e^{i2\pi22\over 4}+a_3e^{i2\pi 32\over 4} = a_{0}-a_1+a_2-a_3 = 1a_{0}+i^2a_1+i^4a_2+i^6a_3$$A_3=f(t_3)=a_{0}e^{i2\pi 03\over 4}+a_1e^{i2\pi 13\over 4}+a_2e^{i2\pi 23\over 4}+a_3e^{i2\pi 33\over 4}=a_{0}-ia_1-a_2+ia_3=1a_{0}+i^3a_1+i^6a_2+i^9a_3$写成矩阵形式：$\begin{pmatrix}A_0\\A_1\\A_2\\A_3\end{pmatrix}=\begin{pmatrix}1&amp;1&amp;1&amp;1\\1&amp;i&amp;i^2&amp;i^3\\1&amp;i^2&amp;i^4&amp;i^6\\1&amp;i^3&amp;i^6&amp;i^9\end{pmatrix}\begin{pmatrix}a_0\\a_1\\a_2\\a_3\end{pmatrix}$设$F=\begin{pmatrix}1&amp;1&amp;1&amp;1\\1&amp;i&amp;i^2&amp;i^3\\1&amp;i^2&amp;i^4&amp;i^6\\1&amp;i^3&amp;i^6&amp;i^9\end{pmatrix}$，令s表示第s行，t表示第t列，则F的第s行第t列元素为$F_{s,t}=i^{(s-1)(t-1)}$，其实上文中的记号j刚好可以视为行数，k刚好表示列数。 一般地，$\begin{pmatrix}A_0\\A_1\\\vdots\\A_{N-1}\end{pmatrix}=F\begin{pmatrix}a_0\\a_1\\\vdots\\a_{N-1}\end{pmatrix}$，$F_{j, k}=e^{i{2\pi jk\over N}}$令$\omega_N=e^{i{2\pi\over N}}\Rightarrow F_{j,k}=\omega^{jk}_{N}=F_{j,k}$。F称为傅里叶矩阵，F的各列相互正交且F对称(但注意：不是Hermite矩阵)，这个矩阵跟范德蒙德行列式很像。如果令$\omega_N=e^{i{2\pi\over N}}\Rightarrow F_{s,t}=\omega^{st}_{N}=F_{t,s}$那么F表示成$F=\begin{pmatrix}1&amp;1&amp;1&amp;1\\1&amp;\omega&amp;\omega^2&amp;\omega^3\\1&amp;\omega^2&amp;\omega^4&amp;\omega^6\\1&amp;\omega^3&amp;\omega^6&amp;\omega^9\end{pmatrix}$。 对于给定的$\begin{pmatrix}A_0\\A_1\\\vdots\\A_{N-1}\end{pmatrix}$，求$\begin{pmatrix}a_0\\a_1\\\vdots\\a_{N-1}\end{pmatrix}=F^{-1}\begin{pmatrix}A_0\\A_1\\\vdots\\A_{N-1}\end{pmatrix}$，$F^{-1}={1\over N}\overline{F}$，需要$N^2$次乘法，$N(N-1)$次加法（忽略除以N的除法），计算量$=O(N^2)$。 注记：实际上由前文可得$\begin{pmatrix}a_0\\a_1\\\vdots\\a_{N-1}\end{pmatrix}=\begin{pmatrix}c_0\\c_1\\\vdots\\c_{N-1}\end{pmatrix}$，因此是向量$\begin{pmatrix}A_0\\A_1\\\vdots\\A_{N-1}\end{pmatrix}$关于某个正交向量基的投影长度，即坐标分量。$(a_0, a_1,b_1,\ldots)$是$f(x)$关于$\{1,cosx,sinx,\dots\}$的坐标。 快速傅里叶变换FFT快速傅里叶变换减少了$DFT$的计算量到$O(Nlog_2^N)$ $N$ $N^2$ $Nlog_2^N$ FFT efficiency 256 65536 1024 64:1 512 262144 2304 114:1 1024 1048576 5120 205:1 注：$\lim\limits_{N\rightarrow +\infty}{log_2^N\over N}=0$ 解释算法：$N=4，\begin{pmatrix}a_0\\a_1\\a_2\\a_3\end{pmatrix}={1\over 4}\begin{pmatrix}1&amp;1&amp;1&amp;1\\1&amp;-i&amp;-1&amp;i\\1&amp;-1&amp;1&amp;-1\\1&amp;i&amp;-1&amp;-i\end{pmatrix}\begin{pmatrix}A_0\\A_1\\A_2\\A_3\end{pmatrix}\quad i^4=1$ $\begin{equation}4a_0=(A_0+A_2)+(A_1+A_3)\\4a_1=(A_0-A_2)-i(A_1-A_3)\\4a_2=(A_0+A_2)-(A_1+A_3)\\4a_3=(A_0-A_2)+i(A_1-A_3)\end{equation}$ 注意：求$a_2$的时候，可以把在求$a_0$过程中的两个括号的值重新利用，求$a_3$的时候，可以把在求$a_1$过程中的两个括号的值重新利用。 引入记号： 将$A_0, A_1, A_2, A_3$重新排序$A_0,A_2,A_1,A_3$使用记号，则 $FFT$算法将$DFT$算法分成$log_2^N$段，每一段有${N\over 2}$个butterfly operation。 举例：$N=8$，第一步将$A_0,A_1,\ldots,A_7$重新排序。原则：考虑$0,1,\ldots,7$的二进制，设$j$的二进制数的反转为$n_j$。若$j&lt;n_j$，则交换$Aj$和$A_{n_j}$。例如1的二进制数为${001}_2$,反转为${100}_2=4, 1&lt;4$，交换$A_1$和$A_4$。 排序后为：$A_0,A_4,A_2,A_6,A_1,A_5,A_3,A_7$（奇偶分离） 奇偶分离的原因：$\begin{pmatrix}a_0\\a_1\\\vdots\\a_{N-1}\end{pmatrix}=({1\over N}\overline{F})\begin{pmatrix}A_0\\A_1\\\vdots\\A_{N-1}\end{pmatrix}$，令$p(x)=A_0+A_1x+\cdots+A_{N-1}x^{N-1}=p_e(x^2)+xp_o(x^2),p_e=A_0+A_2x^2+\cdots\quad p_o=A_1+A_3x^2+\cdots$ 注解：e代表even，o代表odd，则$a_j={1\over N}(1,\overline{\omega}_N^j,\overline{\omega}_{N}^{2j},\ldots)\begin{pmatrix}A_0\\\vdots\\A_{N-1}\end{pmatrix}={1\over N}p(\overline{\omega}_N^j)={1\over N}[p_e(\overline{\omega}_N^{2j})+\overline{\omega}_N^{j}p_o(\overline{\omega}_N^{2j})], j=0,1,\cdots,{N\over 2}-1$ $a_{N\over 2+j}={1\over N}[p_e(\overline{\omega}_N^{2({N\over 2}+j)})+\overline{\omega}_N^{N\over 2+j}p_o(\overline{\omega}_N^{2({N\over 2+j})})],j=0,1,\cdots,{N\over 2}-1​$ 再由于：$\omega_N=e^{i{2\pi\over N}}\Rightarrow\overline{\omega}_N^{2j}=\overline{\omega}_{N\over 2}^j, \overline{\omega}_N^{N\over 2+j}=-\overline{\omega}_N^j, \overline{\omega}_N^{N+2j}=\overline{\omega}_{N\over 2}^j$ 所以：$\cases{a_j={1\over N}[p_e(\overline{\omega}_{N\over 2}^{j})+\overline{\omega}_N^{j}p_o(\overline{\omega}_{N\over 2}^{j})],j=0,1,\cdots,{N\over 2}-1\\a_{N\over 2+j}={1\over N}[p_e(\overline{\omega}_{N\over 2}^{j})-\overline{\omega}_N^{j}p_o(\overline{\omega}_{N\over 2}^{j})],j=0,1,\cdots,{N\over 2}-1}$ 所以：$a_j={1\over N}p(\overline{\omega}_N^j)$，再令$b_j=p_e(\overline{\omega}_{N\over 2}^{j}), b’_j=p_o(\overline{\omega}_{N\over 2}^{j})$，那么：$\cases{a_j = {1\over N}[ b_j+\overline{\omega}_N^{j}b’_j],j=0,1,\cdots,{N\over 2}-1\\a_{N\over 2+j} = {1\over N}[b_j-\overline{\omega}_N^{j}b’_j] ,j=0,1,\cdots,{N\over 2}-1}$，那么这又是一个butterfly operation: 可以重复利用以上原理对$b_j,b’_j$讨论，$b_j=p_e(\overline{\omega}_{N\over 2}^{j}),j=0,1,\cdots,{N\over 2}-1$，令$c_j=p_{ee}(\overline{\omega}_{N\over 4}^{j}), c’_j=p_{eo}(\overline{\omega}_{N\over 4}^{j})$，那么：$\cases{b_j = {1\over N}[c_j+\overline{\omega}_{N\over 2}^{j}c’_j],j=0,1,\cdots,{N\over 4}-1\\b_{N\over 4+j} = {1\over N}[c_j-\overline{\omega}_{N\over 2}^{j}c’_j],j=0,1,\cdots,{N\over 4}-1}$，那么这又是一个butterfly operation: 不停的划分下去，即：$FFT$算法将$DFT$算法分成$log_2^N$段，每一段有${N\over 2}$个butterfly operation。 举例：]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机图像]]></title>
    <url>%2F2017%2F08%2F11%2Fcomputer_graphics%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第11讲：计算机图像 引言熟悉的三维空间的基本变换是：平移(translation)，伸缩(rescaling)，旋转(rotation)，投影(projection)和反射(reflection)。现在一个问题：平移变换只对于点才有意义，因为平移变换会改变点的坐标，可是普通向量没有位置概念，只有大小和方向。那如何区分点和向量呢？这时候引入齐次坐标系(homogeneous coordinate system)。 对于任意一个3维空间点$p$的坐标均是参照（相对于）基点（原点）的坐标，可以表示成$p=x\vec e_1+y\vec e_2+z\vec e_3+ O=x\begin{pmatrix}1\\0\\0\end{pmatrix}+y\begin{pmatrix}0\\1\\0\end{pmatrix}+z\begin{pmatrix}0\\0\\1\end{pmatrix}+\begin{pmatrix}0\\0\\0\end{pmatrix}$，然而$\vec{op}=x\vec e_1+y\vec e_2+z\vec e_3$ 是不参照任何东西的，为了在线性代数中统一表示和区分，把$p=\begin{pmatrix}1&amp;0&amp;0&amp;0\\0&amp;1&amp;0&amp;0\\0&amp;0&amp;1&amp;0\\0&amp;0&amp;0&amp;0\end{pmatrix}\begin{pmatrix}x\\y\\z\\1\end{pmatrix}\quad \vec{op}=\begin{pmatrix}1&amp;0&amp;0&amp;0\\0&amp;1&amp;0&amp;0\\0&amp;0&amp;1&amp;0\\0&amp;0&amp;0&amp;0\end{pmatrix}\begin{pmatrix}x\\y\\z\\0\end{pmatrix}$， 这时三维空间中的一个点的齐次坐标是$(x,y,z,1)$或$\begin{pmatrix}x\\y\\z\\1\end{pmatrix}$，一个向量的齐次坐标是$(x,y,z,0)$或$\begin{pmatrix}x\\y\\z\\0\end{pmatrix}$，所以平移变换就不是$R^3\rightarrow R^3$。 定义 一个函数$f: R^n \rightarrow R^N $是一个刚体运动(rigid motion)，如果$\forall v,w\in R^n, ||f(v)-f(w)||=||v-w||$，即内部的各点间距离不变。定理 $R^3$上的刚体运动是平移，旋转和反射的合成。此时，$f(v)=Av+v_0$，其中$A$是三阶正交阵。三阶正交阵的分类：设$A$是一个三阶正交阵，则存在实可逆阵$P$，$P^{-1}AP=\begin{pmatrix}cos\theta&amp;-sin\theta&amp;0\\sin\theta&amp;cos\theta&amp;0\\0&amp;0&amp;\pm 1\end{pmatrix}=B$，其中$P=(\alpha_1, \alpha_2, \alpha_3)$，根据相似的性质：$|B|=\pm 1\rightarrow |A|=\pm 1$，$A$本身是一个正交阵，因此$A^TA=I_3$。 若$B_{33=1}, AP=PB\rightarrow A\alpha_3=\alpha_3$是一个旋转矩阵，旋转轴是$\alpha_3$所在直线，旋转角度是沿$\alpha_3$方向逆时针转$\theta$角；若$B_{33}=-1, AP=PB\rightarrow A\alpha_3=-\alpha_3$ 是$A$将$\alpha_3$变为$-\alpha_3$，将$\alpha_1,\alpha_2$所在平面逆时针旋转$\theta$角，此时$A$的作用就是镜面反射和旋转，这里镜面指的是x-y平面。 平移translation 伸缩rescaling 旋转rotation3个特殊情形 一般情形 旋转的性质 投影projection 反射]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图和网络]]></title>
    <url>%2F2017%2F08%2F08%2Fgraph_and_network%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第8讲：图和网络 简介欧姆定律Ohm’s law的向量形式 图与矩阵 关联矩阵incidence matrix 邻接矩阵adjacency matrix 拉普拉斯矩阵laplacian matrix 注： 半正定证明与刚度矩阵类似 网络和加权Laplacian矩阵 电路相关的物理定律 例子不接外部源 接外部源 带权$K=A^TCA$ 关联矩阵的四个基本子空间N(A) C(A)按$C(A)$的定义得：$C(A)=\{Ax|x\in R^n\}$ 。沿用前面使用的字母：$u$是各点电势，$e$是各边电势差，$Au=e$ ，当$Au=e$ 有解 $\Leftrightarrow e \in C(A)$ 去证明：$dim(C(A))=n-1$ ，即$A$ 的任意 $n-1$个列向量是线性无关的。设$A=(a_1,a_2,\,…\,,a_n) $，不妨假设$a_1,a_2,\,…\,,a_{n-1}$线性相关，那么存在$c_1, c_2,\,…\,,c_{n-1} \in R$ 且不全为0满足：$c_1a_1+c_2a_2+…+c_{n-1}a_{n-1}+0a_n=0\Rightarrow A\begin{pmatrix}c_1\\c_2\\\vdots\\c_{n-1}\\0\end{pmatrix}={0}\Rightarrow \begin{pmatrix}c_1\\c_2\\\vdots\\c_{n-1}\\0\end{pmatrix}\in N(A), $但与$N(A)=\left\{c\begin{pmatrix}1\\\vdots\\1\end{pmatrix} \Bigg| c\in R \right\} $ 矛盾，以此类推，得以证明$C(A)$的维数是$n-1$ ，即$A$的任意$n-1$个列向量均可作为$C(A)$的一组基。 发现矩阵中对应的回路：$e\in C(A)$ 如下等式有解 $Au=e\Rightarrow \begin{pmatrix}-1&amp;1&amp;0&amp;0\\ -1&amp;0&amp;1&amp;0\\0&amp;-1&amp;1&amp;0\\0&amp;-1&amp;0&amp;1\\0&amp;0&amp;-1&amp;1\end{pmatrix}\begin{pmatrix}u_1\\u_2\\u_3\\u_4\\u_5 \end{pmatrix}=\begin{pmatrix}e_1\\e_2\\e_3\\e_4\\e_5 \end{pmatrix} \Rightarrow \begin{cases}-u_1+u_2=e_1\\ -u_1+u_3=e_2\\ -u_2+u_3=e_3\\ -u_2+u_4=e_4\\ -u_3+u_4=e_5\end{cases} \Rightarrow \begin{cases}e_1-e_2+e_3=0\\e_3-e_4+e_5=0\end{cases}$ ，即边1,2,3这3条边电势差之和为0，由图上可得边1,2,3恰好构成一个回路，边3,4,5也一样。这恰好是Kirchholff Voltage Law (KVL)。把这两个回路等式书写成矩阵形式$\begin{pmatrix}1&amp;-1&amp;1&amp;0&amp;0\\0&amp;0&amp;1&amp;-1&amp;1 \end{pmatrix}\begin{pmatrix} e_1\\e_2\\e_3\\e_4\\e_5 \end{pmatrix}=0$ . 此时称矩阵$B =\begin{pmatrix}1&amp;-1&amp;1&amp;0&amp;0\\0&amp;0&amp;1&amp;-1&amp;1 \end{pmatrix}$ 为回路矩阵，可以看到它的每一行代表一个回路且称为极小回路，每一列代表一条边。如果边的方向是逆时针方向则取为正号，否则取为负号。注意，此时$e\in N(B)$。 此外，$BA=\begin{pmatrix}1&amp;-1&amp;1&amp;0&amp;0\\0&amp;0&amp;1&amp;-1&amp;1\end{pmatrix}\begin{pmatrix}-1&amp;1&amp;0&amp;0\\ -1&amp;0&amp;1&amp;0\\0&amp;-1&amp;1&amp;0\\0&amp;-1&amp;0&amp;1\\0&amp;0&amp;-1&amp;1\end{pmatrix}=\begin{pmatrix}0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0\end{pmatrix}$即$C(A) \subseteq N(B) $ 。$dim(N(B))=3, dim(C(A))=3$，因此$C(A)$就构成了$N(B)$的基。从理意义角度理解：$A$矩阵执行的操作表示求解各边电势之差，$B$各行刚好是回路，由$KVL$定律得结果必为0. $N(A^T)$ 由定义得：$N(A^T)=\{y\in R^m|A^Ty=0\}$。例子中，关联矩阵$A$ 各行代表一条边，各列代表一个顶点。那么$A^T$ 的行代表顶点，列代表边。$A^Ty=0\Rightarrow\begin{pmatrix}-1&amp;-1&amp;0&amp;0&amp;0\\1&amp;0&amp;-1&amp;-1&amp;0\\0&amp;1&amp;1&amp;0&amp;-1\\0&amp;0&amp;0&amp;1&amp;1\end{pmatrix}\begin{pmatrix}y_1\\y_2\\y_3\\y_4\\y_5 \end{pmatrix}=\begin{pmatrix}0\\0\\0\\0\\0\end{pmatrix} \Rightarrow \begin{cases}-y_1-y_2=0\\y_1-y_3-y_4=0\\y_2+y_3-y_5=0\\y_4+y_5=0\end{cases}$物理意义解读：$y_i$是各第$i$边上的电流，上述等式表明每一个顶点输入输出电流和为0，即Kichhoff Current Law (KCL)。 $A^Ty=0$， 由前文得到：$BA=0 \Rightarrow A^TB^T=0 \Rightarrow A^TB^T=\begin{pmatrix}-1&amp;-1&amp;0&amp;0&amp;0\\1&amp;0&amp;-1&amp;-1&amp;0\\0&amp;1&amp;1&amp;0&amp;-1\\0&amp;0&amp;0&amp;1&amp;1\end{pmatrix}\begin{pmatrix}1&amp;0\\ -1&amp;0\\1&amp;1\\0&amp;-1\\0&amp;1\end{pmatrix}=\begin{pmatrix}0&amp;0\\0&amp;0\\0&amp;0\\0&amp;0\end{pmatrix}$因此，$C(B^T) \subseteq N(A^T)$。由于$r(A)=C(A)=r=n-1, N(A^T)+C(A)=m, N(A^T)=m-r=5-3=2$， 由于$B^T$的列向量线性无关，即$B$的行向量代表回路，那么回路向量就是$N(A^T)$的一组基。 $C(A^T)$ 总结 $N(A_{m\times n})$零空间 $Au=0$ ，$N(A)=c{(1,1,\,…\,,1)^T}_{n\times 1}$ ；物理意义：各点电势相等，电势差为0。 $C(A_{m\times n})$列空间 $Au=e$(上文用的是x, b)，$A$ 中任意$n-1$ 列构成了$C(A)$ 的一组基；物理意义每个极小回路电势守恒，每个极小回路构成的极大回路电势依然守恒，诠释了KVL定律。 $N(A^T)$左零空间 $A^Ty=0$，回路向量构成了$N(A^T)$ 的一组基；诠释了无外部电流源的KCL定律。 $C(A^T)$行空间 ，$A^Ty=f$， 每个极大树子图对应关联矩阵的行向量（即边）构成了$C(A^T)$ 的一组基；诠释了有外部电流源的KCL定律。 注计N(B)=C(A) B的零空间中的任何一个向量，它都要属于A的列空间，$A$的列空间中的每一个向量的特点，比如说$A$乘上一个$x_1$到$x_n$，$x_1$到$x_n$是$n$个顶点的电势。$A$乘上这个向量得到的是各个边上的电势差，那么相应的$x_j-x_k$就是$j$和$k$两个顶点上的电势差，顶点连线，$j$和$k$连线的边上的电势差。那么我们要想说明，N(B)中的向量属于C(A)那么我们只要说明任何一个向量属于B的零空间，它最后都能写成这样一种形式，就可以了。那么设$e$属于$N(B)$，那么我们可以取定这个连通图的一个极大树子图，然后在这个极大树子图$T$上取一个顶点作为基点，那么任意的另外一个顶点$K$跟这个基点之间它们连线的路在$T$上只有一条这样的路，因为$T$是一个树，它不可能有回路，所以在$T$中有唯一的一条连接K到基点的路。定义K的电势：在这条路上各边的电势之和，各边的电势之和，我们这个$e_1$到$e_m$呢，我们可以刻画各个边上的电势，那么我们可以看到$e$属于$N(B)$我们实际上可以检查出任意边上的电势差实际上是$e_j$等$u_k$减$u_1$，那么其中的这个$k$呢为j的起点，$l$为$j$的终点，最后我们就可以得到$e=-Au$，所以$e$就属于$C(A)$就是这个地方呢，我们要使用$e$属于$N(B)$，我们才能检查出：任意边上的这个电势差等于$u_k$减$u_l$，就是要满足科尔霍夫电压定律。 欧拉公式Euler’s formula 对于$B_{x \times m}\Rightarrow C(B^T)+dim(N(B))=r_B+dim(N(B))=m\Rightarrow m-r_B=dim(N(B))=dim(C(A))=n-1$ 又因为欧拉公式：$m-l=n-1$，得：$r_B=l$，即$B$是行满秩的，其实极小回路组对应极大线性无关组。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工程中的矩阵]]></title>
    <url>%2F2017%2F08%2F07%2Fengineering_matrices%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第七讲：工程中的矩阵 应用数学的几个原则 将非线性问题变成线性问题(Nonlinear becomes linear) 将连续问题转化为离散的(Continuous becomes discrete) 工程中的矩阵许多物理定理都是线性关系(as approximations of reality)，比如胡克定律(Hook’s law)、欧姆定律(Ohm’s law)、牛顿第二定律(F=ma)，讨论这些定律的向量形式。线性关系的向量形式以如下方式、框架来讨论： $(1)\ e=Au$$(2)\ y=Ce$$(3)\ f=A^Tw$ 其中$u$是起始未知量$(primary\ unknown)$，$f$是外部的输入$(input)$： 线性问题通常是：输入$f$，求出$u$？ 例如：胡克定律：Displacement is proportional to force f=ku欧姆定律：Current is proportional to voltage difference推广到向量形式：$f=Ku$另外的例子：最小二乘法 $A^TAx=A^Tb$ ，求$x$ 线性弹簧模型 情形(1) 情形(2) 情形(3) 情形(4) 总结 胡克定律的向量形式把它应用到了弹性力学中，这个$u$表示的是质体的上下位移$e$是弹簧和伸长或缩短量，那么它们之间的关系呢？可以通过这样$A$这个矩阵那么A非常相似于一个差分矩阵，这样弹簧的伸长和缩短量和弹簧的弹力之间可以通过胡克定律来描述，那么这若干根弹簧它们所产生的弹力我们提升到胡克定律这样一个向量形式：C的每一个对角分量表示的是一个弹性系数（$y=Ce$）。最后弹力和外力之间：当达到平衡以后，可以通过一个矩阵去描述它们的关系，这个矩阵跟前面这个矩阵正好互为转置最后把整个过程合起来到这个矩阵$K=A^TCA$，称为刚度矩阵刚度矩阵刻划了系统受外力作用的形变程度。 刚度矩阵 注：此处老师讲解具有小的跳跃性 ，渣渣注释如下： $K,T$是正定的：$C$ 矩阵表示弹性系数是正定的，$K=A^TCA$ ，当 $A$ 可逆的时候，$K$ 与 $C$ 合同的。 与正定矩阵合同的对称矩阵也是正定的 ​ 判断是实对称阵是不是正定的第一条判别法：特征值是否全正，是的话则这个实对称矩阵就是正定的。根据惯性定理，由于与正定矩阵（记为$A$）合同的矩阵（记为$B$）其特征值符号与 $A$ 一致且保持对称性，那么$B$ 的特征值也是全正的，因此 $B$ 也是正定的。 $B, C$ 是半正定的 因为弹性系数矩阵 $C$ 是正定的对角阵$\Rightarrow x^TKx=x^TA^TCAx=x^TA^T ({\sqrt{C}}^T \sqrt{C}) Ax = x^TA^T {\sqrt{C}}^T \sqrt{C} Ax = ||\sqrt{C} Ax||^2 $，因为$A$是奇异的，$x^TKx\ge 0$， 因此K是半正定的。 性质1 注：$f_i$ 是 $i$ 个质题所受的外力，例如：重力，$f_i=m_ig,\ m_i$ 是 $i$ 个质体的质量。 性质2 注：此处老师直接说一般性结论，$A, \ B$ 都正定的，那么$AB$ 可能不对称，但是$AB$ 存在正特征值。圆盘定理也是直接引用（！！渣渣工科狗表示闻所未闻！！）。 性质3 从离散到连续$f=A^TCAu$ 总结： $(1)\ e=u_i-u_{i-1}=\Delta u={du\over dx}=Au\(2)y=Ce=c(x)e(x)\(3)\ f=-(y_i-y_{i-1})=-\Delta y=-{dy\over dx}=A^Ty$]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伪逆(广义逆)pseudo inverse]]></title>
    <url>%2F2017%2F08%2F06%2Fpseudo_inverse%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第六讲：伪逆 引言矩阵的奇异值分解可以理解成从$R^n$到$R^m$的线性变换在不同基底下矩阵表示，接下来利用矩阵的奇异值分解来定义矩阵的伪逆，然后再利用矩阵的伪逆来讨论线性方程组Ax＝b无解时的最小二乘解，线性代数的中心问题是求解线性方程组$Ax=b$，最简单的情况是如果系数矩阵A是n阶的可逆矩阵，那么这时对于任意的n维向量$b$，线性方程组$Ax=b$有唯一的解，这个解是$A^{-1} b$，那这就启发去对于不可逆的矩阵或者是对于$A_{m\times n}$的矩阵，我们来定义它的一个逆矩阵，那么这时候逆矩阵我们叫做伪逆或者是叫广义逆 。 定义伪逆的定义来自于奇异值分解 (需先了解奇异值分解的内容)：(1)若$A$可逆，即$r=m=n$，则：$A^{-1}=(U\Sigma V^T)^{-1}=V\Sigma^{-1}U^T=A^+$，注意：由奇异值分解公式$AV=U\Sigma,\ (v_1\,…\,v_r)\in C(A^T),\ (v_{r+1}\,…\,v_n)\in N(A),\ (u_1\,…\,u_r)\in C(A),\ (u_{r+1}\,…\,u_m)\in N(A^T)$ 得：$AV=U\Sigma: C(A^T)\rightarrow C(A)$，同理可得：$A^+U^T=V\Sigma^{+}:C(A)\rightarrow C(A^T)$ (2)$AA^+=(U\Sigma_{m\times n} V^T)(V\Sigma^+_{n\times m}U^T)=U\Sigma_{m\times n}\Sigma^+_{n\times m}U^T=U\begin{pmatrix}I_r&amp;0\\0&amp;0\end{pmatrix}_{m\times m}U^T$ 得出以下3个性质： 对称性：$(AA^+)^T=AA^+$ $AA^+=u_1u_1^T+\,…\,+u_ru_r^T, U=(u_1,\,…\,u_r,\,u_{r+1}\,…\,,u_n)$ $AA^+=R^m$到$C(A)$的正交投影矩阵，$AA^+|_{C(A)}=id, AA^+|_{N(A^T)}=0$ 证明1：$AA^+x=(u_1u_1^T+\,…\,+u_ru_r^T)x=(u_1^Tx)u_1+\,…\,+(u_r^Tx)u_r​$，由奇异值svd分解得到$V=(v_1,\,…\,,v_r)​$是$A^T​$列空间（即$C(A^T)​$）的单位正交特征向量基，而$U=(u_1,\,…\,,u_r)​$是$C(A)​$的单位正交特征向量基，所以$AA^+​$是投影到$C(A)​$的正交投影矩阵（即保留了$C(A)​$的部分），因此$AA^+​$限制在$C(A)​$的变换即变成了恒等变换。而$U​$中$(u_{r+1}\,…\,u_m)​$和$U^T​$中$(u_{r+1}\,…\,u_m)^T​$即属于$N(A^T)​$的基乘以矩阵$\begin{pmatrix}I_r&amp;0\\0&amp;0\end{pmatrix}_{m\times m}​$中右下角的$0​$相当于对属于$N(A^T)​$的部分做了零变换。 证明2：$A^+u_j={1\over \sigma_j}v_j\Rightarrow AA^+u_j=A({1\over\sigma_j}v_j)={1\over \sigma_j}Av_j$ 再根据奇异值分解中$Av_j=\sigma u_j, (1\le j \le r)$ 得$AA^+u_j=u_j(1\le j\le r),\ AA^+u_j=0(r+1\le j \le m)$ 验证：$(AA^+)(AA^+)=U\begin{pmatrix}I_r&amp;0\\0&amp;0\end{pmatrix}_{m\times m}U^TU\begin{pmatrix}I_r&amp;0\\0&amp;0\end{pmatrix}_{m\times m}U^T$，由于从svd分解知道$U$是单位正交特征向量基 ，因此：$U^T=U^{-1}\Rightarrow (AA^+)(AA^+)=U\begin{pmatrix}I_r&amp;0\\0&amp;0\end{pmatrix}_{m\times m}U^T=AA^+$，这正是投影的性质：多次投影结果还是第一次投影结果。 结果：$\forall\ p\in R^m, b=p+e, p\in C(A), e\in N(A^T), AA^+b=p$ (3)$A^+A=(V\Sigma^+_{n\times m}U^T)(U\Sigma_{m\times n} V^T)=V\begin{pmatrix}I_r&amp;0\\0&amp;0\end{pmatrix}_{n\times n}V^T$ 得到以下三个性质（证明同上）： $(A^+A)^T=A^+A$ $A^+A=v_1v_1^T+\,…\,+v_rv_r^T$ $A^+A=R^n$到$C(A^T)$的正交投影矩阵（$A^+A|_{C(A^T)}=id,\quad A^+A|_{N(A)}=0$）: $\forall\ x\in R^n=C(A^T)\bigoplus N(A)),\ x=x_{1,r}+x_{r+1,n}, \ x_{1,r}\in C(A^T),\ x_{r+1,n}\in N(A^T),\\ A^+Ax=A^+A(x_1,\,…\,x_r,x_{r+1},\,…\,x_n)=x_{1,r}$ 为什么称为伪逆、左逆、右逆 例子注：$u_1, u_2,u_3$ 是$R^m$的一组基底那么它是${Av_1\over \sigma_1}$，那么很容易计算出来，是${1\over\sqrt{2}}\begin{pmatrix}1\\1\\0\end{pmatrix}$那$u_2$和$u_3$ 分别是0所对应的特征向量，$u_2$和$u_3$可以看成是三维空间里头，$u_1$的正交补所给出来的单位正交的向量。 特例 Jordan标准形的伪逆推导结论：$J_n^+=J_n^T$，Jordan标准形的伪逆是它自己的转置。 Moore-Penrose伪逆E.H.Moore伪逆 Penrose伪逆注： A可以是mxn的复数矩阵，这样的话(3)(4)里面就变成共轭转置。 Penrose伪逆与E.H.Moore伪逆定义是等价的。 $(1)AXA =A \Rightarrow AXAX=AX\Rightarrow (AX)^N=AX\Rightarrow AX$ 是幂等矩阵，投影矩阵$(2)XAX=X\Rightarrow XAXA=XA\Rightarrow (XA)^N=XA\Rightarrow XA$ 是幂等矩阵，投影矩阵$(3)(AX)^T=AX\Rightarrow AX$ 是对称矩阵$(4)(XA)^T=XA\Rightarrow XA$ 是对称矩阵 通过奇异值分解得到的伪逆矩阵$A^+$，$AA^+: R^m \rightarrow C(A)$，$A^+A:R^n\rightarrow C(A^T)=C(A^+)$，前文已经证明两者都是对称的，所以符合Penrose对伪逆矩阵的定义。对于伪逆唯一性的证明上文图片太小可以放大来看。 伪逆的应用之最小二乘法引言但是我们需要求$e$ 即误差最小的解！但是这时候$A_{m\times n}$不是列满秩不存在逆矩阵，于是自然地想到利用伪逆求解。 伪逆求解正规方程——最佳最小二乘解注：由于$A^+$ 来自于：$A^+U^T=V\Sigma^{+},\ (v_1\,…\,v_r)\in C(A^T),\ (v_{r+1}\,…\,v_n)\in N(A),\ (u_1\,…\,u_r)\in C(A),\ (u_{r+1}\,…\,u_m)\in N(A^T),\\\Sigma^+=\begin{pmatrix}{1\over \sigma_1}\\&amp;{1\over \sigma_2}\\&amp;&amp;.\\&amp;&amp;&amp;.\\&amp;&amp;&amp;&amp;{1\over \sigma_r}\\&amp;&amp;&amp;&amp;&amp;0\end{pmatrix}_{n\times m}\Rightarrow A^+: C(A)\rightarrow C(A^T)$，另外由于 $A^TAx=0, Ax=0$ 同解所以零空间相同。 最佳最小二乘解的四个基本子空间]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[马尔科夫矩阵和正矩阵]]></title>
    <url>%2F2017%2F08%2F06%2FMarkov_matrix%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第9讲：马尔科夫矩阵和正矩阵 引言 马尔科夫链详细参考：Markov chain Markov Matrix正矩阵 马尔科夫矩阵定义 马尔科夫矩阵性质 正马尔科夫矩阵 正马尔科夫矩阵的性质 例子 人口流动模型 正矩阵 谱半径Spectral radius 定义为谱半径是矩阵特征值模的最大值，而非最大特征值，注意：矩阵来自于线性变换（也叫线性算子），因此线性变换也有谱半径，详询wiki: 谱半径Spectral radius。 ##Perron-Frobenius theorem 这个原理应用在统计推断，经济，人口统计学，搜索引擎的基础。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性变换2]]></title>
    <url>%2F2017%2F08%2F05%2Flinear_transformation_2nd_part%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第五讲：线性变换2 前言对于给定的线性变换选取适当的基底使得其矩阵表示尽可能简单，我们引入了线性变换的矩阵表示对于从$n$维的向量空间$V$到$m$维的向量空间$W$的线性变换$\sigma$，我们取定$V$的一组基$v_1$到$v_n$取定W的一组基$w_1$到$w_m$，那线性变换$σ$作用在$v_1$到$v_n$上可以被$w_1,…,w_m$线性表示，表示的系数我们被一个$m×n$的矩阵$A$去描述，那么这样线性变换$σ$就跟这个$m×n$的矩阵$A$一一对应。线性变换的矩阵表示要依赖于我们基底的选取，一般说来如果基做了改变，同一个线性变换它会有不同的矩阵表示，那我们希望找出线性变换与基底选取无关的性质，这样当我们借助矩阵来研究线性变换的这些性质的时候就可以利用好基底下面尽可能简单的矩阵表示。 恒等变换与基变换恒等变换就是不变，那么不变的线性变换对应单位矩阵。 the 9th property of determinant: the determinant of $AB$ is det $A$ times det $B$: $|AB| = |A||B|$ 因此：由于$(\sigma_1\,….\,\sigma_n)$ 和 $(\beta_1\,…\,\beta_n)$ 都是基向量，因此都是列满秩，又是 $n$ 维，所以可逆，再推出$P$可逆。否则 $|\alpha_1\,…\,\alpha_n|\ne|\beta_1\,…\,\beta_n||P|$ 基变换的应用一张256x256的灰度图像 注意：$C^N$是$n$维元素可为复数的基 图像的其中3种基底 小波基好求它的逆，傅里叶基也好求它的逆。如果是$4\times4$纯色图像直接用小波基或者傅里叶基的第一个分量$w_1$和$\xi_1$做基底，表示成$c_1w_1=W\begin{pmatrix}c_1\\0\\0\\0\end{pmatrix}$和$c_1\xi_1=\xi\begin{pmatrix}c_1\\0\\0\\0\end{pmatrix}$。而像素之间变换比较剧烈的图像可用小波基中的 $c(w_3+w_4)$ 和傅里叶基中的 $c\xi_3$ 。 jpeg 图像本身是用系数矩阵$c$表示，那么所谓的压缩和传输图像也是压缩和传输这个矩阵$c$。压缩做的就是用尽可能少的信息（数据）去代表原有的信息（数据），这个过程会丢失一些不重要的信息（数据），对应到矩阵上就是$c$的非0项元素比较少（这个要求用更少数量的基底向量就能接近描述出原来的矩阵，越少越好）。由于 $c=W^{-1}x$ 因此能不能快速计算基底的逆也很重要，而小波基和傅里叶基正符合此特点。 线性变换在不同基下的矩阵 定理：$n$向量空间$V$上的线性变换$\sigma$在$V$的不同基下的矩阵是相似矩阵。 由上图可得：$I_1$ 和 $I_2$ 是恒等变换$(\beta_1\,…\,\beta_n)=I_1(\beta_1\,…\,\beta_n)=(\alpha_1\,…\,\alpha_n)P$$(\alpha_1\,…\,\alpha_n)=I_2(\alpha_1\,…\,\alpha_n)=(\beta_1\,…\,\beta_n)P^{-1}$线性变换复合角度：$\sigma=I_2\,\sigma\,I_1\,\rightarrow\,B=P^{-1}AP$ 同一个线性变换在不同基下的不变性当我们借助于矩阵来研究线性变换的时候，我们希望研究线性变换与基底选取无关的性质。由以上的讨论我们知道这个向量空间$V$到自身的线性变换在不同基下的矩阵表示是互为相似矩阵的。因此，所谓与基底选取无关的性质也就是相似变换下不变的性质，那么这样自然地研究相似不变量是线性代数中很重要的内容。我们知道对于一个矩阵而言特征多项式、特征值、迹、行列式、矩阵的秩等等都是矩阵的相似不变量，这样我们就称一个n维向量空间$V$上线性变换在$V$的一组基下的矩阵$A$，把矩阵表示$A$的特征多项式、特征值、迹行列式等等就叫做这个线性变换的特征多项式、特征值 、迹、行列式。 矩阵分解与基变换给定一个$R^n$到$R^m$的线性变换$σ$，它在$R^n$中的标准基$e_1$到$e_n$和$R^m$的标准基$ẽ_1,…,ẽ_m$下的矩阵是 $A$ ，$σ$作用在$e_1 … e_n$上面就等于$\tilde{e}_1,…, \tilde{e}_m$去乘以矩阵$A$，也就是说$σ$作用在$e_j$上，就等于$A$的第j列，也就是$A$去乘以$e_j$，因此这个线性变换就可以表示成对任何的$n$维向量$v$，那么$σ$作用在$v$上就是矩阵$A$去乘以$V$ ：$$\sigma(e_1\,…\,e_n)=(\tilde{e}_1 \,…\,\tilde{e}_m)A\rightarrow\sigma(e_j)=Ae_j$$ 接下来做基变换，第一个改变输入基，第二个改变输出基，第三个输入输出基都改。 对角化矩阵视为线性变换 由上可得 $\sigma(x_1\,…\,x_n)=(x_1\,…\,x_n)\Lambda=S\Lambda$ ，$x$ 为特征向量基，另外基变换 ${id}_1(S)=S=\{e\}S$$σ$这个线性变换在A的特征向量作为的新基下面，它的矩阵表示是 $\Lambda$ 这个对角阵。而$σ$从 $R^n$ 到 $R^n$在标准基下的矩阵是$A$，$σ$在特征向量基下的矩阵表示是对角阵 $\Lambda$。那么输入$x$这组基，输出$e$这组基，这个恒同变换，它的矩阵表示是 $S$ 。如果输入$e$这组基 ，输出$x$这组基这个恒同变换，它的矩阵表示是$S^{-1}$。 奇异值分解视为线性变换 线性变换的核与像定义 线性变换的零度与秩 线性变换秩的证明 注：$L(\sigma(v_1),\,…\,,\sigma(v_n))$ 符号含义：由 $\sigma(v_1),\,…\,,\sigma(v_n)$ 线性张成。 线性变换的维度公式 单射满射可逆中学学过的单射双射满射 线性变换下的单射（injective），满射（surjective）与逆（inverse） 第一个等价符号证明（反证法）：如果单射无法推出核只有$\{0\}$，那么假设$\exists\,\alpha(\ne0)\in{ker\,\sigma}$ 那么$\sigma(\alpha)=0$，又因为$\sigma(0)=0$, 即$\sigma(\alpha\,or\,0)=0$与单射矛盾。反之，如果$\sigma(v_1)=0, \sigma(v_2)=0$，根据线性变换的定义或者性质得：$\sigma(v_1-v_2)=0\rightarrow v_1-v_2\in ker\,\sigma=\{0\}\rightarrow v_1=v_2\rightarrow \sigma$ 是单射。因此：$\sigma$是单射$\Leftarrow\Rightarrow ker\,\sigma=\{0\}$ 例子： 不变子空间定义 不变子空间的意义 那从这里头我们看到，我们希望把大空间分解成不变子空间的直和，从而能够取出合适的基底，从而使得线性变换在这组基底下的矩阵表示能够成为对角块的形状，那么对于线性变换的研究就转化成它限制在不变子空间上的研究以此为基础，看一下幂零变换的结构。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性变换1]]></title>
    <url>%2F2017%2F08%2F04%2Flinear_transformation_1st_part%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第四讲：线性变换1 前言历史上英国数学家Arthur Cayley是为了描述线性变换的复合而引入矩阵的乘法，从而使矩阵成为数学的研究对象。线性变换是两个向量空间之间保持线性运算的映射。线性代数就是从其中心问题（求解线性方程组）出发发展起来研究向量空间、线性变换以及研究相关数学问题的数学学科。对有限维向量空间的研究总可以转化成对矩阵的研究，这是线性代数的核心特点。 线性变换的定义性质运算回顾中学阶段学过的函数：$f(x)=2x\quad g(x)=x^{2}\quad l(x)=sin(x)$ 都是一个映射从定义域中的一个数映成值域中的一个数。推广到把向量映射到向量的映射比如f是从 $R^{3}$ 映到 $R^{2}$ 的一个映射：$f:\begin{pmatrix}x\\y\\z\end{pmatrix}\,\rightarrow\,\begin{pmatrix}2x\\3y-z\end{pmatrix}$，我们关心向量空间到向量空间的映射。人们发现平面上的点、空间中的点 、矩阵多项式函数、连续函数等等集合看上去不同但是它们各自的加法和数乘满足同样的性质，于是就引入了向量空间这样的一个抽象的概念来统一地研究向量空间的概念。 向量空间的定义 线性变换的定义 例子 注意，由线性变换的定义 $T:V\,\rightarrow\,W$ 得到 $T(0)=0$ 线性变换的性质 针对第一条证明： 如果 $T(0)\ne0$ 不满足线性变换定义 $T(cx)=cT(x)$，例如： $T(0)=1\,\rightarrow\,T(0)=T(c0)=1\,\ne\,cT(0)=c$ 针对第三条证明：若 $x_{1},\,…\,,x_{n}$ 线性相关，那么存在不全为0的数 $c_{1},\,…\,,c_{n}$ 满足 $c_{1}x_{1}\,+\,…\,+\,c_{n}x_{n}=0$ 即 $T(c_{1}x_{1}\,+\,c_{2}x_{2}\,+\,…\,+\,c_{n}x_{n})=T(0)=c_{1}f(x_{1})\,+\,…\,+\,c_{n}f(x_{n})=0$，即$T(x_{1}),\,…\,,T(x_{n})$ 线性相关。 线性变换的运算加法 数乘 乘积注：线性变换的乘积被定义为线性变换的复合运算 注意：线性变换不满足乘法交换律、消去律，与矩阵乘法类似 逆 幂 多项式 注：由于线性变换不满足乘法交换律，因此$(\sigma\tau)^{m}=\underbrace{(\sigma\tau)(\sigma\tau)\,…\,(\sigma\tau)}_{m个(\sigma\tau)相乘}\ne\sigma^{m}\tau^{m}$ 线性变化的矩阵表示 由于 $T(v_{1})$,$T(v_{2})$, … , $T(v_{3})\,\epsilon\,W$ 这个输出空间, 因此可以进行如下： 例子 线性变换与矩阵之间的关系一一对应 线性变换的乘积与矩阵的乘积 注（极其重要）：这里线性变换的乘积（复合）对应的是矩阵的“左乘”。 线性同构 例：设线性变换$\tau\,:\,R^{3}\rightarrow\,R^{2}$定义为$\tau(x,y,z)=(x+y,y-z)$, 线性变换$\sigma:R^{2}\,\rightarrow\,R^{2}$定义为$\sigma(u,v)=(2u-v,u)$.求线性变换$\sigma\tau:R^{3}\,\rightarrow\,R^{2}$在$R^{3}$与$R^{2}$标准基下的矩阵. 解：注意到$\sigma\tau=\sigma(\tau(x,y,z))=\sigma(x+y, y-z)=(2x+y+z, x+y)$ 因此标准基下线性变化$\sigma(\tau(x\,y\,z)):R^{3}\to\,R^{2}$: $$e_{1}=(1,0,0)^{T}, e_{2}=(0,1,0)^{T}, e_{3}=(0,0,1)^{T}\,\Rightarrow\, I_{3}=(e_{1}\,e_{2}\,e_{3})$$ $\sigma(\tau(e_{1}))=\sigma(\tau(\,(1,0,0)\,)=\begin{pmatrix}2\\1\\\end{pmatrix}\quad\sigma((\tau(e_{2}))=\begin{pmatrix}1\\1\\\end{pmatrix}\quad\sigma(\tau(e_{3}))=\begin{pmatrix}1\\0\\\end{pmatrix}$ $\sigma(\tau(e_{1}\,e_{2}\,e_{3}))=\sigma(\tau(I_{3}))=\underbrace{\begin{pmatrix}2&amp;1&amp;1\\1&amp;1&amp;0\end{pmatrix}}_{C}$ 第一个线性变化$\tau(x,y,z)=(x+y,y-z):R^{3}\,\to\,R^{2}$ : $$\tau(e_{1})=\tau(1,0,0)=(1+0,0+0)=(1,0)$$ $$\tau(e_{2})=\tau(0,1,0)=(0+1,1+0)=(1,1)$$ $$\tau(e_{3})=\tau(0,0,1)=(0+0,0+1)=(0,1)$$ $$\tau(I_{3})=\tau(e_{1}\,e_{2}\,e_{3})=\begin{pmatrix}1&amp;1&amp;0\\0&amp;1&amp;-1\end{pmatrix}=I_{2}\begin{pmatrix}1&amp;1&amp;0\\0&amp;1&amp;-1\end{pmatrix}$$ $$\underbrace{\begin{pmatrix}1&amp;1&amp;0\\0&amp;1&amp;-1\end{pmatrix}}_{A}\begin{pmatrix}x\\y\\z\end{pmatrix}=\begin{pmatrix}x+y\\y-z\end{pmatrix}$$ 第二个线性变化$\sigma(u,v)=(2u-v,u): R^{2}\,\to\,R^{2}$: $$\delta_{1}=(1,0)^{T}, \delta_{2}=(0,1)^{T}\,\Rightarrow\, I_{2}=(\delta_{1}\,\delta_{2})$$ $$\sigma(\delta_{1})=\begin{pmatrix}2\\1\end{pmatrix},\,\sigma(\delta_{2})=\begin{pmatrix}-1\\0\end{pmatrix}\Rightarrow\sigma(\delta_{1}\,\delta_{2})=I_{2}\begin{pmatrix}2&amp;-1\\1&amp;0\end{pmatrix}$$ $$\underbrace{\begin{pmatrix}2&amp;-1\\1&amp;0\end{pmatrix}}_{B}\begin{pmatrix}u\\v\end{pmatrix}=\begin{pmatrix}2u-v\\u\end{pmatrix}$$ 发现$BA=C\,\Rightarrow\,\begin{pmatrix}2&amp;-1\\1&amp;0\end{pmatrix}\begin{pmatrix}1&amp;1&amp;0\\0&amp;1&amp;-1\end{pmatrix}=\begin{pmatrix}2&amp;1&amp;1\\1&amp;1&amp;0\end{pmatrix}$，符合上文所说的线性变换的复合是对应矩阵的左乘。 结论：有限维向量空间上的线性变换$\leftarrow\rightarrow$矩阵]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[奇异值分解singular values decomposition]]></title>
    <url>%2F2017%2F08%2F03%2Fsingular_values_decomposition%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第三讲：奇异值分解 前言对角矩阵是我们最喜欢的一类矩阵，对能够相似于对角阵的矩阵能方便地计算其幂和指数，对不能相似于对角阵的方阵。上节课我们讨论了如何求出其尽可能简单的相似标准形及Jordan标准形以上讨论的都是方阵。那么对m乘n的矩阵我们如何来对它进行对角化呢？ 线性代数中最重要的一类矩阵分解即奇异值分解，从而回答以上的问题。对角矩阵是我们最喜欢的一类矩阵，因为给定一个对角阵立即就可以得到它的特征值，行列式，幂和指数函数等等。对角矩阵的运算跟我们熟悉的数的运算有很多相似之处，而一个n阶的矩阵相似于对角阵当且仅当它存在着n个线性无关的特征向量。特别地，实对称矩阵一定会正交相似于对角阵，也就是说给你一个实对称矩阵，一定存在着正交矩阵$Q$把它的列向量记成$v_1$到$v_n$，它能够满足$Q^TAQ$等于$\lambda$，$\lambda$是一个对角阵，它的对角元是$A$的特征值，那么其中$Q$的列向量$v_i$，它是矩阵$A$的属于特征值，$\lambda_i$的特征向量，也就是满足$Av_i$等于$\lambda_iv_i$。我们现在有个问题是说，如果对于$m \times n$的一个矩阵，我们如何来”对角化”它。那么也就是说在什么意义上，我们能够尽可能地。把$m \times n$的一个矩形的阵向对角阵靠拢，今天我们来讨论矩阵的奇异值分解它是线性代数应用中，最重要的一类矩阵分解。 $AA^T$与$A^TA$的特性$AA^T$与$A^TA$的特征值 $AA^T$与$A^TA$非0特征值集合 $A^TA$与$AA^T$的特征向量 令$u_i:={Av_i \over \sigma_i}\in\,R^m(1 \le i \le r) $，则 $AA^Tu_i=A(A^T\frac{Av_i}{\sigma_i})=A\frac{A^TAv_i}{\sigma_i}=A\frac{\sigma_i^2v_i}{\sigma_i}={\sigma_i}^2{Av_i \over \sigma_i}={\sigma_i}^2u_i$，得出：$AA^Tu_i={\sigma_i}^2u_i$。又因为：${u_i}^T{u_j}=\frac{(Av_i)^T}{\sigma_i}{Av_j \over \sigma_j}={v_i^T(A^TAv_j) \over \sigma_i\sigma_j}=\frac{\sigma_j^2{v_i}^Tv_j}{\sigma_i\sigma_j}={\sigma_j\over \sigma_i}v_i^Tv_j\rightarrow u_i^Tu_j=\begin{cases}0, &amp; i\ne j\\ 1, &amp; i=j\end{cases}$故：$\{u_i|1\le i \le r\}$ 是$AA^T$的单位正交特征向量。 根据假设（$v_1,\,…\,,v_n$是$A^TA$的单位交基，$\sigma_1^2,\,…\,,\sigma_n^2$是$AA^T$的特征值）得：$A^TAv_i=\sigma_i^2v_i(1\le i\le r) \rightarrow v_i^TA^TAv_i=v_i^T\sigma_i^2v_i=\sigma_i^2v_i^Tv_i \rightarrow ||Av_i||^2=\sigma_i^2 \rightarrow|Av_i|=\sigma_i$ 从$AA^T$得出SVD$(1)u_i:={Av_i \over \sigma_i}\in\,R^m(1 \le i \le r) \rightarrow Av_i=\sigma_iu_i\\ (2)A^TAv_i={\sigma_i}^2v_i, (i\le i \le r)\rightarrow A^T{Av_i\over \sigma_i}=\sigma_iv_i\rightarrow A^Tu_i=\sigma_iv_i$ 由上式子得：$U$是$A$列空间的一组单位正交基，$V$是$A^T$的列空间的一组单位正交基。$\sigma_i$是$Av_i$的长度，计$\begin{pmatrix}\sigma_1&amp;&amp;&amp;&amp;\\&amp;.&amp;&amp;&amp;\\&amp;&amp;.&amp;&amp;\\&amp;&amp;&amp;.&amp;\\&amp;&amp;&amp;&amp;\sigma_r\end{pmatrix}$为$\Sigma$，得：$A_{m\times n}V_{n\times r}=U_{m\times r}\Sigma_{r\times r}\rightarrow A_{m\times n}=U_{m\times r}\Sigma_{r\times r} {V^{-1}}_{r\times n}\\=U_{m\times r}\Sigma_{r\times r} {V^{T}}_{r\times n}$ 向量形式：$A=\sum_{i=1}^r \sigma_i u_i{v_i}^T$ SVD形式 例题 求$u_3$两种方法： 方法1：$AA^Tu_3=\begin{pmatrix}1&amp;0\\0&amp;1\\1&amp;-1\end{pmatrix}\begin{pmatrix}1&amp;0&amp;1\\0&amp;1&amp;-1\end{pmatrix}u_3=\begin{pmatrix}1&amp;0&amp;1\\0&amp;1&amp;-1\\1&amp;-1&amp;2\end{pmatrix}u_3=0u_3\rightarrow u_3={1\over\sqrt{3}}\begin{pmatrix}1\\ -1\\ -1\end{pmatrix}$ 方法2：$u_j:=\begin{pmatrix}x\\y\\z\end{pmatrix}, \sum_{i=1}^{r=3}u_iu_j=0 (i\ne j), ||u_j||^2=1\rightarrow u_{j=3}={1\over\sqrt{3}}\begin{pmatrix}1\\ -1\\ -1\end{pmatrix}$ svd几何意义 svd应用svd与矩阵的四个基本子空间 svd与图像压缩 奇异值与特征值关系 奇异值与奇异矩阵as]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[傅里叶级数]]></title>
    <url>%2F2017%2F08%2F02%2FFourier_series%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第10讲：傅里叶级数 引言 傅里叶级数Fourier series定义定义1设$f(x)$是周期为$2\pi$的有限个分段（piecewise）的连续函数（ continuous function）（即在$[\pi,-\pi]$中只有有限个点不连续，且不连续点的左右极限存在），那么它的傅里叶级数是 $F={a_0\over 2}+\sum\limits_{k=1}^{\infty}(\ a_kcos(kx)+b_ksin(kx)\ ), a_k={1\over \pi}\int_{-\pi}^{\pi}f(x)cos(kx)dx, b_k={1\over \pi}\int_{-\pi}^{\pi}f(x)sin(kx)dx,k=0,1,\ldots$，这个级数又称为傅里叶级数的实形式。 $f(x)$举例如下的$(1)$，而 $(2)$ 在周期内的不连续点处无极限。 定义2$f(x)$如上，它的傅里叶级数的复形式是$F=\sum\limits_{k=-\infty}^{+\infty}c_ke^{ikx}, c_k={1\over 2\pi}\int_{-\pi}^{\pi}f(x)e^{-ikx}dx$. 推导如下： 在定义1中，使用欧拉公式：$e^{ix}=cosx+isinx\Rightarrow cosx={e^{ix}+e^{-ix}\over 2},\ sinx={e^{ix}-e^{-ix}\over 2i}$ ，定义1中的傅里叶级数变成$F={a_0\over 2}+\sum\limits_{k=1}^{\infty}[{a_k\over 2}(e^{ikx}+e^{-ikx})-{ib_k\over 2}(e^{ikx}-e^{-ikx})]={a_0\over 2}+\sum\limits_{k=1}^{\infty}({a_k-ib_k\over 2}e^{ikx}+{a_k+ib_k\over 2}e^{-ikx}).$ 其中$a_k-ib_k={1\over 2\pi}\int_{-\pi}^{\pi}f(x)(e^{ikx}+e^{-ikx})dx-{i\over 2\pi}\int_{-\pi}^{\pi}f(x)\frac{e^{ikx}-e^{-ikx}}{i}dx ={1\over \pi}\int_{-\pi}^{\pi}e^{-ikx}dx,\ a_k+ib_k={1\over \pi}\int_{-\pi}^{\pi}e^{ikx}dx​$ , 令$c_k={a_k-ib_k\over 2}={1\over 2\pi}\int_{-\pi}^{\pi}f(x)e^{-ikx}dx,k=1,2,\ldots\quad c_{-k}={a_k+ib_k\over 2}={1\over 2\pi}\int_{-\pi}^{\pi}f(x)e^{ikx}dx,k=1,2,\ldots​$ 这样就得到定义2。注意：正如泰勒级数，这里并没有断言$f(x)​$等于它的傅里叶级数。 定理设$f(x)$是周期为$2\pi$的周期函数，$f(x)$和$f’(x)$均在$[-\pi, \pi]$上是分段连续的，则$f(x)$的傅里叶级数收敛，且在任意连续点$x=a$等于$f(a)$，在不连续点$x=a$等于${1\over 2}[lim_{x\rightarrow a^{+}}f(x)+lim_{x\rightarrow a^{-}}f(x)]$。 内积空间inner product space设$V$是一个向量空间（线性空间）（$R$或$C$上），$V$上的一个内积是这样一个函数 (-,-) : $V\times V\rightarrow R\ or\ C$ 满足： $\forall u\in V, (u,u)\ge0$，且若$(u,u)=0\rightarrow u=0$ $(c_1u+c_2v,w)=c_1(u,w)+c_2(v,w), u,v,w\in V, c_1,c_2\in R\ or\ C$ $\overline{(u,v)}=(v,u)$ 共轭对称 注：没有假设$v$是有限维的。第一条：$u$跟自己的内积必须是一个实数且是一个正数，或者说更确切地是一个非负数，如果$u$跟自己的内积是等于0的，那么就可以确定$u$就是$0$向量。第二条：两个向量的线性组合跟另一个向量的内积相当于两个向量跟另一个向量先作内积再做线性组合。第三条：$u$和$v$的内积与$v$和$u$的内积是一个共轭的关系，如果这个函数是定义在$V\times V\rightarrow R$，那么这个内积函数是个对称的，$u,v$的内积与$v,u$的内积是一样的，如果定义在复数上，那么就差一个共轭。 令$||u||=\sqrt{(u,u)}$，若$||u||=1$，则$u$ 是一个单位向量。任何一个向量$u\ne 0\rightarrow {v\over ||v||}$是一个单位向量，关于范数($||·||$)，这里范数是长度。 例 $V=R^2,u=\begin{pmatrix}a_1\\a_2\end{pmatrix}, v=\begin{pmatrix}b_1\\b_2\end{pmatrix},(u,v)=u^T v=a_1b_1+a_2b_2$ 是一个内积，$||u||=\sqrt{(a_1^2+a_2^2)}$。若$V=C^2$，$u,v\in C, (u,v)=u^T\bar{v}=a_1\overline{b_1}+a_2\overline{b_2}$ 。 $C[a,b]$是定义在区间$[a,b]$上的全体连续实函数构成的向量空间。定义连续函数的内积为$(f,g)=\int_{a}^{b}f(x)g(x)dx$ 。验证这个式子：$f(x)\in C[a,b], (f,f)\ge 0$ ，即 $(f,f)=\int_{a}^{b}{f(x)}^2dx=\int_{a}^{b}{|f(x)|}^2dx\ge 0$。若$(f,f)=0$，即$\int_{a}^{b}{|f(x)|}^2dx=0$，令$F(t)=\int_{a}^{t}{|f(x)|}^2dx, a\le t \le b$，则$F(t)=0, F(t)$可导，$F’(t)={|f(t)|}^2=0$，即$f(t)=0,t\in [a,b]$。在这里函数的长度的平方定义为函数与自身的内积，即$||f(x)||^2=(f(x),f(x))=\int_{a}^{b}f(x)f(x)dx$。 在例2中，若$C[a,b]$是$[a,b]$上的连续复函数的向量空间，则内积定义为：$(f,g)=\int_{a}^{b}f(x)\overline{g(x)}dx$。 标准正交系orthonormal system总结：若f(x)在区间$[a,b]$存在傅里叶级数，那么f(x)的傅里叶级数是f(x)在标准正交系$\{\frac{1}{\sqrt{2\pi}}, \frac{1}{\sqrt{\pi}}sinx, \frac{1}{\sqrt{\pi}}cosx, \frac{1}{\sqrt{\pi}}sin2x, \frac{1}{\sqrt{\pi}}cos2x, \ldots\}$下的投影。 周期函数的傅里叶级数对傅里叶级数的实数形式$F={a_0\over 2}+\sum\limits_{k=1}^{\infty}(\ a_kcos(kx)+b_ksin(kx)\ ), a_k={1\over \pi}\int_{-\pi}^{\pi}f(x)cos(kx)dx, b_k={1\over \pi}\int_{-\pi}^{\pi}f(x)sin(kx)dx,k=0,1,\ldots$进行变量代换，令 $x={\pi\over L}t, k=n$ 得：$ dx={\pi\over L}dt,\ t=\cases{L, x=\pi\\ -L, x=-\pi}\Rightarrow f(t)={a_0\over 2}+\sum\limits_{n=1}^{\infty}[a_ncos({n\pi t\over L})+b_nsin({n\pi t\over L})],\ a_n={1\over L}\int_{-L}^{L}f(t)cos({n\pi t\over L})dt, \\b_n={1\over L}\int_{-L}^{L}f(t)sin({n\pi t\over L})dt, n=0,1,\ldots$，对应的复数形式为： 投影注：$e^{ikx}=cos(kx)+isin(kx)\rightarrow (e^{ikx},e^{ikx})=2L, L$为半周期的绝对值，另外根据复函数的向量空间的内积定义为：$(f,g)=\int_{a}^{b}f(x)\overline{g(x)}dx \rightarrow (f(x),e^{ikx})$在周期 $[-\pi,\pi]$ 下为 $\int_{-\pi}^{\pi}f(x)e^{-iks}dx$ 。 关于傅里叶变换的注记Fourier series傅里叶级数和Fourier transformation傅里叶变换是傅里叶分析的主要部分。设$f(t)$周期$T=2L$，则$f(t)$的傅里叶级数展开为$f(t)=\sum\limits_{k=-\infty}^{\infty}c_ke^{\frac{ik\pi}{L}t},c_k={1\over 2L}\int_{-L}^{L}f(t)e^{\frac{-ik\pi}{L}t}dt$ ($c_k$是$f(t)$在$e^{\frac{ik\pi}{L}t}$上的投影)。现在考虑定义在$(-\infty, +\infty)$上的非周期函数$f(t)$，它有傅里叶级数展开形式吗？ 给定$L&gt;0$，定义$f_L(t)=\cases{f(t), |t|&lt;L\\0 , \quad\ |t| \ge L}$。假设$L\rightarrow \infty$时，$f_L(t)$（一致）趋近于$f(t)$。函数 $f_L(t)$ 能被周期延拓，即令$F_L(t)=\cases{f(t), -L&lt; t \le L\\ F_L(t+2L), T=2L}$ 则 $F_L(t)$有傅里叶级数。 当 $-L&lt;t&lt;L,f(t)=f_L(t)=F_L(t)=\sum\limits_{k=-\infty}^{\infty}c_k(L)e^{\frac{ik\pi}{L}t},c_k(L)={1\over 2L}\int_{-L}^{L}f_L(t)e^{\frac{-ik\pi}{L}t}dt$ 因为 $f_L(t)=0, |t|&gt;L \rightarrow c_k(L)={1\over 2L}\int_{-L}^{L}f_L(t)e^{\frac{-ik\pi}{L}t}dt={1\over 2L}\int_{-\infty}^{\infty}f_L(t)e^{\frac{-ik\pi}{L}t}dt$ 由于 $k\rightarrow\infty$ 同时 $L\rightarrow \infty$ ，所以等式右边的指数项未知，因此做变量代换，令 $\tilde{f}_L(w)=\int_{-\infty}^{\infty}f_L(t)e^{-iwt}dt$，令 $w_k={k\pi\over L}$ 则$c_k(L)={1\over 2L}\tilde{f}(\frac{k\pi}{L})={1\over 2L}\tilde{f}({w_k})={1\over 2\pi}\tilde{f}({w_k})(w_{k+1}-w_k)$ 那么得到傅里叶展开的新形式：$f_L(t)=F_L(t)={1\over 2\pi}\sum\limits_{-\infty}^{+\infty}\tilde{f}_L(w_k)e^{iw_kt}\Delta w_k, \tilde{f}_L(w)=\int_{-\infty}^{+\infty}f_L(t)e^{-iw_kt}dt, \Delta w_k=w_{k+1}-w_{k}={\pi\over L}$。当$L\rightarrow +\infty, \Delta w\rightarrow 0$，等式左边$f_L(t)$（一致）趋近于$f(t)$，右边就趋近于一个积分形式：$ f(t)={1\over 2\pi}\int_{-\infty}^{+\infty}\tilde{f}_L(w)e^{iwt}dw$， 称$\tilde{f}(w)$是$f(t)$的傅里叶变换，$f(t)$是$\tilde{f}(w$)的逆傅里叶变换。 $f(t)$实际上是关于时间函数的$sin\ cos$之间叠加出来的，那么$\tilde{f}(ω)$是关于这些频率叠加出来的，它是频率的函数。讲复矩阵的时候将会回到这个傅里叶变换，会考虑傅里叶变换的离散形式，那么$f(x)$或者$f(t)$就被一个向量替换，$\tilde{f}(ω)$也被一个向量替换，它们之间互逆的这种傅里叶变换或者逆傅里叶变换的关系，实际上就是通过一个傅里叶矩阵进行互相转换的，以及相应的快速的傅里叶变换。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[positive definite and least squares]]></title>
    <url>%2F2017%2F08%2F01%2Fpositive_definite_and_least_square%2F</url>
    <content type="text"><![CDATA[positive definiteWhen a symmetric matrix $A$ has one of these five properties, it has them all and $A$ is positive definite: all n eigenvalue are positive. all n principal minors(n upper left determinants) are positive. all n pivots are positive. $x^{T}Ax$ is positive except when $x = 0$ (this is usually the definition of positive definiteness and the energy-based definition). $A$ equals $R^{T}R$ for a matrix $R$ with independent columns. Let us prove the fifth rule. If $A = R^{T}R$, then $$\begin{eqnarray}x^{T}Ax&amp;=&amp;x^{T}R^{T}Rx \nonumber\\&amp;=&amp;(x^{T}R^{T})Rx \nonumber\\&amp;=&amp;(Rx)^{T}Rx \nonumber\\&amp;=&amp;|Rx| \nonumber\\&amp;\ge&amp;0 \nonumber\end{eqnarray}$$ And the columns of $R$ are also independent, so $|Rx|=x^{T}Ax&gt;0$, except when $x$=0 and thus $A$ is positive definite. $A^{T}A$$A_{m\times n}$ is almost certainly not symmetric, but $A^{T}A$ is square (n by n) and symmetric. We can easily get the following equations through left multiplying $A^{T}A$ by $x^{T}$ and right multiplying $A^{T}A$ by $x$: $$\begin{eqnarray}x^{T}A{^TA}x&amp;=&amp;x^{T}(A{^TA})x\nonumber\\&amp;=&amp;(x^{T}A^{T})Ax\nonumber\\&amp;=&amp;(Ax)^{T}(Ax)\nonumber\\&amp;=&amp;|Ax|\nonumber\\&amp;\ge&amp;0\nonumber\end{eqnarray}$$ If $A_{m\times\,n}$ has rank $n$ (independent columns), then except when $x = 0$, $Ax=|Ax|=x^{T}(A{^TA})x&gt;0$ and thus $A^{T}A$ is positive definite. And vice versus. Besides, $A^{T}A$ is invertible only if $A$ has rank $n$ (independent columns). To prove this, we assume $Ax=0$, then: $$\begin{eqnarray}Ax&amp;=&amp;0\nonumber\\(Ax)^{T}(Ax)&amp;=&amp;0\nonumber\\(x^{T}A{^T})(Ax)&amp;=&amp;0\nonumber\\x^{T}A{^T}(Ax)&amp;=&amp;x^{T}0\nonumber\\(A{^TA})x&amp;=&amp;0\nonumber\end{eqnarray}$$ From the above equations, we know solutions of $Ax=0$ are also solutions of $(A{^TA})x=0$. Because $A_{m\times\,n}$ has a full set of column rank (independent columns), $Ax=0$ only has a zero solution as well as $(A{^T}A)x=0$. Furthermore, if $A{^T}A$ is invertible, then $A_{m\times\,n}$ has rank $n$ (independent columns). We also notice that if $A$ is square and invertible, then $A{^T}A$ is invertible. Overall, if all columns of $A_{m\times\,n}$ are mutual independent, then $(A{^T}A)$ is invertible and positive definite as well, and vice versus. least squareWe have learned that least square comes from projection :$$b-p=e\Rightarrow\,A^{T}(b-A\hat{x})=0\Rightarrow\,A^{T}A\hat{x}=A^{T}b$$Consequently, only if $A^{T}A$ is invertible, then we can use linear regression to find approximate solutions $\hat{x}=(A^{T}A)^{-1}A^{T}b$ to unsolvable systems of linear equations. According to the reasoning before, we know as long as all columns of $A_{m\times\,n}$ are mutual independent, then $A{^T}A$ is invertible. At the same time we ought to notice that the columns of $A$ are guaranteed to be independent if they are orthoganal and even orthonormal. In another prospective, if $A^{T}A$ is positive definite, then $A_{m\times\,n}$ has rank $n$ (independent columns) and thus $A^{T}A$ is invertible. Overall, if $A^{T}A$ is positive definite or invertible, then we can find approximate solutions of least square.]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正定矩阵]]></title>
    <url>%2F2017%2F08%2F01%2Fpositive_definite_matrix%2F</url>
    <content type="text"><![CDATA[笔记源自：清华大学公开课：线性代数2——第一讲：正定矩阵 引言 矩阵特征值的正负在求解微分方程和差分方程时，会影响解是否收敛，例如上图如果$\lambda_i &lt; 0$那么$e^{\lambda_i t}$ 随着$t\rightarrow \infty, e^{\lambda_it}\rightarrow0$ 主子式 实对称矩阵A正定的充要条件下列6项条件，满足任意一项即可判定实对称矩阵$A$为正定矩阵： 证明$(1)\Rightarrow(2):$ 对实对称矩阵$A$，那么存在正交阵$Q$，使得$AQ=Q\Lambda \rightarrow A=Q\Lambda Q^T$，其中$\Lambda=diag(\lambda_1,\,…\,,\lambda_n)$。于是对于任意非零向量$x$，有$x^TAx=x^TQ\Lambda Q^Tx=y^T \Lambda y=\lambda_1 {y_1}^2+\,…\,+\lambda_n {y_n}^2&gt;0, y=Q^Tx=(y_1,\,…\,,y_n) \ne\vec{0}$ $(2)\Rightarrow(1):​$ 设$Ax=\lambda x(x\ne0)​$ 则$0&lt;x^TAx=x^T\lambda x=\lambda||x||^2​$，因此所有$\lambda_i&gt;0​$。 $(2)\Rightarrow(3):$ 由于行列式等于矩阵特征值的乘积，故$(2)\Rightarrow(1)\Rightarrow (3)det A=\lambda_1\,…\,\lambda_n&gt;0$ ： $(2)\, 0&lt;\begin{pmatrix}x_k^T&amp;0\end{pmatrix} \begin{pmatrix}A_k&amp;*\\*&amp;*\end{pmatrix}\begin{pmatrix}x_k\\0\end{pmatrix}={x_k}^T A_k x_k = {x_k}^T \begin{pmatrix} \lambda_1&amp;\\&amp;\ddots\\&amp;&amp;\lambda_k \end{pmatrix} x,\, (1 \le k \le n) \\\Rightarrow (1) \lambda_i &gt; 0,(1\le i \le k, 1 \le k \le n) \Rightarrow (3) detA_k&gt;0, (1 \le k \le n)$ $(3)\Rightarrow(4)$：顺序主子式与主元有直接联系，因为第k个主元$d_k={det A_k \over det A_{k-1}}$，所以$(3) \Rightarrow (4)\,d_k &gt; 0$，其中$A_k$是第$k$个顺序主子矩阵（the k-th leading principal sub-matrix）。 $(4) \Rightarrow (2)$：由对称矩阵的Gauss消元法得$A=LDL^T$且对角阵$D=diag(d_1,\,…\,d_n)$ 的对角元为A的主元，$L$是下三角矩阵，$L^T$ 是上三角矩阵，而且根据分解结果知道$L$的主对角线上全元素为1，也即$L^T$的主元全为1，即$L^T$行列式为1且是方阵，那么这俩都可逆。因为$(4):d_1,\,…\,,d_n$大于0，那么到：$x\ne 0\Rightarrow y=L^Tx\ne 0\Rightarrow x^TAx=x^TLDL^Tx=y^TDy=d_1y_1^2+…+d_ny_n^2&gt;0$ 。 可逆矩阵齐次方程只有零解 $(2)\Rightarrow(5)$：$A=LDL^T=L\sqrt{D}\sqrt{D}L^T=(\sqrt{D}L^T)^T(\sqrt{D}L^T)$，此时可取$R=\sqrt{D}L^T$，因为$\sqrt{D}, L^T$ 都可逆且都是方阵，由于$(2)\Rightarrow(3)\Rightarrow(4)$ ，因此$\sqrt{D}&gt;0$，且有上面推导得$|L^T|&gt;0$， 可逆矩阵乘积还是可逆。 根据行列式性质：$ |A||B|=|AB|$, 当$A,B$ 均可逆，那么$|A|&gt;0, |B|&gt;0 \rightarrow |AB|&gt;0$, 所以$AB$也可逆。 或者：$A=Q\Lambda Q^T=Q\sqrt{\Lambda}\sqrt{\Lambda}Q^T=(\sqrt{\Lambda}Q^T)(\sqrt{\Lambda}Q^T)$，此时可取 $R=\sqrt{\Lambda}Q^T$ ，同理可得。 $(5)\Rightarrow(2)$：$A=R^TR\Rightarrow x^TAx=x^TR^TRx=(Rx)^TRx=||Rx||^2 \ge 0$且$R$是列满秩，除了$x=0$之外，其余 $x^TAx=||Rx||^2 &gt; 0$，即$(5)\Rightarrow(2)$ $(6)\Leftarrow\Rightarrow(2)$: 典型例子 正定矩阵的性质如果$A,B$是正定矩阵，那么$A+B$也是正定矩阵 如果$A$为正定矩阵，则存在矩阵$C$，满足$A=C^2$ 如果$A$为正定矩阵，则矩阵$A$的幂也是正定的 如果$A$为正定矩阵，矩阵$C$，那么$B=C^TAC$也是正定的 注：其实B称为A的合同矩阵 半正定矩阵的判别条件 二次型定义 注意：这里证明里面 ${A-A^T\over 2}$ 是反对称矩阵，利用反对称矩阵性质，所以 $x^T{A-A^T\over 2}x=0$ 。二次型与判定正定矩阵的第二条准则密切相关。 例子 对角形 二次型化成对角形 注：由于实对称矩阵$A$可以与二次型一一对应，因此，可以借助实对称矩阵研究二次型。 主轴定理principal axis theorem 有心二次型central_conic 三维空间中的二次曲面-6类基本的二次曲面$R^3$种的二次曲面的方程形如:$a_{11}x^2+a_{22}y^2+a_{33}z^2+2a_{12}xy+2a_{13}xz+2a_{23}yz+b_{1}x+b_{2}y+b_{3}z+c=0$. 注：由于二次型可以与实对称对称矩阵一一对应，二次型里面又包括二次曲面，所以实对称矩阵可以跟二次曲面对应起来。 二次型的分类 二次型与特征值 二次型的一个应用——求二次型的几何形状 把二次型的部分去化成对角形的标准型，相应的这个一次项也作了变换，于是再做配方然后去跟基本的形状做比较得出这个曲面的几何形状，这是二次型的一个应用。 合同congruent前言 注：非退化矩阵即满秩矩阵 定义 例子 主轴定理与合同 合同的性质 证明:矩阵$A$左乘可逆矩阵$C^T$相当于做初等行变换，右乘以可逆矩阵$C$相当于做初等列变换，因此根据消元法知道并不改变矩阵$A$的秩。对称性保持证明在于二次型定义可以看到。 1.利用初等变换不改变矩阵的秩，因为可逆矩阵可以表示为初等矩阵的乘积，而A乘初等矩阵相当于对A作初等变换，所以A的秩不变-。这个方法包括了可逆矩阵左乘A，右乘A，或是左右同时乘A 2.利用 r(AB) 惯性定理Sylvester’s law of inertia的证明 惯性定理的应用 正负定矩阵在函数极值中的应用以二元函数$f(x,y)$为例：设$(x_0,y_0)$是二元函数$f(x,y)$的一个稳定点，即：$\frac{\partial f}{\partial x}(x_0,y_0)={\partial{f}\over \partial{y}}(x_0,y_0)=0$。如果$f(x,y)$在$(x_0,y_0)$的领域里有三阶偏导数，则$f(x,y)$在$(x_0,y_0)$可展开成Talor级数： 黑塞Hessian矩阵黑塞矩阵（Hessian Matrix），又译作海森矩阵、海瑟矩阵、海塞矩阵等，是一个多元函数的二阶偏导数构成的方阵，描述了函数的局部曲率。黑塞矩阵最早于19世纪由德国数学家Ludwig Otto Hesse提出，并以其名字命名。黑塞矩阵常用于牛顿法解决优化问题，利用黑塞矩阵可判定多元函数的极值问题。在工程实际问题的优化设计中，所列的目标函数往往很复杂，为了使问题简化，常常将目标函数在某点邻域展开成泰勒多项式来逼近原函数，此时函数在某点泰勒展开式的矩阵形式中会涉及到黑塞矩阵。]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linear_algebra</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim无插件使用]]></title>
    <url>%2F2016%2F01%2F20%2Fvim_without_widgets%2F</url>
    <content type="text"><![CDATA[本文根据使用经验，会持续更新。 vim的四种模式 一般模式：normal模式。可以移动光标，删除字符或整行，也可复制、粘贴文件数据。打开vim就是进入这个模式，3个模式的切换也是在这里中转。 编辑模式：一般模式下按下i I o O a A r R s S 任何一个进入该模式。可以编辑文件内容，按Esc回到一般模式。 i I是insert（在光标所在字符前和行首） o O是open新行（在光标所在行的下面另起一新行和在光标所在行的上面另起一行开始插入 a A是append（在在光标所在字符后和在光标所在你行的行尾） s S 是删除（光标所在的字符并开始插入和光标所在行并开始插入），即substitute替换。 r R是replace光标所在的字符和变成替换模式 命令行模式：一般模式下按下: / ？任何一个进入该模式（下文会介绍这些符号的含义）。可以查找数据操作，读取、保存、大量替换字符、离开vim、显示行号等操作，按Esc回到一般模式。 可视模式：一般模式下按下v V ctr+v 进入可视模式，相当于高亮选取文本后的普通模式，即在该模式下进行任意选择特定区域且被选择的区域高亮显示，v选择单位：一个字符； V 又称为可视行模式，选择单位：行；ctr+v又称为可视块模式，选择的单位：方块；这三者都有用，详细看下文。 移动normal模式下： w → 到下一个单词的开头 e → 到下一个单词的结尾 （单词默认是以空格分隔的）W → 到下一个字符串的开头 E → 到下一个字符串的结尾 (字符串指的是数字、字母、下划线组成的字符串)B → 到前一个字符串的首字符上 b → “命令则将光标移动到前一个word的首字符上。 默认上来说，一个单词由字母，数字和下划线组成 如果你认为单词是由blank字符分隔符，那么你需要使用大写的E和W（陈皓: 注） 0 → 数字零，到行头^ → 到本行第一个不是blank字符的位置（所谓blank字符就是空格，tab，换行，回车等）$ → 到本行行尾g_ → 到本行最后一个不是blank字符的位置% → 到光标所在这对括号的另外一个gg → 首行G → 最后一行h j k l (强例推荐使用其移动光标，但不必需) →你也可以使用光标键 (←↓↑→). 注: j 向下伸，k是向上伸 高频使用场景1： 修改行中某个变量名 先移把光标移动：w and b 、W and B （或者如果本行太长可用下文的搜索功能）到目的单词 高频使用场景2： 修改缩进，跳到行头^ 高频使用场景3： 查看函数或类的完整或者变量作用域% 高频使用场景4： 切分屏幕之后，跳转不同窗口：ctrl+w+(h or j or k or l) 高频使用场景5： 左下上右移动（h、j、k、l） 高频使用场景6： 删除到末尾:d$ 删除到开头: d^ 标记简记：标记是为了更好地查找，normal模式下： mx mean: mark x, x is mark name;&#39;x mean: go to the position of x mark 高频使用场景1： 在函数中看到调用其他函数，你想去看怎么定义的，你看完之后要回来，那么先标记一下，然后在跳回来。 语法相关的跳转normal模式下： gd 意思： go to definition 先按 [ 再按 ctrl+d 跳转到#define处 语言支持不太良好 先按 [ 再按 ctrl+i 跳转到函数、变量和#define 语言支持不太良好 快速翻页normal模式下： 伙伴1 伙伴2 ctr + d page down ctr + u page up ctr + f page former ctr + b page back 动作操作指令normal模式下： 伙伴1 伙伴2 d delete a character and copy to clipboard D 从光标所在位置一直删除到行尾 y copy to clipboard Y 复制一行(=yy) s substitue a character S 替换光标所在行 r replace a character R 不常用，表示进入替换模式 c change a character C 不常用，表示修改光标所在位置一直到行尾，与S呈现效果一样 p paste after the cursor P 黏贴在光标位置之前（如果是黏贴一整行，则黏贴到上一行） u undo a operation U 一次性撤销对一整行的所有操作 x cut a character X 不常用， 向左剪切，即退格：删除光标的左边那个字符 * 向下搜索当前光标所在的单词，找到就跳到下一个单词 # 向上搜索当前光标所在的单词，找到就跳到上一个单词 /word 向下全文搜索单词word，跳到匹配的第一个单词，如果多个，继续向下查找按n键（顺着命令本来方向），向上找按N键。 ?word 向上全文搜索单词word，跳到匹配的第一个单词，如果多个，继续向上查找按n键（顺着命令本来方向），向下找按N键。 a append after the cursor A是附加在光标所在行的行尾） i insert before the cursor I插入在光标所在行的行首 o 在光标所在行的下面另起一新行，open the new world？ O在光标所在行的上面另起一行开始插入 v 进入visual模式，用来选择区域（可跨行），用来配合后续的其他操作（增删改查） v 进入visual行模式，用来选择一些行，用来配合后续的其他操作（增删改查） f find a character after the cursor F 向光标位置之前查找一个字符 t till a character tx和fx相同，区别是跳到字符x前 T Tx 和Fx相同，区别是跳到字符x后 单独成型. 重复刚才的操作~ 转换大小写 可以对变量首字母改变大小写 可以结合下文提供的命令的选择一个字符串（变量），然后再改变整个字符串（变量）的大小写。比如：宏定义 = 自动格式化 对当前行用== （连按=两次）, 或对多行用n==（n是自然数）表示自动缩进从当前行起的下面n行 或者进入可视行模式选择一些行后再=进行格式化，相当于一般IDE里的code format。 使用gg=G可对整篇代码进行排版。 撤销和恢复 u undo撤销上一步的操作，命令可以组合，例如Nu N是任意一个整数，表示撤销N步操作，以下类同。 U 恢复当前行（即一次撤销对当前行的全部操作） ctr+r control+redo 恢复上一步被撤销的操作 CTRL-R 回退前一个命令 文本替换normal 模式下输入替换命令： :[range]s/pattern/string/[flags] pattern 就是要被替換掉的字串，可以用 regexp 來表示。 string 將 pattern 由 string 所取代。 [range] 有以下一些取值： [range] 含义 无 默认为光标所在的行 . 光标所在当前的行 N 第N行 $ 最后一行 &#39;a 标记a所在的行（之前要使用ma做过标记） .+1 当前光标所在行的下面一行 $-1 倒数第二行，可以对某一行加减某个数值来确定取得相对的行 22,33 第22～33行 1,$ 第1行 到 最后一行 1,. 第1行 到 当前行 .,$ 当前行 到 最后一行 &#39;a,&#39;b 标记a所在的行 到 标记b所在的行（之前要使用ma和mb做过标记） % 所有行（与 1,$ 等价） ?str? 从当前位置向上搜索，找到的第一个str所在的行 （其中str可以是任何字符串或者正则表达式） /str/ 从当前位置向下搜索，找到的第一个str所在的行（其中str可以是任何字符串或者正则表达式） 注意，上面的所有用于range的表示方法都可以通过 +、- 操作来设置相对偏移量。 [flags]有以下一些取值： flags 含义 g 对指定范围内的所有匹配项（global）进行替换 c 在替换前请求用户确认（confirm） e 忽略执行过程中的错误 i ignore 不分大小写 无 只对指定范围内的第一个匹配项进行替换 注意：上面的所有flags都可以组合起来使用，比如 gc 表示对指定范围内的 所有匹配项进行替换，并且在每一次替换之前都会请用户确认。 例子替换某些行的内容 :10,20s/from/to/g 对第10行到第20行的内容进行替换。 :1,$s/from/to/g 对第一行到最后一行的内容进行替换（即全部文本） :1,.s/from/to/g 对第一行到当前行的内容进行替换。 :.,$s/from/to/g 对当前行到最后一行的内容进行替换。 :&#39;a,&#39;bs/from/to/g 对标记a和b之间的行（含a和b所在的行）进行替换，其中a和b是之前用m命令所做的标记。 替换所有行的内容：:%s/from/to/g 动作的重复normal模式下，任意一个动作都可以重复 注：N是数字 数字：Nyy从当前行算起向下拷贝N行、Ndd从当前行算起向下删除N行、Ngg跳到第N行、dNw删除从当前光标开始到第N个单词前（不包含空白，即删除N-1个单词)、yNe拷贝从当前光标到第N个单词末尾（注意： yy=1yy dd=1dd）、d$删除到本行末尾 重复前一个命令： .N （N表示重复的次数） 区块选择注：中括号内容为可选项 normal模式下：[ctr + ] v + (h or j or k or l) 高频使用场景1: [ctr + ] v 选中某些行的行头之后 再按= 效果：代码格式自动调整 高频使用场景2: [ctr + ] v 选中某些行的行头之后 再按I再按注释的符号（比如：//）最后按ESC 效果：选中的这些行全部注释了 多行快速注释 高频使用场景3: [ctr + ] v 选中某些行的行头之后 再按A再按注释的内容 最后按 ESC（比如：//这是测试代码） 效果：选中的这些行的行尾全部注释上//这是测试代码 多行快速注释 高频使用场景4: [ctr + ] v 选中某些行的行头的注释（比如：//）之后 再按d 最后按ESC 效果：选中的这些行全部注释删除了 多行快速删除注释 高频使用场景5: [ctr + ] v 选中某些区块之后，再按上文动作的按键实现区域操作 组合的强大操作光标所在的一个单词normal模式下： 动作 + 移动 [+重复次数]前面已经已经大量使用组合，这里继续： 动作操作指令+范围 效果 cw or c1 or c1w change from current cursor to word end caw change whole word including current cursor dw or d1 or d1w delete from current cursor to word end daw delete whole word including current cursor yw or y1 or y1w copy from current cursor to word end yaw copy whole word including current cursor 范围+动作操作指令 效果 bve 或 BvE + c/d/y 操作一个变量或字符串 上表都是高频使用场景 自动补全在insert模式下直接按： 最常用的补全 12ctrl + n ctrl + p 智能补全 1ctrl + x //进入补全模式 整行补全 CTRL-X CTRL-L 根据当前文件里关键字补全 CTRL-X CTRL-N 根据字典补全 CTRL-X CTRL-K 根据同义词字典补全 CTRL-X CTRL-T 根据头文件内关键字补全 CTRL-X CTRL-I 根据标签补全 CTRL-X CTRL-] 补全文件名 CTRL-X CTRL-F 补全宏定义 CTRL-X CTRL-D 补全vim命令 CTRL-X CTRL-V 用户自定义补全方式 CTRL-X CTRL-U 拼写建议 CTRL-X CTRL-S //例如：一个英文单词 折叠normal模式下： 123zo (折+open)zi (折+indent)zc (折+close) 切分屏幕切分命令，normal模式下，输入 vs(说明：vertically split 纵向切分屏幕） sp(说明：split 横向切分屏幕，即默认的切分方式） 屏幕相互跳转 ctr + w 再按 h或j或k或l 解释：h: left , j : down , k : up, l : right 调整切分窗口的大小 ctrl+w 在按 + 或 - 或 = ，当然在按 + 或 - 或 = 之前先按一个数字，改变窗口高度，= 是均分的意思。。 在normal模式下 输入：resize -N 或 :resize +N 明确指定窗口减少或增加N行 ctrl+w 在按 &lt; 或 &gt; 或 = ，当然在按 &lt; 或 &gt; 或 = 之前先按一个数字，改变窗口宽度，= 是均分的意思。 有时候预览大文件，感觉切分的屏幕太小，ctrl+w + T 移动当前窗口至新的标签页。 tab窗口vim 从 vim7 开始加入了多标签切换的功能， 相当于多窗口. 之前的版本虽然也有多文件编辑功能， 但是总之不如这个方便啦。 用法normal模式下： :tabnew [++opt选项] ［＋cmd］ 文件 建立对指定文件新的tab :tabc 关闭当前的tab or :q :tabo 关闭其他的tab :tabs 查看所有打开的tab :tabp 前一个previous tab window :tabn 后一个next tab window 标准模式下： gt , gT 可以直接在tab之间切换。 还有很多他命令， :help table 吧。 目录normal模式下： :Te 以tab窗口形式显示当前目录 然后可进行切换目录、打开某个文件 :!ls 这种是vim调用shell命令的方式:!ls + shell_command,但不是以tab窗口的形式显示当前目录。 成对符号的内容操作以下命令可以对标点内的内容进行操作： ci&#39; ci&quot; ci( ci[ ci{ ci&lt; 分别change这些配对标点符号中的文本内容 di&#39; di&quot; di(或dib di[ di{或diB di&lt; 分别删除这些配对标点符号中的文本内容 yi&#39; yi&quot; yi( yi[ yi{ yi&lt; 分别复制这些配对标点符号中的文本内容 vi&#39; vi&quot; vi( vi[ vi{ vi&lt; 分别选中这些配对标点符号中的文本内容 cit dit yit vit 分别操作一对标签之间的内容，编辑html很好用 另外如果把上面的 i 改成 a 可以同时操作配对标点和配对标点内的内容，举个例子： 比如要操作的文本：111”222”333，将光标移到”222”的任何一个字符处输入命令 di” ,文本会变成： 111””333 若输入命令 da” ,文本会变成： 111333 剪贴板1. 简单复制和粘贴vim提供12个剪贴板，它们的名字分别为vim有11个粘贴板，分别是0、1、2、…、9、a、“。如果开启了系统剪贴板，则会另外多出两个+和*。使用:reg命令，可以查看各个粘贴板里的内容。 在vim中简单用y 只是复制到 &quot; 的粘贴板里，同样用p 粘贴的也是这个粘贴板里的内容。 2. 复制和粘贴到指定剪贴板要将vim的内容复制到某个粘贴板，进入正常模式后，选择要复制的内容，然后按 &quot;Ny 完成复制，其中N为粘贴板号（注意是按一下双引号然后按粘贴板号最后按y），例如要把内容复制到粘贴板a，选中内容后按”ay就可以了。 要将vim某个粘贴板里的内容粘贴进来，需要退出编辑模式，在正常模式按&quot;Np，其中N为粘贴板号。比如，可以按&quot;5p将5号粘贴板里的内容粘贴进来，也可以按&quot;+p将系统全局粘贴板里的内容粘贴进来。 3. 系统剪贴板查看vim支持的剪切板，normal模式下输入：reg 和系统剪贴板的交互又应该怎么用呢？遇到问题一般第一个寻找的是帮助文档，剪切板即是 Clipboard。通过:h clipboard 查看帮助 星号和加号+粘贴板是系统粘贴板。在windows系统下， 和 + 剪贴板是相同的。对于 X11 系统， 剪贴板存放选中或者高亮的内容， + 剪贴板存放复制或剪贴的内容。打开clipboard选项，可以访问 + 剪贴板；打开xterm_clipboard，可以访问 剪贴板。 * 剪贴板的一个作用是，在vim的一个窗口选中的内容，可以在vim的另一个窗口取出。 复制到系统剪贴板 example： &quot;*y &quot;+y &quot;+Nyy 复制N行到系统剪切板 解释： 命令 含义 {Visual}”+y copy the selected text into the system clipboard “+y{motion} copy the text specified by {motion} into the system clipboard :[range]yank+ copy the text specified by [range] into the system clipboard 剪切到系统剪贴板 example： “+dd 从系统剪贴板粘贴到vim normal模式下： &quot;*p &quot;+p :put+ 含义： Ex command puts contents of system clipboard on a new line 插入模式下： &lt;C-r&gt;+ 含义： From insert mode (or commandline mode) “+p比 Ctrl-v 命令更好，它可以更快更可靠地处理大块文本的粘贴，也能够避免粘贴大量文本时，发生每行行首的自动缩进累积，因为Ctrl-v是通过系统缓存的stream处理，一行一行地处理粘贴的文本。 vim编码Vim 可以很好的编辑各种字符编码的文件，这当然包括UCS-2、UTF-8 等流行的 Unicode 编码方式。 四个字符编码选项，encoding、fileencoding、fileencodings、termencoding (这些选项可能的取值请参考 Vim 在线帮助 :help encoding-names，它们的意义如下: encoding: Vim 内部使用的字符编码方式 包括 Vim 的 buffer (缓冲区)、菜单文本、消息文本等。默认是根据你的locale选择.用户手册上建议只在 .vimrc 中改变它的值，事实上似乎也只有在.vimrc 中改变它的值才有意义。你可以用另外一种编码来编辑和保存文件，如你的vim的encoding为utf-8,所编辑的文件采用cp936编码,vim会自动将读入的文件转成utf-8(vim的能读懂的方式），而当你写入文件时,又会自动转回成cp936（文件的保存编码). fileencoding: Vim 中当前编辑的文件的字符编码方式 Vim 保存文件时也会将文件保存为这种字符编码方式 (不管是否新文件都如此)。 fileencodings: Vim会自动探测编码设置项 启动时会按照它所列出的字符编码方式逐一探测即将打开的文件的字符编码方式，并且将 fileencoding 设置为最终探测到的字符编码方式。因此最好将Unicode 编码方式放到这个列表的最前面，将拉丁语系编码方式 latin1 放到最后面。 termencoding: Vim 所工作的终端 (或者 Windows 的 Console 窗口) 的字符编码方式 如果vim所在的term与vim编码相同，则无需设置。如其不然，你可以用vim的termencoding选项将自动转换成term的编码.这个选项在 Windows 下对我们常用的 GUI 模式的 gVim 无效，而对 Console 模式的Vim 而言就是 Windows 控制台的代码页，并且通常我们不需要改变它。 好了，解释完了这一堆容易让新手犯糊涂的参数，我们来看看 Vim 的多字符编码方式支持是如何工作的。 Vim 启动，根据 .vimrc 中设置的 encoding 的值来设置 buffer、菜单文本、消息文的字符编码方式。 读取需要编辑的文件，根据 fileencodings 中列出的字符编码方式逐一探测该文件编码方式。并设置 fileencoding 为探测到的，看起来是正确的 (注1) 字符编码方式。 对比 fileencoding 和 encoding 的值，若不同则调用 iconv 将文件内容转换为encoding 所描述的字符编码方式，并且把转换后的内容放到为此文件开辟的 buffer 里，此时我们就可以开始编辑这个文件了。注意，完成这一步动作需要调用外部的 iconv.dll(注2)，你需要保证这个文件存在于 $VIMRUNTIME 或者其他列在 PATH 环境变量中的目录里。 编辑完成后保存文件时，再次对比 fileencoding 和 encoding 的值。若不同，再次调用 iconv 将即将保存的 buffer 中的文本转换为 fileencoding 所描述的字符编码方式，并保存到指定的文件中。同样，这需要调用 iconv.dll由于 Unicode 能够包含几乎所有的语言的字符，而且 Unicode 的 UTF-8 编码方式又是非常具有性价比的编码方式 (空间消耗比 UCS-2 小)，因此建议 encoding 的值设置为utf-8。这么做的另一个理由是 encoding 设置为 utf-8 时，Vim 自动探测文件的编码方式会更准确 (或许这个理由才是主要的 ;)。我们在中文 Windows 里编辑的文件，为了兼顾与其他软件的兼容性，文件编码还是设置为 GB2312/GBK 比较合适，因此 fileencoding 建议设置为 chinese (chinese 是个别名，在 Unix 里表示 gb2312，在 Windows 里表示cp936，也就是 GBK 的代码页)。 对于fedora来说，vim的设置一般放在/etc/vimrc文件中，不过，建议不要修改它。可以修改~/.vimrc文件（默认不存在，可以自己新建一个），写入所希望的设置。 我的.vimrc文件如下: 1234:set encoding=utf-8:set fileencodings=ucs-bom,utf-8,cp936:set fileencoding=gb2312:set termencoding=utf-8 其中，fileencoding配置可以设置utf-8，但是我的mp3好像不支持utf-8编码，所以干脆，我就设置为gb2312了。现在搞定了，不管是vi中还是mp3上都可以显示无乱码的.txt文件了。 个人的配置本人无插件使用过程中的配置很短，写在vim的配置文件.vimrc里， 配置是使用vim script进行配置的，它有自己的一套语法，详细请点击vim Script 1234567891011set number;display numberset mouse=a; setting smart mouseset hlsearch ;high light searchset tabstop=4 ; setting tab width 4 lettersset shiftwidth=4; setting new line incident widthset noexpandtab; tab doesn't expand to space;set list ;display manipulator, example： \n \t \r ......set encoding=utf-8set fileencodings=ucs-bom,utf-8,cp936set fileencoding=gb2312set termencoding=utf-8 前进和后退功能流行的文本编辑器通常都有前进和后退功能，可以在文件中曾经浏览过的位置之间来回移动（联想到浏览器），在 vim 中使用 Ctrl-O 执行后退，使用 Ctrl-I 执行前进，相关帮助： :help CTRL-O :help CTRL-I :help jump-motions vim比较文件启动方法首先保证系统中的diff命令是可用的。Vim的diff模式是依赖于diff命令的。 1vimdiff file1 file2 [file3 [file4]] 或者1vim -d file1 file2 [file3 [file4]] 窗口比较局部于当前标签页中。你不能看到某窗口和别的标签页中的窗口的差异。这样，可以同时打开多组比较窗口，每组差异在单独的标签页中。Vim 将为每个文件打开一个窗口，并且就像使用 -O 参数一样，使用垂直分割。如果你要水平分割，加上 -o 参数:1vimdiff -o file1 file2 [file3 [file4]] 如果已在 Vim 中，你可以用三种方式进入比较模式，只介绍一种：1:diffs[plit] &#123;filename&#125; 对 {filename} 开一个新窗口。当前的和新开的窗口将设定和”vimdiff” 一样的参数。要垂直分割窗口，在前面加上 :vertical 。例如:1:vert diffsplit another_filename 跳转到差异有两条命令可用于在跳转到差异文所在的位置: [c 反向跳转至上一处更改的开始。计数前缀使之重复执行相应次。 ]c 正向跳转至下一个更改的开始。计数前缀使之重复执行相应次。如果不存在光标可以跳转到的更改，将产生错误。 合并比较目的就是合并差异，直接使用以下自带命令或者麻烦的办法：手动从一个窗口拷贝至另一个窗口。 123456789101112131415161718:[range]diffg[et] [bufspec] 用另一个缓冲区来修改当前的缓冲区，消除不同之处。除非只有另外一 个比较模式下的缓冲区， [bufspec] 必须存在并指定那个缓冲区。 如果 [bufspec] 指定的是当前缓冲区，则为空动作。[range] 可以参考下面。:[range]diffpu[t] [bufspec] 用当前缓冲区来修改另一个缓冲区，消除不同之处。[count]do 同 ":diffget"，但没有范围。"o" 表示 "obtain" (不能用 "dg"，因为那可能是 "dgg" 的开始！)。dp 同 ":diffput"，但没有范围。注意 不适用于可视模式。 给出的 [count] 用作 ":diffput" 的 [bufspec] 参数。当没有给定 [range] 时，受影响的仅是当前光标所处位置或其紧上方的差异文本。当指定 [range] 时，Vim 试图仅改动它指定的行。不过，当有被删除的行时，这不总有效。参数 [bufspec] 可以是缓冲区的序号，匹配缓冲区名称或缓冲区名称的一部分的模式。例如: :diffget 使用另一个进入比较模式的缓冲区 :diffget 3 使用 3 号缓冲区 :diffget v2 使用名字同 "v2" 匹配的缓冲区，并进入比较模式(例如，"file.c.v2") 更新比较和撤销修改比较基于缓冲区的内容。因而，如果在载入文件后你做过改动，这些改动也将参加比较。不过，你也许要不时地使用 :diffupdate[!]。因为并非所有的改动的结果都能自动更新。包含! 时，Vim 会检查文件是否被外部改变而需要重新载入。对每个被改变的文件给出提示。 如果希望撤销修改，可以和平常用vim编辑一样，直接进入normal模式下按u但是要注意一定要将光标移动到需要撤销修改的文件窗口中。 上下文的展开和查看比较和合并文件的时候经常需要结合上下文来确定最终要采取的操作。Vimdiff 缺省是会把不同之处上下各 6 行的文本都显示出来以供参考。其他的相同的文本行被自动折叠。如果希望修改缺省的上下文行数，可以这样设置： 1:set diffopt=context:3 多个文件的退出在比较和合并告一段落之后，可以用下列命令对多个文件同时进行操作。 比如同时退出：:qa （quit all） 如果希望保存全部文件：:wa （write all） 或者是两者的合并命令，保存全部文件，然后退出：:wqa （write, then quit all） 如果在退出的时候不希望保存任何操作的结果：:qa! （force to quit all） vimdiff 详细请参考 vim下 :help diff vimdiff doc vim命令行的保存、离开等命令： :w 将编辑的数据写入硬盘文件中。 :w! 若文件属性为“只读”，强制写入该文件。但能否写入还由对该文件的文件权限有关。 :q保存后离开。若为“:wq！”则强制保存后离开。 :w[文件名] 将编辑的数据保存为另一个文件。 :r[文件名] 在编辑的数据中读入另一个文件的内容加到光标所在行后面。 :n1,n2 w[文件名] 将n1行到n2行的内容保存到另一个文件。 :!command 暂时离开vi到命令行模式下执行command的显示结果。 ZZ 若文件未改动，则直接离开；若已改动则保存后离开。 set num/nonum 显示/取消行号。 VIM的宏宏的使用非常强大，前往vim 中，宏的使用 完整版命令本文只提供个人使用过程中积累的高频场景，完整版请点击此处，或查阅 vim manual 玩游戏来熟能生巧用进废退，所以多用才是王道，这里推荐一个游戏：通过键盘输入控制人物角色冒险的游戏，玩游戏的过程中熟悉VIM命令: vim-adventures 参考 官方文档 vim doc 中文 freewater 博客 Thinking In Linux]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[决策树学习]]></title>
    <url>%2F2015%2F05%2F01%2Fdecision_tree%2F</url>
    <content type="text"><![CDATA[决策树学习决策树学习通常包含三个方面：特征选择、决策树生成和决策树剪枝。决策树学习思想主要来源于：Quinlan在1986年提出的ID算法、在1993年提出的C4.5算法和Breiman等人在1984年提出的CART算法。 特征选择为了解释清楚各个数学概念，引入例子 表5.1 贷款申请样本数据表（来自李航《统计方法》） ​ 上表有15个样本数据组成的贷款申请训练数据D。数据包括贷款申请人的4个特征：年龄、有工作与否、有房子与否、信贷情况，其中最后一列类别的意思是：是否同意发放贷款，这个就是决策树最后要给出的结论，即目标属性——是否发放贷款，即决策树最末端的叶子节点只分成2类：同意发放贷款与不同意发放贷款。 信息熵（entropy）​ 引入概念，对于第一个要用到的概念：信息熵在另外一篇博客——数据压缩与信息熵中详细解释了信息熵为什么度量的是不确定性，下文也不再赘述，直接引用。 ​ 设D为按照目标类别（或称目标属性）对训练数据（即样本数据）进行的划分，则D的信息熵（information entropy）表示为： ​ 其中pi表示第i个类别在整个训练数据中出现的概率，可以用属于此类别元素的数量除以训练数据（即样本数据）总数量作为估计。 具体问题具体分析 在上表中目标类别：是否发放贷款，将9个发放归为一类，剩余6个不发放归为一类，这样进行分类的信息熵为： $$H(D)=-\frac{9}{15}log_2\frac{9}{15}-\frac{6}{15}log_2\frac{6}{15}=0.971$$ 注：这个根据目标类别分类得出的信息熵，在样本给出的情况下就已经知晓，根据概率统计，也称经验熵。 ​ 现在我们假设将训练数据D按属性A进行划分，则按A属性进行分裂出的v个子集（即树中的v个分支），这些子集按目标类别（发放与不发放两类）进行分类所对应的熵的期望（即：按属性A划分出不同子集的信息熵的平均值）： 注：这个实际上是经验条件熵，因为确认是在A属性划分出子集的前提下再按照目标类别分类得出的熵的期望，见下文信息增益计算就可以一目了然。 信息增益（information gain）为上述两者的差值： 具体问题具体分析 按照年龄属性（记为A1）划分：青年（D1表示），中年（D2表示），老年（D3表示） 按照是否有工作（记为A2）划分：有工作（D1表示），无工作（D2表示） 按照是否有自己房子（记为A3）划分：有自己房子（D1表示），无自己房子（D2表示） 同理，根据最后一个属性：信贷情况算出其信息增益： 所以可以看出信息增益度量的是：信息熵的降低量，这个降低是经过某个属性对原数据进行划分得出的。信息熵的降低，即确定性的提高，进一步讲，就是类别的数量在下降，那么确定为哪一类的可能性就提高，这样就更容易分类了。ID3算法就是基于信息增益来衡量属性（即特征）划分数据的能力，进而为特征（即属性）选择提供原则。 增益比率（gain ratio） 信息增益选择方法有一个很大的缺陷，它总是会倾向于选择属性值多的属性，如果我们在上面的数据记录中加一个姓名属性，假设15条记录中的每个人姓名不同，那么信息增益就会选择姓名作为最佳属性，因为按姓名分裂后，每个组只包含一条记录，而每个记录只属于一类（要么发放要么不发放），因此不确定性最低，即纯度最高，（注：为什么最高呢？大家可以根据导数计算一下，最大值的情况，这里不赘述）以姓名作为测试分裂的结点下面有15个分支。但是这样的分类没有意义，它没有任何泛化能力。增益比率对此进行了改进，它引入一个分裂信息： $$SplitInfo_R(D)=-\sum\limits_{j=1}^{k}\frac{|D_j|}{D}\times log_2(\frac{|D_j|}{D})$$ 注：分裂信息即按照某个属性划分的信息熵，而本文前面叙述的熵全部是按照目标属性进行分类的信息熵。 增益比率定义为信息增益与分裂信息的比率： $$GainRatio(R)=\frac{Gain(R)}{SplitInfo_R(D)}$$ 我们找GainRatio最大的属性作为最佳分裂属性。如果一个属性的取值很多，那么SplitInfoR(D)会大，从而使GainRatio(R)变小。不过增益比率也有缺点，SplitInfo(D)可能取0，此时没有计算意义；且当SplitInfo(D)趋向于0时，GainRatio(R)的值变得不可信，改进的措施就是在分母加一个平滑，这里加一个所有分裂信息的平均值： $$GainRatio(R)=\frac{Gain(R)}{\overline{SplitInfo(D)}+SplitInfo_R(D)}$$ C4.5算法就是按照信息增益比来计算各属性的分类能力，进而为特征（即属性）选择提供原则。 基尼指数（Gini coefficient） 定义（基尼指数）：在分类问题中，假设有K个类，样本点属于第K类的概率为p(k)，则概率分布的基尼指数定义为 对于2分类问题，若样本属于第一类的概率是p，则概率分布的基尼指数为： 对于给定的样本集合D的基尼指数为： 这里，C(k)是D中属于第k类的样本子集，K是类的个数。 如果样本集合D根据特征A是否取某一可能值α被分割成D1和D2两部分，即 则在特征A的条件下，集合D的基尼指数定义为 基尼指数Gini(D)表示集合D的不确定性，基尼指数Gini(D, A)表示经A=α分割后集合D的不确定性。基尼指数值越大，样本集合的不确定性也就越大，这一点与熵相似。 ID3算法 信息增益算法（来自李航《统计方法》） ID3算法（来自李航《统计方法》） 示例（来自李航《统计方法》） C4.5生成算法（来自李航《统计方法》） CART生成算法（来自李航《统计方法》） 示例]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Perception Learning Algorithm]]></title>
    <url>%2F2015%2F04%2F24%2Fperception_learning_algorithm%2F</url>
    <content type="text"><![CDATA[PLA(Perception Learning Algorithm) 适用于二维及高维的线性可划分问题。问题的答案只有同意或者不同意。 例子银行可以根据顾客的个人信息来判断是否给顾客发放信用卡。将顾客抽象为一个向量$X$，包括姓名、年龄、年收入、负债数等。同时设定各个属性所占的权重向量为$W$，对于正相关的属性设置相对较高的权重，如年收入，对于负相关的属性设置较低的权重，如负债数。$y$表示是否想该用户发放了信用卡。通过求$X$和$W$的内积减去一个阀值threshold，若为正则同意发放信用卡，否则不发放信用卡。我们假设存在着一个从$X$到$Y$的映射$f$，PLA算法就是用来模拟这个映射，使得求出的函数与$f$尽可能的相似，起码在已知的数据集(即样本上)上一致。 PLA算法即用来求向量$W$，使得在已知的数据中机器做出的判断与现实数据相同。当$X$为二维向量时，相当于在平面上画出一条直线将所有的点分成两部分，一部分同意发送，另一部分的不同意。内积可以表示成：$$\begin{eqnarray}h(x) &amp;=&amp; sign((\sum\limits_{i=1}^{d}W_i X_i)-threshold)\\&amp;=&amp; sign((\sum\limits_{i=1}^{d}W_i X_i)+\underbrace{(-threshold)}_{W_0}\times\underbrace{(+1)}_{X_0})\\&amp;=&amp; sign(\sum\limits_{i=0}^{d}W_i X_i)\\&amp;=&amp; sign(W^TX)\end{eqnarray}$$ 其中$X_0=1，W_0=-threshold$ $y_s$的值域：$\{+1，-1\}$，($y_s$ 表示样本中$y$的值，用于输入到算法进行调整) 结合文中例子：$y_s=1$ 表示在给定的样本数据中，给该用户发放了信用卡，$y_s= -1$表示未发放。 PLA先假定$W_0$为向量$\vec{0}$，然后找到一个不满足条件的点，调整$W$的值，依次进行迭代所有样本数据使得最终可以将两部分完全分开。 W的调整方案错误驱动调整 解释一下ppt的内容，出现错误分2种情况： 在给定的已知数据中向该用户发放了数据，即$y_s(i)$样本中第$i$个数据为$+1$，但算法给出的结果是不发放（$h(X_i) &lt;0$），说明两个向量的内积为负，需要调整$W$向量使得两条向量更接近，此时令调整系数为样本的$y_s(i)$，则调整后的$W_{t+1}= W_t + y_s(i)X_i$，$W$的下标$t, t+1$表示调整的次数，示意图: 在给定的已知数据中向该用户发放了数据，即$y_s(i)$样本中第$i$个数据为$-1$，但算法给出的结果是不发放（$h(X_i) &gt; 0$），说明两个向量的内积为正，需要调整$W$向量使得两条向量更远离，此时令调整系数为样本的$y_s(i)$，则调整后的$W_{t+1}= W_t + y_s(i)X_i$，示意图: 注意：2种不同情况的调整的表达式都一样 对于线性可分的数据集，PLA算法是可收敛的 两个向量的内积增大说明： 两个向量夹角越小 或者向量的长度增大 老师的ppt上 $||W_{t+1}||^2 \le ||W_t||^2 + max\{1 \le i \le n\ \ |\ \ ||y_i X_i||^2\}$ 其中，$y_i$的值域 $\{+1, -1\}$ 因此 $||W_{t+1}||^2 \le ||W_t||^2 + max\{1 \le i \le n\ \ |\ \ ||X_i||^2\}$ 这说明每次调整后，向量的长度增加有限。不妨 带入上一公式得到： $$\begin{eqnarray}\frac{||W_{t+1}||^2}{||W_{t}||^2} &amp;\le&amp; \frac{||W_{t}||^2 + max||y_n x_n||^2}{||W_{t}||^2} \\&amp;=&amp; \frac{||W_{t}||^2 + max||x_n||^2}{||W_{t}||^2} \\&amp;=&amp;1+ \frac{R^2}{||W(t)||^2}\end{eqnarray}$$ 因此$W_t$最终是收敛的，到此已经证明了PLA算法最终可以停止。 算法需要调整的次数由上述过程可以得到以下两个不等式： $$\begin{eqnarray}W_f^t W_t &amp;=&amp; W_f^t(W_{t-1}+y_s(t-1)X_{t-1}) \\&amp;=&amp; W_f^tW_{t-1}+y_s(t-1)W_f^tX(t-1) \\&amp;\ge&amp; W_f^tW_{t-1}+min(yW_f^tX) \\&amp;\ge&amp; W_f^tW_{t-2}+2\,min(yW_f^tX) \\&amp;\cdots&amp; \\&amp;\ge&amp; W_f^tW_0 + t\,min(yW_f^tX) \\&amp;=&amp; t\,min(yW_f^tX)\end{eqnarray}$$ $$\begin{eqnarray}||W_t||^2 &amp;\le&amp; ||W_{t-1}||^2+max(||X||^2)\\&amp;\le&amp; ||W_{t-2}||^2+2\,max(||X||^2)\\&amp;\cdots&amp; \\&amp;\le&amp; ||W_0||^2+t\,max(||X||^2)\\&amp;=&amp; t\, max(||X||^2)\end{eqnarray}$$ 那么来看这个式子：$\frac{W_f^t W_t}{||W_f^t||\ ||W_t||}\ge \frac{t\ min(yW_f^tX)}{||W_f^t||\sqrt{t\,(max(||X||))^2}}=\sqrt{t}\, \frac{min(yW_f^tX)}{||W_f^t||max(||X||)} $ 再根据余弦值最大为1，可以得到$\frac{W_f^tW_t}{||W_f^t||\ ||W_t||}\le 1$，于是我们得到调整次数：$t\le \frac{||W_f^t||(max(||X||))^2}{(min(yW_f^tX))^2}={R^2 \over \rho^2}$. PLA的优缺点 一方面，我事先肯定不知道$W_f^t$，另一方面为了应对可能出现的噪声。那么怎么衡量当前得到的直线能够满足要求呢？我们只能在每一步的时候都判断一下，调整后的$W_{t+1}$是否比上一次的$W_t$能够线性可分更多的数据，于是有了下面的改进算法Pocket PLA，PocketPLA比PLA在调整的时候多做一步：判断当前改正犯的错是否比之前更小，也就是贪心选择。 Pocket PLA 参考 HappyAngel DreamerMonkey ppt全部来自台大《机器学习基石》课堂]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划-最长公共子序列]]></title>
    <url>%2F2014%2F06%2F01%2Flongest_common_sub-sequence%2F</url>
    <content type="text"><![CDATA[算法总体思想动态规划（Dynamic Programming）是通过组合子问题的解而解决整个问题的。分治是指将问题划分成一些独立的子问题，递归地求解各子问题，然后合并子问题的解而得到原始问题的解，与此不同，动态规划适用于子问题不是独立的情况，也就是各个子问题包含公共的子问题。在这种情况下，采用分治法会做许多不必要的工作，即重复地求解公共地子问题。动态规划算法对每个子问题只求解一次，将其结果保存在一张表中，从而避免每次遇到各个子问题时重新计算答案。 动态规划算法的基本要素最优子结构 矩阵连乘计算次序问题的最优解包含着其子问题的最优解。这种性质称为最优子结构性质。 在分析问题的最优子结构性质时，所用的方法具有普遍性：首先假设由问题的最优解导出的子问题的解不是最优的，然后再设法说明在这个假设下可构造出比原问题最优解更好的解，从而导致矛盾。 利用问题的最优子结构性质，以自底向上的方式递归地从子问题的最优解逐步构造出整个问题的最优解。最优子结构是问题能用动态规划算法求解的前提。 注意：同一个问题可以有多种方式刻划它的最优子结构，有些表示方法的求解速度更快（空间占用小，问题的维度低） 重叠子问题 递归算法求解问题时，每次产生的子问题并不总是新问题，有些子问题被反复计算多次。这种性质称为子问题的重叠性质。 动态规划算法，对每一个子问题只解一次，而后将其解保存在一个表格中，当再次需要解此子问题时，只是简单地用常数时间查看一下结果。 通常不同的子问题个数随问题的大小呈多项式增长。因此用动态规划算法只需要多项式时间，从而获得较高的解题效率。 问题举例最长公共子序列(LCS) 若给定序列$X=\{x_1,x_2,…,x_m\}$，则另一序列$Z=\{z_1,z_2,…,z_k\}$，是 $X$ 的子序列是指存在一个严格递增下标序列$\{i_1,i_2,…,i_k\}$使得对于所有$j=1,2,…,k$ 有：$z_j=x_{i}$。例如，序列 $Z=\{B，C，D，B\}$ 是序列 $X=\{A，B，C，B，D，A，B\}$ 的子序列，相应的递增下标序列为$\{2，3，5，7\}$。 给定2个序列 $X$ 和 $Y$，当另一序列 $Z$ 既是 $X$ 的子序列又是 $Y$ 的子序列时，称 $Z$ 是序列 $X$ 和 $Y$ 的公共子序列。 给定2个序列$X=\{x_1,x_2,…,x_m\}$和 $Y=\{y_1,y_2,…,y_n\}$，找出 $X$ 和 $Y$ 的最长公共子序列。 最长公共子序列的结构(LCS)设序列$X=\{x_1,x_2,…,x_m\}$和 $Y=\{y_1,y_2,…,y_n\}$的最长公共子序列为 $Z=\{z_1,z_2,…,z_k\}$ ，则 若$x_m=y_n$，则$z_k=x_m=y_n$，且 $z_{k-1}$ 是 $\{x_1,\ldots, x_{m-1}\}$ 和 $\{y_1, \ldots, y_{n-1}\}$ 的最长公共子序列。 若 $x_m≠y_n$ 且 $z_k≠x_m, z_k=y_n$，则 $Z$ 是 $\{x_1,\ldots, x_{m-1}\}$ 和 $Y$ 的最长公共子序列。 若 $x_m≠y_n$且 $z_k≠y_n, z_k=x_m$，则 $Z$ 是 $X$ 和 $\{y_1, \ldots, y_{n-1}\}$ 的最长公共子序列。 由此可见，2个序列的最长公共子序列包含了这2个序列的前缀的最长公共子序列。因此，最长公共子序列问题具有最优子结构性质。 LCS时间复杂度求解LCS问题，不能使用暴力搜索方法。一个长度为n的序列拥有 2的n次方个子序列，它的时间复杂度是指数阶，而且还是两个序列求最长公共子序列。 子问题的递归结构由最长公共子序列问题的最优子结构性质建立子问题最优值的递归关系。用$c[i][j]$记录序列和的最长公共子序列的长度。 其中，$X[i]=\{x_1,x_2,…,x_i\}$；$Y[j]=\{y_1,y_2,…,y_j\}$。当 $i=0$ 或 $j=0$ 时，空序列是 $X[i]$ 和 $Y[j]$ 的最长公共子序列。故此时 $c[i][j]=0$ 。其他情况下，由最优子结构性质可建立递归关系如下： $c[i][j]=\cases{0,\quad i=0,j=0 \\ c[i-1][j-1]+1\quad i,j&gt;0;x_i=y_j \\ max\{c[i][j-1],c[i-1][j]\}\quad i,j&gt;0;x_i\ne y_j}$ 计算最优值（伪代码）12345678910111213141516AlgorithmlcsLength(x,y,b)mßx.length-1;nßy.length-1;c[i][0]=0;c[0][i]=0;for(int i= 1; i&lt;= m;i++) for(int j = 1; j &lt;= n; j++) if(x[i]==y[j]) c[i][j]=c[i-1][j-1]+1; b[i][j]=1; else if(c[i-1][j]&gt;=c[i][j-1]) c[i][j]=c[i-1][j]; b[i][j]=2; else c[i][j]=c[i][j-1]; b[i][j]=3; 源代码实现（测试通过）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#include&lt;iostream&gt;#define LEN_ARR_A 20#define LEN_ARR_B 12using namespace std;/* * brief : calculate longest common substring of two string and * mark path of getting the longest common substring * parameter : lenComStr : length of common substring * solutionPath : mark of path of solution * * note： dynamic programming :caculate longest common substring between X(n) * and Y(m-1),likey to caculate longest common substring between X(n) * and Y(m-1) or between X(n-1) and Y(m). X(0) and Y(0) are not referenced! * * * return : null */template&lt;class Type&gt;void LCSLength(size_t lenStrA, size_t lenStrB, Type *strA, Type *strB, size_t ** lenComStr, size_t ** solutionPath)&#123; for(size_t i = 0; i &lt; lenStrA; ++i) lenComStr[i][0] = 0; for(size_t i = 0; i &lt; lenStrB; ++i) lenComStr[0][i] = 0; for(size_t i = 1; i &lt; lenStrA; ++i) for(size_t j = 1; j &lt; lenStrB; ++j)&#123; if(strA[i] == strB[j])&#123; lenComStr[i][j] = lenComStr[i -1][j - 1] + 1; //global solution depends on local solution solutionPath[i][j] = 1; //mark path of getting the longest common substring &#125; else if(lenComStr[i - 1][j] &gt;= lenComStr[i][j - 1])&#123; lenComStr[i][j] = lenComStr[i - 1][j]; //global solution depends on local solution solutionPath[i][j] = 2; &#125;else&#123; lenComStr[i][j] = lenComStr[i][j - 1]; //global solution depends on local solution solutionPath[i][j] = 3; &#125; &#125;&#125;/* * brief : output longest common substring of two string * * parameter : i is beginning index of char array * j is end index of char array * solutionPath is the path of solution * * note： value of solutionPath[i][j] has 3 states * * return : null */ template&lt;class Type&gt;void LCS(size_t i, size_t j, Type * strA, size_t ** solutionPath)&#123; if(i == -1 || j == -1) return; if(solutionPath[i][j] == 1)&#123; LCS(i - 1, j - 1, strA, solutionPath); cout &lt;&lt; strA[i]; &#125;else if(solutionPath[i][j] == 2) LCS(i - 1, j, strA, solutionPath); else&#123; LCS(i, j - 1, strA, solutionPath); &#125;&#125;int main()&#123; char strA[LEN_ARR_A] = &#123; '0','B', 'D', 'C', 'A', 'B', 'A'&#125;; char strB[LEN_ARR_B] = &#123; '0', 'A', 'B', 'C', 'B', 'D', 'A', 'B'&#125;; size_t ** lenComStr = new size_t*[LEN_ARR_A]; size_t ** solutionPath = new size_t*[LEN_ARR_A]; for(size_t i = 0; i &lt; LEN_ARR_A; ++i) &#123; lenComStr[i] = new size_t[LEN_ARR_B]; solutionPath[i] = new size_t[LEN_ARR_B]; &#125; LCSLength(LEN_ARR_A, LEN_ARR_B, strA, strB, lenComStr, solutionPath); LCS(LEN_ARR_A - 1, LEN_ARR_B - 1, strA, solutionPath); return 0;&#125;]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Data Structure</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[含括号的运算表达式求解-栈的基础应用3]]></title>
    <url>%2F2013%2F05%2F13%2Fstack_application_on_expression-resolution-with-braces%2F</url>
    <content type="text"><![CDATA[本文根据严蔚敏老师数据结构（c语言版） 写的程序 如有需要先去看视频 如有错误不当之处，欢迎指出，以免害人害己。 例子Exp = a b + ( c – d / e ) f ​ 前缀式：+ a b - c / d e f ​ 中缀式：a b + c–d / e f ​ 后缀式：a b cd e /-f + 相同点数字都是按原式子排列的：因此操作数就按顺序入栈就好了 不同点1:后缀式中运算符的顺序，正好就是求解的顺序 2:每个运算符和它之前出现且紧靠它的2个操作数构成一个最小表达式 关键：就是由原表达式求得后缀式 应用步骤 Step1： 先设立两个栈，一个运算符栈，另一个后缀式栈。 Step2：在表达式前后头尾加入=号，表示运算表达式开始和结束，因此在运算符中，=号优先级最低。 Step3：若当前字符是操作数，则直接发送给后缀式栈。符合上面提到的共同点：数字按原表达式从左自右的顺序。 Step4：左括号的优先级高于左括号前的运算符，左括号后的运算符优先级高于左括号，这样才能起到隔离的作用，则右括号前的运算符高于右括号，这样才能起到括号隔离内层表达式的作用！ Step5：若当前运算符的优先级高于栈顶的运算符，则进运算符栈，否则退出运算符栈的栈顶运算符与从操作数栈栈顶取出的两个操作数运算结果作为新的操作数压入操作数栈，然后再把当前运算符入运算符栈。 源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206#include&lt;stdio.h&gt; #include&lt;malloc.h&gt;//malloc()#include&lt;process.h&gt;//exit();// 函数结果状态代码#define TRUE 1#define FALSE 0#define OK 1#define ERROR 0#define INFEASIBLE -1#define STACK_INIT_SIZE 100 // 存储空间初始分配量#define STACKINCREMENT 2 // 存储空间分配增量typedef int Status; // Status是函数的类型,其值是函数结果状态代码，如OK等typedef char SElemType;struct SqStack&#123; SElemType *base; // 在栈构造之前和销毁之后，base的值为NULL SElemType *top; // 栈顶指针 int stacksize; // 当前已分配的存储空间，以元素为单位&#125;;Status InitStack(SqStack &amp;S)&#123; // 构造一个空栈S if(!(S.base=(SElemType *)malloc(STACK_INIT_SIZE*sizeof(SElemType)))) exit(-1); // 存储分配失败 S.top=S.base; S.stacksize=STACK_INIT_SIZE; return OK;&#125;Status DestroyStack(SqStack &amp;S)&#123; // 销毁栈S，S不再存在 free(S.base); S.base=NULL; S.top=NULL; S.stacksize=0; return OK;&#125;Status ClearStack(SqStack &amp;S)&#123; // 把S置为空栈 S.top=S.base; return OK;&#125;Status StackEmpty(SqStack S)&#123; // 若栈S为空栈，则返回TRUE，否则返回FALSE if(S.top==S.base) return TRUE; else return FALSE;&#125;int StackLength(SqStack S)&#123; // 返回S的元素个数，即栈的长度 return S.top-S.base;&#125;Status GetTop(SqStack S,SElemType &amp;e)&#123; // 若栈不空，则用e返回S的栈顶元素，并返回OK；否则返回ERROR if(S.top&gt;S.base) &#123; e=*(S.top-1); return OK; &#125; else return ERROR;&#125;Status Push(SqStack &amp;S,SElemType e)&#123; // 插入元素e为新的栈顶元素 if(S.top-S.base&gt;=S.stacksize) // 栈满，追加存储空间 &#123; S.base=(SElemType *)realloc(S.base,(S.stacksize+STACKINCREMENT)*sizeof(SElemType)); if(!S.base) exit(-1); // 存储分配失败 S.top=S.base+S.stacksize; S.stacksize+=STACKINCREMENT; &#125; *(S.top)++=e; return OK;&#125;Status Pop(SqStack &amp;S,SElemType &amp;e)&#123; // 若栈不空，则删除S的栈顶元素，用e返回其值，并返回OK；否则返回ERROR if(S.top==S.base) return ERROR; e=*--S.top; return OK;&#125;Status StackTraverse(SqStack S,Status(*visit)(SElemType))&#123; // 从栈底到栈顶依次对栈中每个元素调用函数visit()。 // 一旦visit()失败，则操作失败 while(S.top&gt;S.base) visit(*S.base++); printf("\n"); return OK;&#125;SElemType Precede(SElemType a, SElemType b) &#123; //判断运算符优先级 int i, j; char Table[8][8] = &#123; &#123;' ','+','-','*','/','(',')','#'&#125;, &#123;'+','&gt;','&gt;','&lt;','&lt;','&lt;','&gt;','&gt;'&#125;, &#123;'-','&gt;','&gt;','&lt;','&lt;','&lt;','&gt;','&gt;'&#125;, &#123;'*','&gt;','&gt;','&gt;','&gt;','&lt;','&gt;','&gt;'&#125;, &#123;'/','&gt;','&gt;','&gt;','&gt;','&lt;','&gt;','&gt;'&#125;, &#123;'(','&lt;','&lt;','&lt;','&lt;','&lt;','=',' '&#125;, &#123;')','&gt;','&gt;','&gt;','&gt;',' ','&gt;','&gt;'&#125;, &#123;'#','&lt;','&lt;','&lt;','&lt;','&lt;',' ','='&#125; &#125;; //优先级表格 for(i=0; i&lt;8; i++) if(Table[0][i]==a) //寻找运算符a break; for(j=0; j&lt;8; j++) //寻找运算符 if(Table[j][0]==b) break; return Table[j][i];&#125;Status In(SElemType c)&#123; // 判断c是否为运算符 switch(c) &#123; case'+': case'-': case'*': case'/': case'(': case')': case'#':return TRUE; default:return FALSE; &#125;&#125;SElemType Operate(SElemType a,SElemType theta,SElemType b)&#123; SElemType c; a=a-48; b=b-48; switch(theta) &#123; case'+':c=a+b+48; break; case'-':c=a-b+48; break; case'*':c=a*b+48; break; case'/':c=a/b+48; &#125; return c;&#125;SElemType EvaluateExpression() // 算法3.4&#123; // 算术表达式求值的算符优先算法。设OPTR和OPND分别为运算符栈和运算数栈 SqStack OPTR,OPND; SElemType a,b,c,x,theta; InitStack(OPTR); Push(OPTR,'#'); InitStack(OPND); c=getchar(); GetTop(OPTR,x); while(c!='#'||x!='#') &#123; if(In(c)) // 是7种运算符之一 switch(Precede(c,x)) &#123; case'&lt;':Push(OPTR,c); // 栈顶元素优先权低 c=getchar(); break; case'=':Pop(OPTR,x); // 脱括号并接收下一字符 c=getchar(); break; case'&gt;':Pop(OPTR,theta); // 退栈并将运算结果入栈 Pop(OPND,b); Pop(OPND,a); Push(OPND,Operate(a,theta,b)); break; &#125; else if(c&gt;='0'&amp;&amp;c&lt;='9') // c是操作数 &#123; Push(OPND,c); c=getchar(); &#125; else // c是非法字符 &#123; printf("非法字符\n"); exit(-1); &#125; GetTop(OPTR,x); &#125; GetTop(OPND,x); return x;&#125;int main()&#123; printf("请输入算术表达式（中间值及最终结果要在0～9之间），并以#结束\n"); printf("%c\n",EvaluateExpression()); return 0;&#125;]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Data Structure</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[行编辑器/容错缓冲区-栈的基础应用2]]></title>
    <url>%2F2013%2F05%2F12%2Fstack_application_on_line-editor_or_buff_zone%2F</url>
    <content type="text"><![CDATA[功能接收用户的从终端输入程序或数据，并存入用户的数据区。由于用户在终端上输入难免出现差错，因此，若在行编辑程序中，“每接收一个字符即存入用户数据区”显然是不合理的。较好的做法，设立一个缓冲区，用以接收用户输入的每一行字符，然后逐行存入用户数据区。允许用户输入出错，并在发现有误时可以及时更正。例如，当用户发现刚刚键入的一个字符是错的时，补进一个退格符#，以表示前一个字符无效；如果发现当前键入的行内差错较多或难以补救，就可以键入一个退行符号@，以表示当前行中的字符均无效。 例子​ 从终端接收这样两行字符： ​ whi##ilr#e(s#*s) ​ outcha@putchar(*s#++) ​ 实际有效的是下列两行： ​ while(*s) ​ putchar(*s++) ​ 为此，我们可以设立一个缓冲区，结构为栈，每当用户从终端接受了一个字符之后现做如下判别：如果他既不是退格符，也不是退行符，则将该字符压入栈中，如果是退格符，则从栈顶删去一个字符；如果是退行符，则将字符栈清空。 源代码1234567891011121314151617181920212223242526272829void LineEdit()&#123; //利用字符栈s，从终端接收一行并送至调用过程的数据区。算法3.2 SqStack s; char ch,c; InitStack(s); printf("请输入一个文本文件,^Z结束输入:\n"); ch=getchar(); while(ch!=EOF) &#123;// EOF为^Z键，全文结束符 while(ch!=EOF&amp;&amp;ch!='\n') &#123; switch(ch) &#123; case '#':Pop(s,c); break; // 仅当栈非空时退栈 case '@':ClearStack(s); break; // 重置s为空栈 default :Push(s,ch); // 有效字符进栈 &#125; ch=getchar(); // 从终端接收下一个字符 &#125; StackTraverse(s,copy); // 将从栈底到栈顶的栈内字符传送至文件 ClearStack(s); // 重置s为空栈 fputc('\n',fp); if(ch!=EOF) ch=getchar(); &#125; DestroyStack(s);&#125;]]></content>
      <categories>
        <category>中文</category>
      </categories>
      <tags>
        <tag>Data Structure</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
</search>
